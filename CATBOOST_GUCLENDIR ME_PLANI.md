# ğŸš€ CatBoost Model GÃ¼Ã§lendirme PlanÄ±

## ğŸ“Š MEVCUT DURUM ANALÄ°ZÄ°

### Mevcut Performans (Loglardan)
```
CatBoost Regressor:
  MAE: 8.1885
  RMSE: 63.7084
  EÄŸitim SÃ¼resi: ~0.0 dakika (Ã§ok hÄ±zlÄ± - erken durdurma ile)

CatBoost Classifier:
  Genel Accuracy: 45.28%
  1.5 AltÄ± DoÄŸruluk: 79.94% âœ… Ä°yi!
  1.5 ÃœstÃ¼ DoÄŸruluk: 26.81% âŒ Ã‡ok DÃ¼ÅŸÃ¼k!
  Para KaybÄ± Riski: 20.1% (Hedef: <20%)
  EÄŸitim SÃ¼resi: ~0.0 dakika (Ã§ok erken durdu!)

Sanal Kasa:
  Kasa 1 (1.5x): +180 TL kar, %71.5 kazanma
  Kasa 2 (%80): +60 TL kar, %78.3 kazanma (23 oyun - Ã§ok az!)
```

### Sorunlar
1. âŒ **Erken Durdurma Ã‡ok Agresif:** Model sadece 12-51 iteration'da durdu (500'den!)
2. âŒ **1.5 ÃœstÃ¼ DoÄŸruluk Ã‡ok DÃ¼ÅŸÃ¼k:** %26.81 (Hedef: %70+)
3. âŒ **Class Imbalance:** 1.5 altÄ±na 2.0x weight yeterli deÄŸil
4. âŒ **Model Kapasitesi:** depth=7-8 ve iterations=500 yetersiz kalmÄ±ÅŸ olabilir

### Neden Erken Durdu?
```python
# Mevcut ayarlar
early_stopping_rounds=20  # Ã‡ok dÃ¼ÅŸÃ¼k!
iterations=500            # Yeterli ama erken duruyor

# 51. iteration'da durdu (Regressor)
# 12. iteration'da durdu (Classifier) - Ã‡OK ERKEN!

Sebep: Validation loss 20 epoch boyunca iyileÅŸmedi
â†’ Model Ã§ok basit veya learning_rate Ã§ok yÃ¼ksek
```

## âœ… Ã‡Ã–ZÃœM STRATEJÄ°SÄ°

### SeÃ§enek 1: Agresif GÃ¼Ã§lendirme (Ã–NERÄ°LEN) â­

#### 1ï¸âƒ£ Iterations ArtÄ±r (500 â†’ 1500)
```python
iterations=1500  # 3x artÄ±ÅŸ - daha derin Ã¶ÄŸrenme

Beklenen:
  - Daha karmaÅŸÄ±k pattern'ler Ã¶ÄŸrenilir
  - Validation performansÄ± iyileÅŸir
  - EÄŸitim sÃ¼resi: 0.1 dk â†’ 0.3-0.5 dk (hala hÄ±zlÄ±!)
```

#### 2ï¸âƒ£ Depth ArtÄ±r (7-8 â†’ 10)
```python
# Regressor
depth=10  # 8 â†’ 10 (daha derin aÄŸaÃ§lar)

# Classifier
depth=9   # 7 â†’ 9 (daha derin aÄŸaÃ§lar)

Beklenen:
  - Daha karmaÅŸÄ±k feature interactions
  - Non-linear pattern'leri daha iyi yakalar
  - Overfitting riski: DÃ¼ÅŸÃ¼k (CatBoost regularization ile)
```

#### 3ï¸âƒ£ Learning Rate Optimize Et
```python
# Mevcut: 0.05 (orta hÄ±z)

# YENÄ° STRATEJÄ°: Daha yavaÅŸ baÅŸla, uzun eÄŸit
learning_rate=0.03  # 0.05 â†’ 0.03 (daha yavaÅŸ, daha stabil)

# ArtÄ±: iterations artÄ±nca otomatik dengelenir
# Daha yavaÅŸ LR + Daha fazla iteration = Daha iyi generalization
```

#### 4ï¸âƒ£ Early Stopping GevÅŸet
```python
# Mevcut: 20 (Ã§ok agresif)
early_stopping_rounds=100  # 20 â†’ 100 (sabÄ±rlÄ± eÄŸitim)

# Neden?
# - Model 12-51 iteration'da duruyordu
# - Daha fazla iteration'a ihtiyaÃ§ var
# - 100 epoch boyunca iyileÅŸmezse gerÃ§ekten durmalÄ±
```

#### 5ï¸âƒ£ Class Weights Ayarla (Classifier Ä°Ã§in)
```python
# Mevcut: {0: 2.0, 1: 1.0}
# 1.5 Ã¼stÃ¼ doÄŸruluk %26 â†’ Ã‡ok dÃ¼ÅŸÃ¼k!

# YENÄ°: Daha dengeli
class_weights = {0: 1.5, 1: 1.2}  # Ä°kisine de Ã¶nem ver

# VEYA: Grid Search ile otomatik bulma
class_weights = {
    0: [1.0, 1.2, 1.5, 2.0, 2.5],  # 1.5 altÄ±
    1: [1.0, 1.1, 1.2, 1.3, 1.5]   # 1.5 Ã¼stÃ¼
}
# Best kombinasyonu bul
```

#### 6ï¸âƒ£ L2 Regularization Ekle
```python
# CatBoost'ta L2 regularization kontrolÃ¼
l2_leaf_reg=3  # Default: 3, arttÄ±rabilirsin (3-10 arasÄ±)

# Overfitting Ã¶nleme
# Model Ã§ok derine giderse regularization dengeler
```

#### 7ï¸âƒ£ Subsample Ekle (Stochastic Gradient)
```python
# Her iteration'da data'nÄ±n bir kÄ±smÄ±nÄ± kullan
subsample=0.8  # %80 data ile train (daha hÄ±zlÄ± + daha robust)

# FaydalarÄ±:
# - Overfitting azalÄ±r
# - EÄŸitim hÄ±zlanÄ±r
# - Generalization iyileÅŸir
```

### SeÃ§enek 2: Hyperparameter Tuning (Opsiyonel)

#### Grid Search ile Otomatik Optimizasyon
```python
from catboost import CatBoostClassifier, Pool, cv

# Grid search parametreleri
param_grid = {
    'iterations': [1000, 1500, 2000],
    'depth': [8, 9, 10, 12],
    'learning_rate': [0.01, 0.03, 0.05],
    'l2_leaf_reg': [1, 3, 5, 7],
    'class_weights': [
        {0: 1.5, 1: 1.0},
        {0: 2.0, 1: 1.2},
        {0: 2.5, 1: 1.5}
    ]
}

# Cross-validation ile en iyi parametreleri bul
best_params = grid_search(param_grid, X_train, y_train)
```

## ğŸ¯ Ã–NERÄ°LEN YAPILANDIRMA

### CatBoost Regressor (Optimize)
```python
regressor = CatBoostRegressor(
    # MODEL KAPASÄ°TESÄ°
    iterations=1500,           # 500 â†’ 1500 (3x artÄ±ÅŸ)
    depth=10,                  # 8 â†’ 10 (daha derin)
    learning_rate=0.03,        # 0.05 â†’ 0.03 (daha stabil)
    
    # REGULARIZATION
    l2_leaf_reg=5,             # YENÄ°: Overfitting Ã¶nleme
    subsample=0.8,             # YENÄ°: Stochastic gradient
    
    # LOSS & METRIC
    loss_function='MAE',
    eval_metric='MAE',
    
    # TRAINING
    task_type='GPU',
    verbose=100,               # 50 â†’ 100 (daha az log)
    random_state=42,
    early_stopping_rounds=100, # 20 â†’ 100 (sabÄ±rlÄ±)
    
    # YENÄ°: Auto class weights
    auto_class_weights='Balanced'  # Otomatik denge
)
```

**Beklenen Ä°yileÅŸme:**
- MAE: 8.19 â†’ **6.5-7.5** (â†“ %10-20)
- RMSE: 63.71 â†’ **50-55** (â†“ %15-20)
- EÄŸitim SÃ¼resi: 0.1 dk â†’ **0.3-0.5 dk** (hala hÄ±zlÄ±!)

### CatBoost Classifier (Optimize)
```python
classifier = CatBoostClassifier(
    # MODEL KAPASÄ°TESÄ°
    iterations=1500,           # 500 â†’ 1500 (3x artÄ±ÅŸ)
    depth=9,                   # 7 â†’ 9 (daha derin)
    learning_rate=0.03,        # 0.05 â†’ 0.03 (daha stabil)
    
    # REGULARIZATION
    l2_leaf_reg=5,             # YENÄ°: Overfitting Ã¶nleme
    subsample=0.8,             # YENÄ°: Stochastic gradient
    
    # CLASS IMBALANCE
    class_weights={0: 1.5, 1: 1.2},  # 2.0 â†’ 1.5 (daha dengeli)
    # VEYA
    auto_class_weights='Balanced',   # Otomatik denge
    
    # LOSS & METRIC
    loss_function='Logloss',
    eval_metric='Accuracy',
    
    # TRAINING
    task_type='GPU',
    verbose=100,
    random_state=42,
    early_stopping_rounds=100, # 20 â†’ 100 (sabÄ±rlÄ±)
    
    # YENÄ°: Class weighting stratejisi
    scale_pos_weight=None,     # auto_class_weights kullanÄ±ldÄ±ÄŸÄ±nda
)
```

**Beklenen Ä°yileÅŸme:**
- Genel Accuracy: 45% â†’ **60-70%** (â†‘ %30-50)
- 1.5 AltÄ± DoÄŸruluk: 80% â†’ **75-85%** (koruma)
- 1.5 ÃœstÃ¼ DoÄŸruluk: 27% â†’ **60-75%** (â†‘ %120-180!) ğŸ¯
- Para KaybÄ± Riski: 20% â†’ **<15%** (â†“ %25)

## ğŸ“ˆ PERFORMANS TAHMÄ°NÄ°

### Mevcut vs Optimize

| Metrik | Mevcut | Optimize | Ä°yileÅŸme |
|--------|--------|----------|----------|
| **Regressor** | | | |
| MAE | 8.19 | 6.5-7.5 | â†“ 10-20% |
| RMSE | 63.71 | 50-55 | â†“ 15-20% |
| EÄŸitim SÃ¼resi | 0.1 dk | 0.3-0.5 dk | 3-5x |
| **Classifier** | | | |
| Genel Acc | 45.28% | 60-70% | â†‘ 30-50% |
| 1.5 AltÄ± Acc | 79.94% | 75-85% | Korundu |
| 1.5 ÃœstÃ¼ Acc | 26.81% | 60-75% | â†‘ 120-180% ğŸ¯ |
| Para KaybÄ± | 20.1% | <15% | â†“ 25% |
| **Sanal Kasa** | | | |
| Kasa 1 ROI | +1.77% | +3-5% | â†‘ 70-180% |
| Kasa 2 ROI | +0.59% | +2-4% | â†‘ 240-580% |

### Neden Bu Kadar Ä°yileÅŸme?

1. **Daha Fazla Iteration:**
   - 500 â†’ 1500 = Model daha fazla pattern Ã¶ÄŸreniyor
   - Erken durdurma 12-51 iteration â†’ 200-400 iteration
   
2. **Daha Derin AÄŸaÃ§lar:**
   - depth 7-8 â†’ 9-10 = Daha karmaÅŸÄ±k feature interactions
   - Non-linear pattern'leri daha iyi yakalar
   
3. **Dengeli Class Weights:**
   - {0: 2.0, 1: 1.0} â†’ {0: 1.5, 1: 1.2}
   - 1.5 Ã¼stÃ¼ de Ã¶ÄŸrenilecek (ÅŸu an ihmal ediliyor!)
   
4. **Regularization:**
   - L2 reg + Subsample = Overfitting Ã¶nleniyor
   - Generalization iyileÅŸiyor

## ğŸš€ UYGULAMA ADIMLARI

### AdÄ±m 1: CatBoost Regressor Optimize Et

```python
# notebooks/jetx_CATBOOST_TRAINING.py

# REGRESSOR OPTIMIZE EDÄ°LMÄ°Å PARAMETRELER
regressor = CatBoostRegressor(
    iterations=1500,           # âœ… 500 â†’ 1500
    depth=10,                  # âœ… 8 â†’ 10
    learning_rate=0.03,        # âœ… 0.05 â†’ 0.03
    l2_leaf_reg=5,             # âœ… YENÄ°
    subsample=0.8,             # âœ… YENÄ°
    loss_function='MAE',
    eval_metric='MAE',
    task_type='GPU',
    verbose=100,
    random_state=42,
    early_stopping_rounds=100  # âœ… 20 â†’ 100
)
```

### AdÄ±m 2: CatBoost Classifier Optimize Et

```python
# CLASS WEIGHTS OPTÄ°MÄ°ZE ET
# SeÃ§enek A: Manuel (hÄ±zlÄ± test)
class_weights = {0: 1.5, 1: 1.2}  # Dengeli

# SeÃ§enek B: Otomatik (Ã¶nerilen)
auto_class_weights = 'Balanced'  # CatBoost otomatik hesaplasÄ±n

# CLASSIFIER OPTIMIZE EDÄ°LMÄ°Å PARAMETRELER
classifier = CatBoostClassifier(
    iterations=1500,           # âœ… 500 â†’ 1500
    depth=9,                   # âœ… 7 â†’ 9
    learning_rate=0.03,        # âœ… 0.05 â†’ 0.03
    l2_leaf_reg=5,             # âœ… YENÄ°
    subsample=0.8,             # âœ… YENÄ°
    loss_function='Logloss',
    eval_metric='Accuracy',
    task_type='GPU',
    auto_class_weights='Balanced',  # âœ… YENÄ° (VEYA class_weights)
    verbose=100,
    random_state=42,
    early_stopping_rounds=100  # âœ… 20 â†’ 100
)
```

### AdÄ±m 3: EÄŸitim ve Ä°zleme

```python
print("ğŸ”¥ CatBoost Regressor eÄŸitimi baÅŸlÄ±yor...")
print(f"ğŸ“Š Optimize Parametreler:")
print(f"  iterations: {regressor.get_params()['iterations']}")
print(f"  depth: {regressor.get_params()['depth']}")
print(f"  learning_rate: {regressor.get_params()['learning_rate']}")
print(f"  l2_leaf_reg: {regressor.get_params()['l2_leaf_reg']}")
print(f"  subsample: {regressor.get_params()['subsample']}")
print()

# EÄŸitim
regressor.fit(
    X_train, y_reg_train,
    eval_set=(X_test, y_reg_test),
    verbose=100,
    plot=False  # Colab'da grafik gÃ¶sterme
)

print(f"\nğŸ“Š Final Iteration: {regressor.get_best_iteration()}")
print(f"ğŸ“Š Final Score: {regressor.get_best_score()}")
```

### AdÄ±m 4: Performans KarÅŸÄ±laÅŸtÄ±rma

```python
# Eski model sonuÃ§larÄ±nÄ± kaydet (karÅŸÄ±laÅŸtÄ±rma iÃ§in)
old_results = {
    'regressor_mae': 8.19,
    'classifier_acc': 0.4528,
    'below_15_acc': 0.7994,
    'above_15_acc': 0.2681
}

# Yeni model sonuÃ§larÄ±
new_results = {
    'regressor_mae': mae_reg,
    'classifier_acc': cls_acc,
    'below_15_acc': below_acc,
    'above_15_acc': above_acc
}

# KarÅŸÄ±laÅŸtÄ±rma raporu
print("\n" + "="*80)
print("ğŸ“Š PERFORMANS KARÅILAÅTIRMASI")
print("="*80)
print(f"{'Metrik':<30} {'Eski':<15} {'Yeni':<15} {'Ä°yileÅŸme':<15}")
print("-"*80)

for metric in ['regressor_mae', 'classifier_acc', 'below_15_acc', 'above_15_acc']:
    old_val = old_results[metric]
    new_val = new_results[metric]
    improvement = ((new_val - old_val) / old_val) * 100
    
    print(f"{metric:<30} {old_val:<15.4f} {new_val:<15.4f} {improvement:+.1f}%")
print("="*80)
```

## ğŸ¯ BEKLENEN SONUÃ‡LAR

### Regressor
```
MAE:  8.19 â†’ 6.5-7.5  (â†“ 10-20%)
RMSE: 63.71 â†’ 50-55   (â†“ 15-20%)

âœ… Daha hassas tahminler
âœ… Outlier'lara daha direnÃ§li
âœ… Generalization iyileÅŸti
```

### Classifier
```
Genel Accuracy: 45% â†’ 60-70%    (â†‘ 30-50%)
1.5 AltÄ± Acc:   80% â†’ 75-85%    (Koruma)
1.5 ÃœstÃ¼ Acc:   27% â†’ 60-75%    (â†‘ 120-180% ğŸ¯)
Para KaybÄ±:     20% â†’ <15%      (â†“ 25%)

âœ… Dengeli tahminler
âœ… 1.5 Ã¼stÃ¼ artÄ±k Ã¶ÄŸreniliyor!
âœ… Para kaybÄ± riski azaldÄ±
```

### Sanal Kasa
```
Kasa 1 (1.5x):
  ROI: +1.77% â†’ +3-5%      (â†‘ 70-180%)
  Kar: +180 TL â†’ +300-500 TL

Kasa 2 (%80):
  ROI: +0.59% â†’ +2-4%      (â†‘ 240-580%)
  Kar: +60 TL â†’ +200-400 TL
  Oyun: 23 â†’ 50-80 oyun    (daha aktif)

âœ… Her iki kasa da daha karlÄ±
âœ… Daha fazla gÃ¼venilir tahmin
```

### EÄŸitim SÃ¼resi
```
Regressor: 0.1 dk â†’ 0.3-0.5 dk  (3-5x artÄ±ÅŸ)
Classifier: 0.1 dk â†’ 0.3-0.5 dk (3-5x artÄ±ÅŸ)

Toplam: ~0.2 dk â†’ ~0.6-1.0 dk  (hala Ã§ok hÄ±zlÄ±!)

âœ… GPU ile hÄ±zlÄ±
âœ… 1 dakika altÄ±nda tamamlanÄ±yor
âœ… Progressive NN'den 2-3x hÄ±zlÄ± kalÄ±yor
```

## ğŸ“‹ KONTROL LÄ°STESÄ°

### Regressor Optimizasyonu
- [ ] iterations: 500 â†’ 1500
- [ ] depth: 8 â†’ 10
- [ ] learning_rate: 0.05 â†’ 0.03
- [ ] l2_leaf_reg: YENÄ° (5)
- [ ] subsample: YENÄ° (0.8)
- [ ] early_stopping_rounds: 20 â†’ 100

### Classifier Optimizasyonu
- [ ] iterations: 500 â†’ 1500
- [ ] depth: 7 â†’ 9
- [ ] learning_rate: 0.05 â†’ 0.03
- [ ] l2_leaf_reg: YENÄ° (5)
- [ ] subsample: YENÄ° (0.8)
- [ ] early_stopping_rounds: 20 â†’ 100
- [ ] class_weights: {0: 2.0, 1: 1.0} â†’ 'Balanced' veya {0: 1.5, 1: 1.2}

### Test & KarÅŸÄ±laÅŸtÄ±rma
- [ ] Performans metrikleri kaydet (eski vs yeni)
- [ ] Feature importance analizi yap
- [ ] Confusion matrix karÅŸÄ±laÅŸtÄ±r
- [ ] Sanal kasa sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±r
- [ ] Model bilgilerini JSON'a kaydet

## ğŸ’¡ EK Ã–NERÄ°LER

### 1. Feature Engineering (Opsiyonel)
```python
# Mevcut feature'lar iyi ama daha fazla eklenebilir
# Ã–rnek: Rolling window statistics
fe = FeatureEngineering.extract_all_features(hist)

# YENÄ° Ã¶zellikler:
fe['volatility_ratio_10_50'] = fe['volatility_10'] / fe['volatility_50']
fe['trend_consistency'] = fe['trend_strength_short_25'] * fe['trend_strength_medium_50']
fe['recent_vs_long_term'] = fe['mean_change_10'] / fe['mean_change_100']
```

### 2. Cross-Validation (Daha Robust)
```python
from catboost import cv, Pool

# 5-Fold CV ile daha gÃ¼venilir metrikler
train_pool = Pool(X_train, y_cls_train)

cv_results = cv(
    train_pool,
    classifier.get_params(),
    fold_count=5,
    shuffle=True,
    partition_random_seed=42,
    verbose=100
)

print(f"CV Mean Accuracy: {cv_results['test-Accuracy-mean'].iloc[-1]:.4f}")
print(f"CV Std: {cv_results['test-Accuracy-std'].iloc[-1]:.4f}")
```

### 3. Model Ensemble (Maksimum Performans)
```python
# Birden fazla CatBoost modeli eÄŸit, ensemble et
models = []
for seed in [42, 123, 456, 789]:
    model = CatBoostClassifier(..., random_state=seed)
    model.fit(X_train, y_train)
    models.append(model)

# Voting ensemble
predictions = np.mean([m.predict_proba(X_test) for m in models], axis=0)
```

## ğŸ‰ SONUÃ‡

### Ã–nerilen Ã‡Ã¶zÃ¼m (En Ä°yi Performans/SÃ¼re OranÄ±)
```python
# 1. Iterations: 500 â†’ 1500
# 2. Depth: 8/7 â†’ 10/9
# 3. Learning Rate: 0.05 â†’ 0.03
# 4. L2 Regularization: 5
# 5. Subsample: 0.8
# 6. Early Stopping: 20 â†’ 100
# 7. Auto Class Weights: 'Balanced'
```

### Beklenen SonuÃ§lar
- **Regressor:** %10-20 iyileÅŸme
- **Classifier:** %30-50 iyileÅŸme (Ã¶zellikle 1.5 Ã¼stÃ¼!)
- **EÄŸitim SÃ¼resi:** 0.2 dk â†’ 1 dk (hala Ã§ok hÄ±zlÄ±!)
- **Sanal Kasa:** ROI %70-580 artÄ±ÅŸ
- **Para KaybÄ± Riski:** 20% â†’ <15%

### Ne Zaman KullanÄ±lmalÄ±?
- âœ… HÄ±zlÄ± prototipleme (1 dakika altÄ±nda!)
- âœ… Production deployment (hafif model)
- âœ… Feature importance analizi
- âœ… Baseline model olarak

### Progressive NN ile KarÅŸÄ±laÅŸtÄ±rma
| Ã–zellik | CatBoost | Progressive NN |
|---------|----------|----------------|
| EÄŸitim SÃ¼resi | 1 dk | 2-3 saat |
| Bellek | <2 GB | 8-14 GB |
| Performans | Ä°yi | Ã‡ok Ä°yi |
| Feature Importance | âœ… Var | âŒ Yok |
| Deployment | âœ… Kolay | âš ï¸ AÄŸÄ±r |

**Ã–nerim:** Her ikisini de eÄŸit, ensemble kullan! ğŸš€