{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ JetX Predictor - ModÃ¼ler EÄŸitim Orkestrasyonu (v6.0 - T4 GPU)\n",
    "\n",
    "Bu notebook, JetX modellerini **tek tek** veya **hepsini bir arada** eÄŸitmenize olanak tanÄ±r.\n",
    "Google Colab T4 GPU ortamÄ± iÃ§in optimize edilmiÅŸtir.\n",
    "\n",
    "### ğŸ“‹ Ã–zellikler:\n",
    "- **ParÃ§alÄ± EÄŸitim:** Ä°stediÄŸiniz modeli seÃ§ip sadece onu eÄŸitebilirsiniz.\n",
    "- **AnÄ±nda Ä°ndirme:** Her eÄŸitim bitiminde model dosyalarÄ± otomatik iner.\n",
    "- **T4 Optimizasyonu:** BÃ¼yÃ¼k batch size ve mixed precision ayarlarÄ±.\n",
    "\n",
    "### ğŸ› ï¸ NasÄ±l KullanÄ±lÄ±r:\n",
    "1. **HÃ¼cre 2 (Kontrol Paneli)**'den eÄŸitmek istediÄŸiniz modelleri `True` yapÄ±n.\n",
    "2. **HÃ¼cre 1** ve **HÃ¼cre 3**'Ã¼ Ã§alÄ±ÅŸtÄ±rarak ortamÄ± hazÄ±rlayÄ±n.\n",
    "3. Ä°lgili modelin hÃ¼cresini Ã§alÄ±ÅŸtÄ±rÄ±n.\n",
    "\n",
    "ğŸ’¾ **Yedekleme:** Dosyalar `/content/drive/MyDrive/JetX_Models_Backup_v6/` klasÃ¶rÃ¼ne de yedeklenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ HÃœCRE 1: ROBUST ORTAM KURULUMU VE YARDIMCI FONKSÄ°YONLAR\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ JetX Predictor v6.0 - Environment Setup\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Google Drive BaÄŸlantÄ±sÄ±\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    from google.colab import files\n",
    "    drive.mount('/content/drive')\n",
    "    BACKUP_DIR = '/content/drive/MyDrive/JetX_Models_Backup_v6'\n",
    "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "    print(f\"âœ… Google Drive baÄŸlandÄ±. Yedekleme: {BACKUP_DIR}\")\n",
    "except:\n",
    "    BACKUP_DIR = None\n",
    "    print(\"âš ï¸ Google Drive baÄŸlanamadÄ±. Sadece lokal indirme yapÄ±lacak.\")\n",
    "\n",
    "# 2. Paket KurulumlarÄ±\n",
    "print(\"\\nğŸ“¦ GEREKLÄ° PAKETLER KURULUYOR...\")\n",
    "install_order = [\n",
    "    ['numpy', 'pandas', 'scikit-learn', 'joblib', 'scipy'],\n",
    "    ['tensorflow', 'torch'],\n",
    "    ['catboost', 'xgboost', 'lightgbm', 'autogluon', 'pytorch-tabnet'],\n",
    "    ['optuna', 'shap', 'nolds', 'PyWavelets'],\n",
    "    ['matplotlib', 'seaborn', 'tqdm', 'pyyaml']\n",
    "]\n",
    "for packages in install_order:\n",
    "    try:\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '-q'] + packages, check=False)\n",
    "    except: pass\n",
    "print(\"âœ… Paketler hazÄ±r.\")\n",
    "\n",
    "# 3. Proje Ã‡ekme\n",
    "PROJECT_ROOT = '/content/jetxpredictor'\n",
    "if not os.path.exists(PROJECT_ROOT):\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/onndd/jetxpredictor.git'], check=True)\n",
    "else:\n",
    "    # GÃ¼ncel kodu Ã§ek\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    subprocess.run(['git', 'pull'], check=False)\n",
    "\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"âœ… Proje dizini: {os.getcwd()}\")\n",
    "\n",
    "# 4. Ä°NDÄ°RME VE YEDEKLEME FONKSÄ°YONU (KRÄ°TÄ°K)\n",
    "def backup_and_download(file_path, description=\"Dosya\"):\n",
    "    \"\"\"DosyayÄ± Drive'a yedekler ve tarayÄ±cÄ±dan indirir\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ {description} bulunamadÄ±: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    # Drive'a kopyala\n",
    "    if BACKUP_DIR:\n",
    "        try:\n",
    "            # EÄŸer klasÃ¶rse zip'le\n",
    "            if os.path.isdir(file_path):\n",
    "                zip_name = f\"{file_path}.zip\"\n",
    "                if not os.path.exists(zip_name):\n",
    "                     shutil.make_archive(file_path, 'zip', file_path)\n",
    "                file_to_copy = zip_name\n",
    "            else:\n",
    "                file_to_copy = file_path\n",
    "                \n",
    "            dest = os.path.join(BACKUP_DIR, os.path.basename(file_to_copy))\n",
    "            shutil.copy(file_to_copy, dest)\n",
    "            print(f\"ğŸ’¾ Drive'a yedeklendi: {dest}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Drive yedekleme hatasÄ±: {e}\")\n",
    "    \n",
    "    # Ä°ndir\n",
    "    try:\n",
    "        if os.path.isdir(file_path):\n",
    "            # KlasÃ¶rse ziplediÄŸimizi indir\n",
    "            if not os.path.exists(f\"{file_path}.zip\"):\n",
    "                shutil.make_archive(file_path, 'zip', file_path)\n",
    "            files.download(f\"{file_path}.zip\")\n",
    "        else:\n",
    "            files.download(file_path)\n",
    "        print(f\"â¬‡ï¸ {description} indiriliyor...\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Ä°ndirme hatasÄ±: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ›ï¸ HÃœCRE 2: KONTROL PANELÄ° (BURAYI DÃœZENLEYÄ°N)\n",
    "# Hangi modeli eÄŸitmek istiyorsanÄ±z onu True yapÄ±n.\n",
    "\n",
    "# ğŸš€ MODEL SEÃ‡Ä°MÄ° (Tek tek True yapabilirsiniz)\n",
    "TRAIN_PROGRESSIVE = True     # 1. Ana Model (NN Transformer - En Ã–nemli)\n",
    "TRAIN_ULTRA = False          # 2. Ultra Aggressive\n",
    "TRAIN_CATBOOST = False       # 3. CatBoost Ensemble\n",
    "TRAIN_AUTOGLUON = False      # 4. AutoGluon\n",
    "TRAIN_TABNET = False         # 5. TabNet\n",
    "TRAIN_RL_AGENT = False       # 6. RL Agent\n",
    "TRAIN_META_MODEL = False     # 7. Meta Model\n",
    "\n",
    "# âš¡ AYARLAR\n",
    "QUICK_TEST_MODE = False  # HÄ±zlÄ± test iÃ§in True yapÄ±n\n",
    "MODELS_DIR = 'models'\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# ğŸ“Š EÄÄ°TÄ°M KONFIGURASYONU (T4 GPU OPTIMIZE)\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 5 if QUICK_TEST_MODE else 100,\n",
    "    'catboost_iterations': 100 if QUICK_TEST_MODE else 1500,\n",
    "    'autogluon_time': 60 if QUICK_TEST_MODE else 3600,\n",
    "    # T4 GPU 16GB VRAM olduÄŸu iÃ§in batch size'Ä± artÄ±rÄ±yoruz\n",
    "    'batch_size': 16 if QUICK_TEST_MODE else 256 \n",
    "}\n",
    "\n",
    "print(f\"âš¡ QUICK_TEST_MODE: {QUICK_TEST_MODE}\")\n",
    "print(f\"ğŸ”§ BATCH SIZE: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"ğŸ¯ SEÃ‡Ä°LEN MODELLER:\")\n",
    "if TRAIN_PROGRESSIVE: print(\"  - Progressive Transformer\")\n",
    "if TRAIN_ULTRA: print(\"  - Ultra Aggressive\")\n",
    "if TRAIN_CATBOOST: print(\"  - CatBoost Ensemble\")\n",
    "if TRAIN_AUTOGLUON: print(\"  - AutoGluon\")\n",
    "if TRAIN_TABNET: print(\"  - TabNet\")\n",
    "if TRAIN_RL_AGENT: print(\"  - RL Agent\")\n",
    "if TRAIN_META_MODEL: print(\"  - Meta Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š HÃœCRE 3: VERÄ° HAZIRLIÄI\n",
    "# VeritabanÄ± kontrolÃ¼ ve hazÄ±rlÄ±ÄŸÄ±\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ“Š Veri kontrol ediliyor...\")\n",
    "db_path = 'jetx_data.db'\n",
    "\n",
    "# Sentetik veri oluÅŸturucu (EÄŸer gerÃ§ek veri yoksa)\n",
    "if not os.path.exists(db_path):\n",
    "    print(\"âš ï¸ VeritabanÄ± yok. Sentetik veri oluÅŸturuluyor (EÄŸitim iÃ§in)...\")\n",
    "    values = np.random.lognormal(0.5, 0.8, 3000)\n",
    "    values = np.clip(values, 1.0, 100.0)\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE IF NOT EXISTS jetx_results (id INTEGER PRIMARY KEY AUTOINCREMENT, value REAL, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)\")\n",
    "    for val in values:\n",
    "        cursor.execute(\"INSERT INTO jetx_results (value) VALUES (?)\", (val,))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"âœ… {len(values)} adet sentetik veri oluÅŸturuldu.\")\n",
    "else:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query(\"SELECT value FROM jetx_results\", conn)\n",
    "    conn.close()\n",
    "    print(f\"âœ… {len(df)} adet veri yÃ¼klendi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  HÃœCRE 4: PROGRESSIVE TRANSFORMER EÄÄ°TÄ°MÄ° (MONOLITHIC)\n",
    "# En Ã¶nemli model. N-Beats, TCN ve Transformer iÃ§erir.\n",
    "\n",
    "if TRAIN_PROGRESSIVE:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ§  PROGRESSIVE TRANSFORMER EÄÄ°TÄ°MÄ° BAÅLIYOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        subprocess.run([sys.executable, 'notebooks/jetx_PROGRESSIVE_TRAINING.py'], check=True)\n",
    "        \n",
    "        # Ã‡Ä±ktÄ±larÄ± yedekle ve indir\n",
    "        backup_and_download('models/jetx_progressive_final.h5', 'Progressive Model (Final)')\n",
    "        \n",
    "        # Transformer kopyasÄ±nÄ± da al (sistem bunu arÄ±yor olabilir)\n",
    "        if os.path.exists('models/jetx_progressive_final.h5'):\n",
    "            import shutil\n",
    "            shutil.copy('models/jetx_progressive_final.h5', 'models/jetx_progressive_transformer.h5')\n",
    "            backup_and_download('models/jetx_progressive_transformer.h5', 'Transformer Model (Copy)')\n",
    "            \n",
    "        backup_and_download('models/scaler_progressive.pkl', 'Progressive Scaler')\n",
    "        backup_and_download('models/model_info.json', 'Model Info')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ HATA: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ Progressive eÄŸitimi atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš¡ HÃœCRE 5: ULTRA AGGRESSIVE MODEL EÄÄ°TÄ°MÄ°\n",
    "\n",
    "if TRAIN_ULTRA:\n",
    "    print(\"\\nâš¡ ULTRA AGGRESSIVE MODEL EÄÄ°TÄ°LÄ°YOR...\")\n",
    "    try:\n",
    "        subprocess.run([sys.executable, 'notebooks/jetx_model_training_ULTRA_AGGRESSIVE.py'], check=True)\n",
    "        \n",
    "        backup_and_download('models/jetx_ultra_model.h5', 'Ultra Model')\n",
    "        backup_and_download('models/scaler_ultra.pkl', 'Ultra Scaler')\n",
    "        backup_and_download('ultra_model_info.json', 'Ultra Info')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ HATA: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ Ultra atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ HÃœCRE 6: CATBOOST ENSEMBLE EÄÄ°TÄ°MÄ°\n",
    "\n",
    "if TRAIN_CATBOOST:\n",
    "    print(\"\\nğŸš€ CATBOOST ENSEMBLE EÄÄ°TÄ°LÄ°YOR...\")\n",
    "    try:\n",
    "        subprocess.run([sys.executable, 'notebooks/jetx_CATBOOST_TRAINING_MULTISCALE.py'], check=True)\n",
    "        \n",
    "        # KlasÃ¶rÃ¼ zipleyip indir\n",
    "        backup_and_download('models/catboost_multiscale', 'CatBoost Models (Folder)')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ HATA: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ CatBoost atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– HÃœCRE 7: AUTOGLUON EÄÄ°TÄ°MÄ°\n",
    "\n",
    "if TRAIN_AUTOGLUON:\n",
    "    print(\"\\nğŸ¤– AUTOGLUON EÄÄ°TÄ°LÄ°YOR...\")\n",
    "    try:\n",
    "        # AutoGluon kodunu burada simÃ¼le ediyoruz (Gerekirse script'e taÅŸÄ±yÄ±n)\n",
    "        from utils.autogluon_predictor import AutoGluonPredictor\n",
    "        from utils.database import DatabaseManager\n",
    "        from category_definitions import FeatureEngineering\n",
    "        \n",
    "        db = DatabaseManager('jetx_data.db')\n",
    "        data = db.get_all_results()\n",
    "        \n",
    "        if len(data) > 500:\n",
    "            X, y = [], []\n",
    "            limit = min(len(data), 3000)\n",
    "            for i in range(500, limit):\n",
    "                 hist = data[i-500:i]\n",
    "                 target = data[i]\n",
    "                 feats = FeatureEngineering.extract_all_features(hist)\n",
    "                 X.append(list(feats.values()))\n",
    "                 y.append(1 if target >= 1.5 else 0)\n",
    "            \n",
    "            X_df = pd.DataFrame(X)\n",
    "            y_series = pd.Series(y)\n",
    "            \n",
    "            print(f\"ğŸš€ AutoGluon eÄŸitiliyor (SÃ¼re limiti: {TRAINING_CONFIG['autogluon_time']}s)...\")\n",
    "            predictor = AutoGluonPredictor()\n",
    "            predictor.train(X_df, y_series, time_limit=TRAINING_CONFIG['autogluon_time'])\n",
    "            \n",
    "            # Ä°ndir\n",
    "            backup_and_download('models/autogluon_model', 'AutoGluon Model (Folder)')\n",
    "            backup_and_download('models/autogluon_scaler.pkl', 'AutoGluon Scaler')\n",
    "        else:\n",
    "            print(\"âš ï¸ Yetersiz veri.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ HATA: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ AutoGluon atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ HÃœCRE 8: TABNET EÄÄ°TÄ°MÄ°\n",
    "\n",
    "if TRAIN_TABNET:\n",
    "    print(\"\\nğŸ¯ TABNET EÄÄ°TÄ°LÄ°YOR...\")\n",
    "    # TabNet eÄŸitim kodunu buraya entegre edin veya utils/tabnet_predictor.py kullanÄ±n\n",
    "    # Basitlik iÃ§in placeholder, script varsa subprocess ile Ã§aÄŸÄ±rÄ±n\n",
    "    print(\"â„¹ï¸ TabNet eÄŸitimi utils Ã¼zerinden Ã§alÄ±ÅŸtÄ±rÄ±labilir.\")\n",
    "    # backup_and_download('models/tabnet_high_x.pkl', 'TabNet Model')\n",
    "else:\n",
    "    print(\"â­ï¸ TabNet atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– HÃœCRE 9: RL AGENT EÄÄ°TÄ°MÄ°\n",
    "\n",
    "if TRAIN_RL_AGENT:\n",
    "    print(\"\\nğŸ¤– RL AGENT EÄÄ°TÄ°LÄ°YOR...\")\n",
    "    try:\n",
    "        subprocess.run([sys.executable, 'notebooks/train_rl_agent.py'], check=True)\n",
    "        backup_and_download('models/rl_agent_model.h5', 'RL Model')\n",
    "        backup_and_download('models/rl_agent_info.json', 'RL Info')\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ HATA: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ RL Agent atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ† HÃœCRE 10: META-MODEL EÄÄ°TÄ°MÄ°\n",
    "\n",
    "if TRAIN_META_MODEL:\n",
    "    print(\"\\nğŸ† META-MODEL EÄÄ°TÄ°LÄ°YOR...\")\n",
    "    try:\n",
    "        subprocess.run([sys.executable, 'notebooks/TRAIN_META_MODEL.py'], check=True)\n",
    "        backup_and_download('models/meta_model.json', 'Meta Model')\n",
    "        backup_and_download('models/meta_model_info.json', 'Meta Info')\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ HATA: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ Meta-Model atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ HÃœCRE 11: TOPLU PAKETLEME VE Ä°NDÄ°RME (Opsiyonel)\n",
    "# EÄŸer yukarÄ±da tek tek indirdiyseniz buna gerek kalmayabilir\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“¦ TOPLU PAKETLEME VE Ä°NDÄ°RME\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "zip_filename = f'JetX_FULL_ARMY_v6.0_{timestamp}.zip'\n",
    "\n",
    "# DosyalarÄ± topla\n",
    "files_to_zip = [\n",
    "    'models/jetx_progressive_transformer.h5',\n",
    "    'models/scaler_progressive.pkl',\n",
    "    'models/jetx_ultra_model.h5',\n",
    "    'models/scaler_ultra.pkl',\n",
    "    'models/meta_model.json',\n",
    "    'models/meta_model_info.json',\n",
    "    'models/rl_agent_model.h5',\n",
    "    'models/rl_agent_info.json',\n",
    "    'models/autogluon_model', # KlasÃ¶r\n",
    "    'models/autogluon_scaler.pkl',\n",
    "    'models/tabnet_high_x.pkl',\n",
    "    'models/tabnet_scaler.pkl',\n",
    "    'models/catboost_multiscale' # KlasÃ¶r\n",
    "]\n",
    "\n",
    "print(\"Dosyalar sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±yor...\")\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for item in files_to_zip:\n",
    "        if os.path.exists(item):\n",
    "            if os.path.isdir(item):\n",
    "                for root, dirs, files in os.walk(item):\n",
    "                    for file in files:\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        arcname = os.path.relpath(file_path, os.path.join(item, '..'))\n",
    "                        zipf.write(file_path, arcname)\n",
    "            else:\n",
    "                zipf.write(item, os.path.basename(item))\n",
    "            print(f\"  Adding: {item}\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ BulunamadÄ±: {item}\")\n",
    "\n",
    "backup_and_download(zip_filename, 'TOPLU ZIP DOSYASI')\n",
    "\n",
    "print(\"\\nğŸ‰ TÃœM Ä°ÅLEMLER TAMAMLANDI!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
