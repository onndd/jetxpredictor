{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ JetX Predictor - 5 Model Ensemble Orkestrasyon (v5.0 ULTIMATE)\n",
    "\n",
    "Bu notebook, JetX projesinin **2 Modlu (Normal/Rolling)** sistemine uygun TÃœM modelleri sÄ±rasÄ±yla eÄŸiten, Meta-Model ile birleÅŸtiren ve sonuÃ§larÄ± Google Drive'a yedekleyen tam otomatize bir **Orkestrasyon DosyasÄ±dÄ±r**.\n",
    "\n",
    "### ğŸ“‹ Sistem Mimarisi:\n",
    "1. **Progressive Transformer** (Monolitik Script)\n",
    "   - *Mimari:* N-Beats + TCN + Transformer (Attention)\n",
    "   - *Girdi:* 1000'lik zaman serisi\n",
    "2. **Ultra Aggressive Model** (Monolitik Script)\n",
    "   - *Mimari:* DerinleÅŸtirilmiÅŸ Hybrid NN\n",
    "   - *Ã–zellik:* Para kaybÄ± odaklÄ± 'Threshold Killer' loss\n",
    "3. **CatBoost Ensemble**\n",
    "   - *YapÄ±:* Multi-scale Gradient Boosting\n",
    "4. **AutoGluon AutoML**\n",
    "   - *YapÄ±:* 50+ model otomatik seÃ§im\n",
    "5. **TabNet Specialist**\n",
    "   - *YapÄ±:* Attention-based tabular learning\n",
    "6. **Meta-Model (Stacking)**\n",
    "   - *GÃ¶revi:* TÃ¼m modellerin kararlarÄ±nÄ± 0.85 ve 0.95 eÅŸiklerine gÃ¶re birleÅŸtirir.\n",
    "\n",
    "### âš¡ Ã–zellikler:\n",
    "- âœ… **2 Modlu YapÄ±:** Normal (%85) ve Rolling (%95) iÃ§in optimize edildi\n",
    "- âœ… **Monolitik Scriptler:** Tek dosya eÄŸitim (Dependency free)\n",
    "- âœ… **Google Drive Entegrasyonu:** Otomatik yedekleme\n",
    "- âœ… **Threshold Manager:** Merkezi eÅŸik yÃ¶netimi\n",
    "\n",
    "**Toplam SÃ¼re**: ~4-6 saat (GPU ile)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ¯ KULLANIM:**\n",
    "1. Bu notebook'u Google Colab'da aÃ§Ä±n\n",
    "2. Runtime â†’ Change runtime type â†’ GPU (T4 Ã¶nerilir)\n",
    "3. HÃ¼creleri sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n (Cell â†’ Run All)\n",
    "4. `JetX_FULL_ARMY_v5.0.zip` dosyasÄ± otomatik indirilecektir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ HÃœCRE 1: ROBUST ORTAM KURULUMU\n",
    "# Gerekli kÃ¼tÃ¼phaneleri kur ve projeyi hazÄ±rla\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ JetX Predictor v5.0 - Environment Setup\")\n",
    "print(\"=\"*80)\n",
    "print(f\"BaÅŸlangÄ±Ã§: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Google Drive mount\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"âœ… Google Drive baÅŸarÄ±yla baÄŸlandÄ±\")\n",
    "    \n",
    "    # Backup dizini oluÅŸtur\n",
    "    backup_dir = '/content/drive/MyDrive/JetX_Models_Backup_v5'\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    print(f\"âœ… Backup dizini hazÄ±r: {backup_dir}\")\n",
    "except:\n",
    "    print(\"âš ï¸ Google Colab dÄ±ÅŸÄ±nda Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor veya Drive baÄŸlanamadÄ±\")\n",
    "\n",
    "print(\"\\nğŸ“¦ GEREKLÄ° PAKETLER KURULUYOR... (Bu iÅŸlem birkaÃ§ dakika sÃ¼rebilir)\")\n",
    "\n",
    "install_order = [\n",
    "    # Temel Veri Ä°ÅŸleme\n",
    "    ['numpy', 'pandas', 'scikit-learn', 'joblib', 'scipy'],\n",
    "    # Deep Learning Frameworks\n",
    "    ['tensorflow', 'torch'],\n",
    "    # Boosting & AutoML\n",
    "    ['catboost', 'xgboost', 'lightgbm', 'autogluon', 'pytorch-tabnet'],\n",
    "    # Optimizasyon & Ä°statistiksel Analiz\n",
    "    ['optuna', 'shap', 'nolds', 'PyWavelets'],\n",
    "    # GÃ¶rselleÅŸtirme & AraÃ§lar\n",
    "    ['matplotlib', 'seaborn', 'tqdm', 'pyyaml']\n",
    "]\n",
    "\n",
    "for i, packages in enumerate(install_order, 1):\n",
    "    print(f\"\\nğŸ“¦ Grup {i}/{len(install_order)}: {', '.join(packages)}\")\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', package], check=False)\n",
    "            print(f\"  âœ… {package}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ {package} kurulum hatasÄ±: {e}\")\n",
    "\n",
    "print(\"\\nğŸ“¥ PROJE KURULUMU...\")\n",
    "PROJECT_ROOT = '/content/jetxpredictor'\n",
    "\n",
    "if os.path.exists(PROJECT_ROOT):\n",
    "    print(f\"âœ… Proje dizini mevcut: {PROJECT_ROOT}\")\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    print(\"ğŸ”„ GÃ¼ncel kodlar Ã§ekiliyor...\")\n",
    "    subprocess.run(['git', 'pull'], check=False)\n",
    "else:\n",
    "    print(f\"ğŸ“¥ Proje GitHub'dan Ã§ekiliyor...\")\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/onndd/jetxpredictor.git'], check=True)\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    print(f\"âœ… Proje klonlandÄ±\")\n",
    "\n",
    "# Python path'e ekle\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"\\nâœ… ORTAM HAZIR!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ›ï¸ HÃœCRE 2: KONTROL PANELÄ°\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ›ï¸ JETX TRAINING CONFIG (v5.0)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ğŸš€ MODEL EÄÄ°TÄ°M BAYRAKLARI\n",
    "# Hangi modellerin eÄŸitileceÄŸini buradan seÃ§ebilirsiniz\n",
    "TRAIN_PROGRESSIVE = True    # Monolitik Progressive Transformer (En Ã–nemli)\n",
    "TRAIN_ULTRA = True          # Ultra Aggressive Model\n",
    "TRAIN_CATBOOST = True       # CatBoost Ensemble\n",
    "TRAIN_AUTOGLUON = True      # AutoGluon AutoML\n",
    "TRAIN_TABNET = True         # TabNet Specialist\n",
    "TRAIN_META_MODEL = True     # Stacking Meta-Model\n",
    "\n",
    "# âš¡ HIZLI TEST MODU\n",
    "# True: Epoch sayÄ±larÄ±nÄ± dÃ¼ÅŸÃ¼rÃ¼r (Test iÃ§in)\n",
    "# False: Tam eÄŸitim yapar (Production iÃ§in)\n",
    "QUICK_TEST_MODE = False\n",
    "\n",
    "# ğŸ“Š EÄÄ°TÄ°M PARAMETRELERÄ°\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 5 if QUICK_TEST_MODE else 100,\n",
    "    'catboost_iterations': 100 if QUICK_TEST_MODE else 1500,\n",
    "    'autogluon_time': 60 if QUICK_TEST_MODE else 3600,\n",
    "    'batch_size': 16 if QUICK_TEST_MODE else 32\n",
    "}\n",
    "\n",
    "MODELS_DIR = 'models'\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"âš¡ QUICK_TEST_MODE: {QUICK_TEST_MODE}\")\n",
    "print(f\"ğŸ¯ HEDEFLER: Normal >%85, Rolling >%95\")\n",
    "print(f\"ğŸ“ Modeller KlasÃ¶rÃ¼: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š HÃœCRE 3: VERÄ° HAZIRLIÄI VE KONTROLÃœ\n",
    "# VeritabanÄ± yoksa oluÅŸturur, varsa temizler ve hazÄ±rlar\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ“Š Veri kontrol ediliyor...\")\n",
    "db_path = 'jetx_data.db'\n",
    "\n",
    "def create_synthetic_data(num_samples=3000):\n",
    "    \"\"\"EÄŸer veri yoksa eÄŸitim iÃ§in sentetik veri oluÅŸturur\"\"\"\n",
    "    print(f\"âš ï¸ VeritabanÄ± bulunamadÄ±. {num_samples} adet sentetik veri oluÅŸturuluyor...\")\n",
    "    # Log-normal daÄŸÄ±lÄ±m (JetX benzeri)\n",
    "    values = np.random.lognormal(0.5, 0.8, num_samples)\n",
    "    values = np.clip(values, 1.0, 100.0)\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE IF NOT EXISTS jetx_results (id INTEGER PRIMARY KEY AUTOINCREMENT, value REAL, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)\")\n",
    "    \n",
    "    for val in values:\n",
    "        cursor.execute(\"INSERT INTO jetx_results (value) VALUES (?)\", (val,))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"âœ… Sentetik veri oluÅŸturuldu ve kaydedildi.\")\n",
    "\n",
    "if not os.path.exists(db_path):\n",
    "    create_synthetic_data()\n",
    "else:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    # Tablo var mÄ± kontrol et\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='jetx_results'\")\n",
    "    if not cursor.fetchone():\n",
    "        create_synthetic_data()\n",
    "    else:\n",
    "        df = pd.read_sql_query(\"SELECT value FROM jetx_results\", conn)\n",
    "        if len(df) < 100:\n",
    "            create_synthetic_data()\n",
    "        else:\n",
    "            print(f\"âœ… {len(df)} adet gerÃ§ek veri bulundu.\")\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  HÃœCRE 4: PROGRESSIVE TRANSFORMER EÄÄ°TÄ°MÄ° (MONOLITHIC)\n",
    "# Bu, sistemin ana modelidir. N-Beats, TCN ve Transformer katmanlarÄ±nÄ± iÃ§erir.\n",
    "\n",
    "if TRAIN_PROGRESSIVE:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ§  PROGRESSIVE TRANSFORMER EÄÄ°TÄ°MÄ° BAÅLIYOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Monolitik scripti Ã§alÄ±ÅŸtÄ±r\n",
    "        # Script kendi iÃ§inde her ÅŸeyi halleder (Feature eng, Model build, Train, Save)\n",
    "        # Standalone Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in dÄ±ÅŸarÄ±dan import hatasÄ± vermez\n",
    "        subprocess.run([sys.executable, 'notebooks/jetx_PROGRESSIVE_TRAINING.py'], check=True)\n",
    "        print(\"âœ… Progressive Transformer eÄŸitimi baÅŸarÄ±yla tamamlandÄ±.\")\n",
    "        \n",
    "        # Kontrol\n",
    "        if os.path.exists('models/jetx_progressive_final.h5'):\n",
    "            print(\"ğŸ’¾ Model dosyasÄ± doÄŸrulandÄ±: models/jetx_progressive_final.h5\")\n",
    "            # DiÄŸer scriptler iÃ§in kopyala\n",
    "            import shutil\n",
    "            shutil.copy('models/jetx_progressive_final.h5', 'models/jetx_progressive_transformer.h5')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ EÄÄ°TÄ°M HATASI (Progressive): Script hata kodu ile dÃ¶ndÃ¼: {e.returncode}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ BEKLENMEYEN HATA: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ Progressive eÄŸitimi atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš¡ HÃœCRE 5: ULTRA AGGRESSIVE MODEL EÄÄ°TÄ°MÄ° (MONOLITHIC)\n",
    "# Para kaybÄ±nÄ± minimize etmeye odaklanan Ã¶zel model.\n",
    "\n",
    "if TRAIN_ULTRA:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âš¡ ULTRA AGGRESSIVE MODEL EÄÄ°TÄ°MÄ° BAÅLIYOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        subprocess.run([sys.executable, 'notebooks/jetx_model_training_ULTRA_AGGRESSIVE.py'], check=True)\n",
    "        print(\"âœ… Ultra Aggressive model eÄŸitimi baÅŸarÄ±yla tamamlandÄ±.\")\n",
    "        \n",
    "        if os.path.exists('models/jetx_ultra_model.h5'):\n",
    "            print(\"ğŸ’¾ Model dosyasÄ± doÄŸrulandÄ±: models/jetx_ultra_model.h5\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ EÄÄ°TÄ°M HATASI (Ultra): Script hata kodu ile dÃ¶ndÃ¼: {e.returncode}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ BEKLENMEYEN HATA: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ Ultra Aggressive eÄŸitimi atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ HÃœCRE 6: CATBOOST ENSEMBLE EÄÄ°TÄ°MÄ°\n",
    "# Gradient Boosting gÃ¼cÃ¼ ile 10 farklÄ± modelin birleÅŸimi.\n",
    "\n",
    "if TRAIN_CATBOOST:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸš€ CATBOOST ENSEMBLE EÄÄ°TÄ°MÄ° BAÅLIYOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        subprocess.run([sys.executable, 'notebooks/jetx_CATBOOST_TRAINING_MULTISCALE.py'], check=True)\n",
    "        print(\"âœ… CatBoost eÄŸitimi baÅŸarÄ±yla tamamlandÄ±.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ EÄÄ°TÄ°M HATASI (CatBoost): {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ CatBoost eÄŸitimi atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– HÃœCRE 7: AUTOGLUON EÄÄ°TÄ°MÄ°\n",
    "# AutoML ile en iyi modeli otomatik seÃ§er.\n",
    "\n",
    "if TRAIN_AUTOGLUON:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ¤– AUTOGLUON AUTOML EÄÄ°TÄ°MÄ° BAÅLIYOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        from utils.autogluon_predictor import AutoGluonPredictor\n",
    "        from utils.database import DatabaseManager\n",
    "        from category_definitions import FeatureEngineering\n",
    "        \n",
    "        print(\"ğŸ“Š Veri hazÄ±rlanÄ±yor...\")\n",
    "        db = DatabaseManager('jetx_data.db')\n",
    "        data = db.get_all_results()\n",
    "        \n",
    "        # Veri yeterli mi?\n",
    "        if len(data) > 500:\n",
    "            # Feature extraction (Son 2000 veri iÃ§in)\n",
    "            X, y = [], []\n",
    "            # EÄŸitim iÃ§in geÃ§miÅŸ veriyi kullan\n",
    "            limit = min(len(data), 3000)\n",
    "            for i in range(500, limit):\n",
    "                 hist = data[i-500:i]\n",
    "                 target = data[i]\n",
    "                 # Basit feature seti (hÄ±z iÃ§in)\n",
    "                 feats = FeatureEngineering.extract_all_features(hist)\n",
    "                 X.append(list(feats.values()))\n",
    "                 y.append(1 if target >= 1.5 else 0)\n",
    "            \n",
    "            X_df = pd.DataFrame(X)\n",
    "            y_series = pd.Series(y)\n",
    "            \n",
    "            print(f\"ğŸš€ AutoGluon eÄŸitiliyor (SÃ¼re limiti: {TRAINING_CONFIG['autogluon_time']}s)...\")\n",
    "            predictor = AutoGluonPredictor()\n",
    "            predictor.train(X_df, y_series, time_limit=TRAINING_CONFIG['autogluon_time'])\n",
    "            print(\"âœ… AutoGluon eÄŸitimi tamamlandÄ±.\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Yetersiz veri, AutoGluon atlandÄ±.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ AutoGluon Hata: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ AutoGluon eÄŸitimi atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ HÃœCRE 8: TABNET EÄÄ°TÄ°MÄ°\n",
    "\n",
    "if TRAIN_TABNET:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ¯ TABNET SPECIALIST EÄÄ°TÄ°MÄ° BAÅLIYOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        from utils.tabnet_predictor import TabNetHighXPredictor\n",
    "        from utils.database import DatabaseManager\n",
    "        from category_definitions import FeatureEngineering\n",
    "        import joblib\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        print(\"ğŸ“Š Veri hazÄ±rlanÄ±yor...\")\n",
    "        db = DatabaseManager('jetx_data.db')\n",
    "        data = db.get_all_results()\n",
    "        \n",
    "        if len(data) > 500:\n",
    "            X, y = [], []\n",
    "            limit = min(len(data), 3000)\n",
    "            for i in range(500, limit):\n",
    "                 hist = data[i-500:i]\n",
    "                 target = data[i]\n",
    "                 feats = FeatureEngineering.extract_all_features(hist)\n",
    "                 X.append(list(feats.values()))\n",
    "                 # Kategori tahmini (0, 1, 2, 3)\n",
    "                 cat = TabNetHighXPredictor.categorize_value(target)\n",
    "                 y.append(cat)\n",
    "            \n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "            \n",
    "            # Scaling\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            joblib.dump(scaler, 'models/tabnet_scaler.pkl')\n",
    "            \n",
    "            print(\"ğŸš€ TabNet eÄŸitiliyor...\")\n",
    "            predictor = TabNetHighXPredictor()\n",
    "            predictor.train(X_scaled, y, max_epochs=TRAINING_CONFIG['epochs'])\n",
    "            predictor.save_model()\n",
    "            print(\"âœ… TabNet eÄŸitimi tamamlandÄ±.\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Yetersiz veri, TabNet atlandÄ±.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ TabNet Hata: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ TabNet eÄŸitimi atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ† HÃœCRE 9: META-MODEL EÄÄ°TÄ°MÄ° (STACKING)\n",
    "# TÃ¼m modelleri birleÅŸtirip nihai kararÄ± verir.\n",
    "\n",
    "if TRAIN_META_MODEL:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ† META-MODEL EÄÄ°TÄ°MÄ° BAÅLIYOR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # TRAIN_META_MODEL.py dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±r\n",
    "        subprocess.run([sys.executable, 'notebooks/TRAIN_META_MODEL.py'], check=True)\n",
    "        print(\"âœ… Meta-Model eÄŸitimi baÅŸarÄ±yla tamamlandÄ±.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ EÄÄ°TÄ°M HATASI (Meta-Model): {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ BEKLENMEYEN HATA: {e}\")\n",
    "else:\n",
    "    print(\"â­ï¸ Meta-Model eÄŸitimi atlandÄ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ HÃœCRE 10: PAKETLEME VE Ä°NDÄ°RME\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“¦ PAKETLEME VE Ä°NDÄ°RME\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "zip_filename = f'JetX_FULL_ARMY_v5.0_{timestamp}.zip'\n",
    "\n",
    "# DosyalarÄ± topla\n",
    "files_to_zip = [\n",
    "    'models/jetx_progressive_transformer.h5',\n",
    "    'models/jetx_progressive_final.h5', # Yedek\n",
    "    'models/scaler_progressive.pkl',\n",
    "    'models/jetx_ultra_model.h5',\n",
    "    'models/scaler_ultra.pkl',\n",
    "    'models/meta_model.json',\n",
    "    'models/meta_model_info.json',\n",
    "    'models/autogluon_model', # KlasÃ¶r\n",
    "    'models/autogluon_scaler.pkl',\n",
    "    'models/tabnet_high_x.pkl',\n",
    "    'models/tabnet_scaler.pkl',\n",
    "    'models/catboost_multiscale' # KlasÃ¶r\n",
    "]\n",
    "\n",
    "print(\"Dosyalar sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±yor...\")\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for item in files_to_zip:\n",
    "        if os.path.exists(item):\n",
    "            if os.path.isdir(item):\n",
    "                for root, dirs, files in os.walk(item):\n",
    "                    for file in files:\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        arcname = os.path.relpath(file_path, os.path.join(item, '..'))\n",
    "                        zipf.write(file_path, arcname)\n",
    "            else:\n",
    "                zipf.write(item, os.path.basename(item))\n",
    "            print(f\"  Adding: {item}\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ BulunamadÄ±: {item}\")\n",
    "\n",
    "# Google Drive'a kopyala\n",
    "try:\n",
    "    if os.path.exists('/content/drive'):\n",
    "        backup_path = f'/content/drive/MyDrive/JetX_Models_Backup_v5/{zip_filename}'\n",
    "        shutil.copy(zip_filename, backup_path)\n",
    "        print(f\"\\nâœ… Google Drive'a yedeklendi: {backup_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Drive yedekleme hatasÄ±: {e}\")\n",
    "\n",
    "# Ä°ndirme\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(zip_filename)\n",
    "    print(\"\\nâ¬‡ï¸ Ä°ndirme baÅŸlatÄ±ldÄ±...\")\n",
    "except:\n",
    "    print(f\"\\nâš ï¸ Otomatik indirme baÅŸarÄ±sÄ±z. Dosya yolu: {os.path.abspath(zip_filename)}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Ä°ÅLEM TAMAMLANDI!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
