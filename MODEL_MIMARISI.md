# JetX Predictor - Model Mimarisi ve Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±

Bu dokÃ¼mantasyon, JetX Predictor projesinde kullanÄ±lan hibrit N-BEATS + TCN modelinin detaylÄ± mimari aÃ§Ä±klamasÄ±nÄ± iÃ§erir.

## ğŸ“‹ Ä°Ã§indekiler

1. [Veri HazÄ±rlÄ±k KatmanÄ±](#1-veri-hazirlik-katmani)
2. [N-BEATS ModÃ¼lÃ¼](#2-n-beats-modÃ¼lÃ¼)
3. [TCN ModÃ¼lÃ¼](#3-tcn-modÃ¼lÃ¼)
4. [Attention MekanizmasÄ±](#4-attention-mekanizmasi)
5. [Psikolojik Analiz Motoru](#5-psikolojik-analiz-motoru)
6. [Ensemble Fusion KatmanÄ±](#6-ensemble-fusion-katmani)
7. [Training Loop](#7-training-loop-mantigi)
8. [Inference AÅŸamasÄ±](#8-inference-tahmin-aÅŸamasi)
9. [Model Optimizasyon](#9-model-optimizasyon-teknikleri)
10. [Rolling Mod Adaptasyonu](#10-rolling-mod-iÃ§in-Ã¶zel-adaptasyon)

---

## 1. VERÄ° HAZIRLIK KATMANI

### Input Pipeline YapÄ±sÄ±

Veri hazÄ±rlÄ±k aÅŸamasÄ± Ã¼Ã§ paralel akÄ±ÅŸtan oluÅŸur:

#### 1.1 Ham Veri AkÄ±ÅŸÄ±

- SQLite'tan Ã§ekilen 7000 deÄŸer bir array'e yÃ¼klenir
- Her tahmin iÃ§in son 1000 deÄŸer "sliding window" mantÄ±ÄŸÄ±yla alÄ±nÄ±r
- Ã–rneÄŸin 3500. deÄŸeri tahmin ederken, 2500-3499 arasÄ± deÄŸerler input olur

#### 1.2 Kategori DÃ¶nÃ¼ÅŸÃ¼m AkÄ±ÅŸÄ±

- Her deÄŸer 15 farklÄ± kategori setinde encode edilir
- 1.67x deÄŸeri â†’ Set1'de kategori-4, Set2'de kategori-3, Set3'de kategori-2... ÅŸeklinde
- Bu 15 farklÄ± encoding paralel olarak saklanÄ±r
- Her deÄŸer iÃ§in 15 boyutlu bir kategori vektÃ¶rÃ¼ oluÅŸur

#### 1.3 Ã–zellik TÃ¼retme AkÄ±ÅŸÄ±

- Her pozisyon iÃ§in dinamik Ã¶zellikler hesaplanÄ±r
- "Son 10x'ten beri kaÃ§ el geÃ§ti" gibi Ã¶zellikler her tahmin anÄ±nda gÃ¼ncellenir
- Pencere iÃ§indeki istatistikler (deÄŸer daÄŸÄ±lÄ±mÄ±, streak'ler) hesaplanÄ±r

---

## 2. N-BEATS MODÃœLÃœ DETAYI

### ÃœÃ§ FarklÄ± N-BEATS BloÄŸu

#### 2.1 KÄ±sa Pencere BloÄŸu (50 el)

- **GiriÅŸ:** Son 50 deÄŸer + bu deÄŸerlerin 15 kategori encoding'i
- **Ä°lk katman:** Basis expansion (temel fonksiyonlara ayÄ±rma)
- **Ä°ÅŸlem:** Trend ve sezonellik ayrÄ±ÅŸtÄ±rmasÄ± yapÄ±lÄ±r
- **Ã‡Ä±kÄ±ÅŸ:** 64 boyutlu Ã¶zellik vektÃ¶rÃ¼ + gelecek tahmini

#### 2.2 Orta Pencere BloÄŸu (200 el)

- **GiriÅŸ:** Son 200 deÄŸer + kategori encoding'leri
- **Mimari:** Daha derin stack (4-5 katman)
- **Ä°ÅŸlem:** Hem backward (geÃ§miÅŸi aÃ§Ä±klama) hem forward (gelecek tahmini) Ã§Ä±kÄ±ÅŸÄ±
- **Ã‡Ä±kÄ±ÅŸ:** 128 boyutlu Ã¶zellik vektÃ¶rÃ¼ + tahmin

#### 2.3 Uzun Pencere BloÄŸu (500 el)

- **GiriÅŸ:** Son 500 deÄŸer + Ã¶zellikler
- **Mimari:** En derin mimari (6-7 katman)
- **Ä°ÅŸlem:** Uzun vadeli pattern'leri ve dÃ¶ngÃ¼leri yakalar
- **Ã‡Ä±kÄ±ÅŸ:** 256 boyutlu Ã¶zellik vektÃ¶rÃ¼ + tahmin

### N-BEATS BloklarÄ±n BirleÅŸimi

Her blok hem kendi tahminini hem de Ã¶ÄŸrendiÄŸi Ã¶zellikleri verir. BirleÅŸim:

- **Tahminler:** AÄŸÄ±rlÄ±klÄ± ortalama ile
  - `(0.5 Ã— kÄ±sa + 0.3 Ã— orta + 0.2 Ã— uzun)`
- **Ã–zellik vektÃ¶rleri:** Concatenate edilir
  - `[64 + 128 + 256] = 448 boyutlu vektÃ¶r`

---

## 3. TCN (TEMPORAL CONVOLUTIONAL NETWORK) MODÃœLÃœ

### TCN'in KatmanlÄ± YapÄ±sÄ±

#### Dilated Convolution KatmanlarÄ±

```
1. Katman: Dilation=1,  son 2 deÄŸere bakar
2. Katman: Dilation=2,  4 deÄŸer aralÄ±ÄŸÄ±na bakar
3. Katman: Dilation=4,  8 deÄŸer aralÄ±ÄŸÄ±na bakar
...
N. Katman: Dilation=32, 64 deÄŸer aralÄ±ÄŸÄ±na bakar
```

Bu sayede toplam 1000 deÄŸerlik pencereyi verimli ÅŸekilde tarar.

#### Residual BaÄŸlantÄ±lar

Her katmanda input direkt olarak output'a eklenir (skip connection). Bu:
- Gradient vanishing problemini Ã¶nler
- Derin aÄŸ eÄŸitimini kolaylaÅŸtÄ±rÄ±r

#### Masking MekanizmasÄ±

- TCN sadece geÃ§miÅŸ deÄŸerlere bakar (causal convolution)
- Gelecek deÄŸerleri gÃ¶rmez, bu da overfitting'i Ã¶nler

### TCN'in Ã‡Ä±ktÄ±sÄ±

TCN, her zaman adÄ±mÄ± iÃ§in bir hidden state Ã¼retir. Son hidden state, tÃ¼m 1000 deÄŸerlik bilgiyi Ã¶zetleyen **512 boyutlu** bir vektÃ¶rdÃ¼r.

---

## 4. ATTENTION MEKANÄ°ZMASI

Model iÃ§inde implicit (Ã¶rtÃ¼k) attention mekanizmalarÄ± bulunur:

### N-BEATS Ä°Ã§indeki Attention

- Hangi geÃ§miÅŸ deÄŸerlerin daha Ã¶nemli olduÄŸunu otomatik Ã¶ÄŸrenir
- Basis fonksiyonlarÄ± aslÄ±nda bir tÃ¼r attention gÃ¶revi gÃ¶rÃ¼r

### TCN Ä°Ã§indeki Attention

- Dilated convolution'lar farklÄ± mesafelere farklÄ± aÄŸÄ±rlÄ±klar verir
- Ã–nemli pattern'ler daha yÃ¼ksek aktivasyon Ã¼retir

---

## 5. PSÄ°KOLOJÄ°K ANALÄ°Z MOTORU

### Pattern Detection ModÃ¼lleri

#### 5.1 Trap Detector (Tuzak Tespit Edici)

- Son 10 eldeki deÄŸer dizilimini kontrol eder
- Bilinen tuzak pattern'lerini arar:
  - 2-3 orta kazanÃ§ â†’ bÃ¼yÃ¼k kayÄ±p
  - Recovery trap (toparlanma tuzaÄŸÄ±)
  - False momentum (sahte ivme)
- Sinir aÄŸÄ± yerine kural tabanlÄ± veya kÃ¼Ã§Ã¼k LSTM
- **Ã‡Ä±ktÄ±:** Tuzak olasÄ±lÄ±ÄŸÄ± (0-1 arasÄ±)

#### 5.2 SoÄŸuma DÃ¶nemi Detector

- Model kendisi Ã¶ÄŸrenir, sabit kural yok
- Son bÃ¼yÃ¼k Ã§arpandan beri geÃ§en sÃ¼reyi input alÄ±r
- O sÃ¼re iÃ§indeki deÄŸer daÄŸÄ±lÄ±mÄ±na bakar
- SoÄŸuma bitiÅŸi sinyallerini arar (volatilite artÄ±ÅŸÄ± gibi)
- **Ã‡Ä±ktÄ±:** SoÄŸuma durumu skoru

#### 5.3 Momentum Analyzer

- ArdÄ±ÅŸÄ±k deÄŸer deÄŸiÅŸimlerini analiz eder
- HÄ±zlanma/yavaÅŸlama pattern'lerini tespit eder
- **Ã‡Ä±ktÄ±:** Momentum vektÃ¶rÃ¼ (yÃ¶n + gÃ¼Ã§)

---

## 6. ENSEMBLE FUSION KATMANI

### ÃœÃ§ Ana BileÅŸenin BirleÅŸimi

#### 6.1 N-BEATS + TCN FÃ¼zyonu (%60 aÄŸÄ±rlÄ±k)

```
N-BEATS â†’ 448 boyutlu vektÃ¶r
TCN     â†’ 512 boyutlu vektÃ¶r
        â†“ concatenate
        960 boyut
        â†“ 2 fully connected katman
        256 boyut
```

#### 6.2 Psikolojik Motor (%30 aÄŸÄ±rlÄ±k)

```
Tuzak + SoÄŸuma + Momentum skorlarÄ±
        â†“ encoding
        32 boyutlu vektÃ¶r
        â†“ neural network
        Psikolojik Ã¶zellikler
```

#### 6.3 Ä°statistiksel Baseline (%10 aÄŸÄ±rlÄ±k)

```
Moving average + Volatilite + Histogram + Markov chain
        â†“ encoding
        16 boyutlu vektÃ¶r
```

### Final Tahmin KatmanÄ±

ÃœÃ§ bileÅŸen birleÅŸir: `256 + 32 + 16 = 304 boyut`

#### Ã‡Ä±ktÄ±lar:

**1. 15 Kategori Tahmini:**
- Her kategori seti iÃ§in ayrÄ± softmax Ã§Ä±ktÄ±sÄ±
- Ã–rnek: Set1 iÃ§in `[0.1, 0.3, 0.4, 0.2...]` olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±
- Toplam: `15 set Ã— ~15 kategori = 225 Ã§Ä±ktÄ± nÃ¶ronu`

**2. Regresyon Tahmini:**
- Direkt deÄŸer tahmini (Ã¶rn: 1.67x)
- Min-max aralÄ±k tahmini (Ã¶rn: 1.5x-2000.0x)

**3. GÃ¼ven Skoru:**
- Tahmin gÃ¼venilirliÄŸi (0-100%)
- Modelin kendi tahmininden ne kadar emin olduÄŸu

---

## 7. TRAINING LOOP MANTIÄI

### Loss Fonksiyonu TasarÄ±mÄ±

**Multi-Task Learning Loss:**

```
Total Loss = Î±â‚ Ã— Kategori Loss + Î±â‚‚ Ã— Regresyon Loss + Î±â‚ƒ Ã— 1.5x EÅŸik Loss
```

#### 7.1 Kategori Loss

- 15 kategori setinin her biri iÃ§in cross-entropy
- AÄŸÄ±rlÄ±klÄ± ortalama alÄ±nÄ±r

#### 7.2 Regresyon Loss

- Mean Absolute Error (MAE) veya Huber Loss
- BÃ¼yÃ¼k hatalara daha az duyarlÄ±

#### 7.3 1.5x EÅŸik Loss (Ã–zel)

- 1.5 altÄ±/Ã¼stÃ¼ binary classification loss
- YanlÄ±ÅŸ taraf tahminine ekstra ceza
- Ã–zellikle 1.45-1.55 aralÄ±ÄŸÄ±nda hassas

### Training Stratejisi

#### Curriculum Learning

1. Ä°lk epochlarda basit pattern'ler (1.5 altÄ±/Ã¼stÃ¼)
2. Sonra kategori tahmini
3. En son exact deÄŸer tahmini

#### Data Augmentation

- Pencereyi kaydÄ±rma (sliding window)
- GÃ¼rÃ¼ltÃ¼ ekleme (robustness iÃ§in)
- Synthetic pattern Ã¼retimi (bilinen pattern'leri varyasyonlarla)

---

## 8. INFERENCE (TAHMÄ°N) AÅAMASI

### GerÃ§ek ZamanlÄ± Tahmin AkÄ±ÅŸÄ±

```
1. Veri HazÄ±rlÄ±k (5ms)
   - Son 1000 deÄŸer alÄ±nÄ±r
   - 15 kategori encoding'i paralel yapÄ±lÄ±r
   - Ã–zellikler hesaplanÄ±r

2. Model Forward Pass (50ms)
   - N-BEATS paralel Ã§alÄ±ÅŸÄ±r (3 pencere)
   - TCN sequential iÅŸler
   - Psikolojik motor analiz yapar

3. Ensemble Fusion (10ms)
   - ÃœÃ§ bileÅŸen birleÅŸtirilir
   - Final tahmin hesaplanÄ±r

4. Post-Processing (5ms)
   - GÃ¼ven skoru kalibrasyonu
   - Risk uyarÄ±larÄ± eklenir
   - SonuÃ§ formatlanÄ±r

Toplam: <100ms tahmin sÃ¼resi
```

---

## 9. MODEL OPTÄ°MÄ°ZASYON TEKNÄ°KLERÄ°

### Quantization (Modeli KÃ¼Ã§Ã¼ltme)

- Float32 â†’ Int8 dÃ¶nÃ¼ÅŸÃ¼mÃ¼
- Model boyutu 4'te 1'e dÃ¼ÅŸer
- HÄ±z 2-3x artar

### Pruning (Gereksiz BaÄŸlantÄ±larÄ± Kesme)

- DÃ¼ÅŸÃ¼k aÄŸÄ±rlÄ±klÄ± connection'lar silinir
- Model %50-70 kÃ¼Ã§Ã¼lÃ¼r
- Accuracy kaybÄ± minimal

### Knowledge Distillation

- BÃ¼yÃ¼k model (teacher) kÃ¼Ã§Ã¼k modele (student) Ã¶ÄŸretir
- Student model 10x daha kÃ¼Ã§Ã¼k olabilir
- Performance kaybÄ± %5'ten az

---

## 10. ROLLING MOD Ä°Ã‡Ä°N Ã–ZEL ADAPTASYON

Rolling modda model davranÄ±ÅŸÄ± ÅŸÃ¶yle deÄŸiÅŸir:

### GÃ¼ven EÅŸiÄŸi YÃ¼kseltme

```
Normal mod:  %65+ gÃ¼vende tahmin gÃ¶ster
Rolling mod: %80+ gÃ¼vende tahmin gÃ¶ster
```

### Conservative Bias Ekleme

- Tahmin aralÄ±ÄŸÄ±nÄ± daralt
- Riskli kategorilere dÃ¼ÅŸÃ¼k olasÄ±lÄ±k ver
- 1.5x altÄ± olasÄ±lÄ±ÄŸÄ±nÄ± %10 artÄ±r (gÃ¼venlik iÃ§in)

### Sermaye Koruma Filtresi

- ArdÄ±ÅŸÄ±k 3 kazanÃ§tan sonra "DUR" sinyali
- SoÄŸuma dÃ¶neminde kesinlikle oynama
- Volatilite yÃ¼ksekse pas geÃ§

---

## ğŸ“Š Model Performans Hedefleri

| Metrik | Hedef | AÃ§Ä±klama |
|--------|-------|----------|
| 1.5x EÅŸik DoÄŸruluÄŸu | %75+ | En kritik metrik |
| Kategori DoÄŸruluÄŸu | %60+ | Genel pattern tanÄ±ma |
| Tahmin HÄ±zÄ± | <100ms | GerÃ§ek zamanlÄ± kullanÄ±m |
| Rolling Mod DoÄŸruluÄŸu | %85+ | YÃ¼ksek gÃ¼ven gerektiren mod |
| ArdÄ±ÅŸÄ±k YanlÄ±ÅŸ Max | 5 | Risk yÃ¶netimi iÃ§in |

---

## ğŸ”§ Teknik Stack

- **Deep Learning Framework:** TensorFlow/Keras veya PyTorch
- **N-BEATS:** Custom implementation
- **TCN:** Temporal Convolutional Network
- **Optimization:** Quantization, Pruning, Knowledge Distillation
- **Inference:** CPU optimized (lokal kullanÄ±m iÃ§in)

---

## ğŸ“š Referanslar

- N-BEATS: Neural basis expansion analysis for interpretable time series forecasting
- TCN: Temporal Convolutional Networks for Sequence Modeling
- Ensemble Learning: Combining multiple models for better predictions

---

**Son GÃ¼ncelleme:** 08.10.2025

Bu dokÃ¼mantasyon, JetX Predictor projesinin model mimarisini aÃ§Ä±klar. Uygulama detaylarÄ± iÃ§in `notebooks/jetx_model_training.ipynb` dosyasÄ±na bakÄ±n.
