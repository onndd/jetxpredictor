# ğŸš€ YENI MODEL GELÄ°ÅTÄ°RME PLANI

**Tarih:** 2025-10-12  
**Hedef:** Transformer + CatBoost + Ã‡ift Sanal Kasa Sistemi  
**Ana Dosya:** `notebooks/JetX_Progressive_Training_Colab.ipynb`

---

## ğŸ“Š Ã–ZET

### DeÄŸiÅŸiklikler:
1. âœ… **XGBoost â†’ CatBoost** (kesin deÄŸiÅŸiklik)
2. âœ… **Transformer Ekleme** (Progressive model'e entegre)
3. âœ… **2 AyrÄ± Sanal Kasa Sistemi:**
   - **Kasa 1:** 1.5x eÅŸik (mevcut sistem, kalacak)
   - **Kasa 2:** Tahmin Ã— %80 Ã§Ä±kÄ±ÅŸ (yeni sistem, 2x+ iÃ§in)
4. âœ… **Dinamik Kasa MiktarÄ±:** Test veri sayÄ±sÄ± Ã— 10 TL
5. âœ… **Colab Entegrasyonu:** TÃ¼m deÄŸiÅŸiklikler `JetX_Progressive_Training_Colab.ipynb`'a

### Beklenen Ä°yileÅŸme:
- **1.5 AltÄ± DoÄŸruluk:** %55 â†’ **%75** (+36%)
- **Para KaybÄ± Riski:** %35 â†’ **%18** (-49%)
- **Kasa 2:** YÃ¼ksek tahminlerde (%80 Ã§Ä±kÄ±ÅŸ) ek kar fÄ±rsatÄ±

---

## ğŸ¯ UYGULAMA FAZLARI

### **FAZ 1: Kod AltyapÄ±sÄ± HazÄ±rlama**
- Transformer mimarisi tasarla
- CatBoost entegrasyonu kodu hazÄ±rla
- Dinamik ve Ã§ift kasa sistemi kodu hazÄ±rla

### **FAZ 2: Colab Entegrasyonu**
- KÃ¼tÃ¼phaneleri gÃ¼ncelle
- Model mimarisini gÃ¼ncelle
- CatBoost eÄŸitim bloÄŸu ekle
- Ã‡ift sanal kasa simÃ¼lasyonu ekle
- Model kaydetme ve indirme sistemi

### **FAZ 3: Test ve Raporlama**
- Final test
- DokÃ¼mantasyon
- Cleanup

---

## ğŸ“‹ DETAYLI ADIMLAR

---

## FAZ 1: KOD ALTYAPISI HAZIRLAMA

### ADIM 1.1: Lightweight Transformer Encoder

**Ne YapÄ±lacak:**
Progressive model'e eklenecek Transformer encoder sÄ±nÄ±fÄ±.

**Kod BloÄŸu (Colab'a eklenecek):**

```python
import tensorflow as tf
from tensorflow.keras import layers

class PositionalEncoding(layers.Layer):
    """
    Positional Encoding for Transformer
    Time series iÃ§in zamansal bilgi ekler
    """
    def __init__(self, max_seq_len=1000, d_model=256, **kwargs):
        super().__init__(**kwargs)
        self.max_seq_len = max_seq_len
        self.d_model = d_model
        
        # Positional encoding matrix oluÅŸtur
        position = tf.range(max_seq_len, dtype=tf.float32)[:, tf.newaxis]
        div_term = tf.exp(tf.range(0, d_model, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / d_model))
        
        pe = tf.zeros((max_seq_len, d_model))
        pe_sin = tf.sin(position * div_term)
        pe_cos = tf.cos(position * div_term)
        
        # Sin ve cos deÄŸerlerini birleÅŸtir
        pe_array = tf.Variable(pe, trainable=False)
        pe_array[:, 0::2].assign(pe_sin)
        pe_array[:, 1::2].assign(pe_cos)
        self.pe = pe_array
    
    def call(self, x):
        seq_len = tf.shape(x)[1]
        return x + self.pe[:seq_len, :]
    
    def get_config(self):
        config = super().get_config()
        config.update({
            'max_seq_len': self.max_seq_len,
            'd_model': self.d_model
        })
        return config


class LightweightTransformerEncoder(layers.Layer):
    """
    Lightweight Transformer Encoder for Time Series
    
    Args:
        d_model: Model dimension (256)
        num_layers: Number of transformer layers (4)
        num_heads: Number of attention heads (8)
        dff: Feedforward dimension (1024)
        dropout: Dropout rate (0.2)
    """
    def __init__(
        self, 
        d_model=256, 
        num_layers=4, 
        num_heads=8, 
        dff=1024, 
        dropout=0.2,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.d_model = d_model
        self.num_layers = num_layers
        self.num_heads = num_heads
        self.dff = dff
        self.dropout_rate = dropout
        
        # Input projection (sequence_len, 1) â†’ (sequence_len, d_model)
        self.input_projection = layers.Dense(d_model)
        
        # Positional encoding
        self.pos_encoding = PositionalEncoding(max_seq_len=1000, d_model=d_model)
        
        # Transformer encoder layers
        self.encoder_layers = []
        for _ in range(num_layers):
            # Multi-head attention
            mha = layers.MultiHeadAttention(
                num_heads=num_heads,
                key_dim=d_model // num_heads,
                dropout=dropout
            )
            
            # Feedforward network
            ffn = tf.keras.Sequential([
                layers.Dense(dff, activation='relu'),
                layers.Dropout(dropout),
                layers.Dense(d_model)
            ])
            
            # Layer normalization
            layernorm1 = layers.LayerNormalization(epsilon=1e-6)
            layernorm2 = layers.LayerNormalization(epsilon=1e-6)
            
            # Dropout
            dropout1 = layers.Dropout(dropout)
            dropout2 = layers.Dropout(dropout)
            
            self.encoder_layers.append({
                'mha': mha,
                'ffn': ffn,
                'layernorm1': layernorm1,
                'layernorm2': layernorm2,
                'dropout1': dropout1,
                'dropout2': dropout2
            })
        
        # Global average pooling
        self.global_pool = layers.GlobalAveragePooling1D()
        
        # Output projection
        self.output_projection = layers.Dense(d_model)
        self.dropout_final = layers.Dropout(dropout)
    
    def call(self, inputs, training=None):
        """
        Forward pass
        
        Args:
            inputs: (batch_size, seq_len, 1) - Time series input
            training: Training mode flag
            
        Returns:
            (batch_size, d_model) - Encoded representation
        """
        # Input projection
        x = self.input_projection(inputs)  # (batch, seq_len, d_model)
        
        # Positional encoding
        x = self.pos_encoding(x)
        
        # Transformer encoder layers
        for layer in self.encoder_layers:
            # Multi-head attention
            attn_output = layer['mha'](
                query=x,
                key=x,
                value=x,
                training=training
            )
            attn_output = layer['dropout1'](attn_output, training=training)
            x = layer['layernorm1'](x + attn_output)  # Residual connection
            
            # Feedforward network
            ffn_output = layer['ffn'](x)
            ffn_output = layer['dropout2'](ffn_output, training=training)
            x = layer['layernorm2'](x + ffn_output)  # Residual connection
        
        # Global pooling
        x = self.global_pool(x)  # (batch, d_model)
        
        # Output projection
        x = self.output_projection(x)
        x = self.dropout_final(x, training=training)
        
        return x
    
    def get_config(self):
        config = super().get_config()
        config.update({
            'd_model': self.d_model,
            'num_layers': self.num_layers,
            'num_heads': self.num_heads,
            'dff': self.dff,
            'dropout': self.dropout_rate
        })
        return config
```

**Nereye Eklenecek:**
Colab notebook'unda, `build_progressive_model()` fonksiyonundan **Ã–NCE** bir hÃ¼creye eklenecek.

---

### ADIM 1.2: Progressive Model'e Transformer Entegrasyonu

**Ne YapÄ±lacak:**
`build_progressive_model()` fonksiyonuna Transformer branch eklenecek.

**DeÄŸiÅŸtirilecek BÃ¶lÃ¼m:**
```python
def build_progressive_model(n_features):
    # ... (mevcut kod - input layers)
    
    # ... (mevcut kod - N-BEATS branches)
    
    # ... (mevcut kod - TCN branch)
    
    # YENÄ°: Transformer branch
    # inp_500 veya inp_1000 kullanÄ±labilir (daha uzun sequence daha iyi)
    transformer_input = inp_1000  # 1000 timestep
    
    # Lightweight Transformer Encoder
    transformer = LightweightTransformerEncoder(
        d_model=256,
        num_layers=4,
        num_heads=8,
        dff=1024,
        dropout=0.2
    )(transformer_input)
    
    # Transformer output: (batch, 256)
    
    # Fusion'a Transformer'Ä± da ekle
    # ESKI: fus = layers.Concatenate()([inp_f, nb_all, tcn])
    # YENÄ°:
    fus = layers.Concatenate()([inp_f, nb_all, tcn, transformer])
    
    # ... (geri kalan kod aynÄ±)
```

**SatÄ±r NumaralarÄ± (YaklaÅŸÄ±k):**
- Transformer branch: ~280-295 satÄ±r civarÄ± (TCN branch'ten sonra)
- Fusion layer: ~287 satÄ±r civarÄ±

---

### ADIM 1.3: CatBoost Entegrasyonu

**Ne YapÄ±lacak:**
XGBoost kodlarÄ±nÄ± CatBoost'a Ã§evirmek.

**KÃ¼tÃ¼phane Kurulumu (Colab'da):**
```python
!pip install -q catboost
```

**CatBoost Regressor Kodu:**
```python
from catboost import CatBoostRegressor, CatBoostClassifier

# Regressor (DeÄŸer Tahmini)
regressor = CatBoostRegressor(
    iterations=500,
    depth=8,
    learning_rate=0.05,
    loss_function='MAE',
    eval_metric='MAE',
    task_type='GPU',  # GPU varsa
    verbose=50,
    random_state=42,
    early_stopping_rounds=20
)

print("ğŸ”¥ CatBoost Regressor eÄŸitimi baÅŸlÄ±yor...")
regressor.fit(
    X_train, y_reg_train,
    eval_set=(X_test, y_reg_test),
    verbose=50
)
```

**CatBoost Classifier Kodu:**
```python
# Class weights hesapla
below_count = (y_cls_train == 0).sum()
above_count = (y_cls_train == 1).sum()

# CatBoost iÃ§in class_weights parametresi
class_weights = {0: 2.0, 1: 1.0}  # 1.5 altÄ±na 2x aÄŸÄ±rlÄ±k

# Classifier (1.5 EÅŸik Tahmini)
classifier = CatBoostClassifier(
    iterations=500,
    depth=7,
    learning_rate=0.05,
    loss_function='Logloss',
    eval_metric='Accuracy',
    task_type='GPU',  # GPU varsa
    class_weights=class_weights,  # Class weights
    verbose=50,
    random_state=42,
    early_stopping_rounds=20
)

print("ğŸ”¥ CatBoost Classifier eÄŸitimi baÅŸlÄ±yor...")
classifier.fit(
    X_train, y_cls_train,
    eval_set=(X_test, y_cls_test),
    verbose=50
)
```

**Model Kaydetme:**
```python
# CatBoost modelleri kaydet
regressor.save_model('/content/jetxpredictor/models/catboost_regressor.cbm')
classifier.save_model('/content/jetxpredictor/models/catboost_classifier.cbm')
print("âœ… CatBoost modelleri kaydedildi")
```

---

### ADIM 1.4: Dinamik ve Ã‡ift Sanal Kasa Sistemi

**Ne YapÄ±lacak:**
2 ayrÄ± sanal kasa sistemi oluÅŸturmak.

**Kasa Sistemi Kodu:**

```python
# =============================================================================
# Ã‡Ä°FT SANAL KASA SÄ°MÃœLASYONU
# =============================================================================
print("\n" + "="*80)
print("ğŸ’° Ã‡Ä°FT SANAL KASA SÄ°MÃœLASYONU")
print("="*80)

# Dinamik kasa miktarÄ± hesapla
test_count = len(y_reg_te)
initial_bankroll = test_count * 10  # Her test verisi iÃ§in 10 TL
bet_amount = 10.0

print(f"ğŸ“Š Test Veri SayÄ±sÄ±: {test_count:,}")
print(f"ğŸ’° BaÅŸlangÄ±Ã§ KasasÄ±: {initial_bankroll:,.2f} TL (dinamik)")
print(f"ğŸ’µ Bahis TutarÄ±: {bet_amount:.2f} TL (sabit)")
print()

# =============================================================================
# KASA 1: 1.5x EÅÄ°K SÄ°STEMÄ° (Mevcut)
# =============================================================================
print("="*80)
print("ğŸ’° KASA 1: 1.5x EÅÄ°K SÄ°STEMÄ°")
print("="*80)
print("Strateji: Model 1.5x Ã¼stÃ¼ tahmin ederse â†’ 1.5x'te Ã§Ä±kÄ±ÅŸ")
print()

kasa1_wallet = initial_bankroll
kasa1_total_bets = 0
kasa1_total_wins = 0
kasa1_total_losses = 0

# Model tahminlerini al (CatBoost classifier'dan)
y_cls_proba = classifier.predict_proba(X_test)
threshold_predictions = (y_cls_proba[:, 1] >= 0.5).astype(int)  # 1.5 Ã¼stÃ¼ tahmin

for i in range(len(y_reg_te)):
    model_pred_cls = threshold_predictions[i]  # 0 veya 1
    actual_value = y_reg_te[i]
    
    # Model "1.5 Ã¼stÃ¼" tahmin ediyorsa bahis yap
    if model_pred_cls == 1:
        kasa1_wallet -= bet_amount  # Bahis yap
        kasa1_total_bets += 1
        
        # 1.5x'te Ã§Ä±kÄ±ÅŸ yap
        exit_point = 1.5
        
        # GerÃ§ek deÄŸer Ã§Ä±kÄ±ÅŸ noktasÄ±ndan bÃ¼yÃ¼k veya eÅŸitse kazandÄ±k
        if actual_value >= exit_point:
            # KazandÄ±k! 1.5x Ã— 10 TL = 15 TL geri al
            kasa1_wallet += exit_point * bet_amount
            kasa1_total_wins += 1
        else:
            # Kaybettik (bahis zaten kesildi)
            kasa1_total_losses += 1

# Kasa 1 sonuÃ§larÄ±
kasa1_profit_loss = kasa1_wallet - initial_bankroll
kasa1_roi = (kasa1_profit_loss / initial_bankroll) * 100
kasa1_win_rate = (kasa1_total_wins / kasa1_total_bets * 100) if kasa1_total_bets > 0 else 0
kasa1_accuracy = kasa1_win_rate

print(f"\nğŸ“Š KASA 1 SONUÃ‡LARI:")
print(f"{'='*70}")
print(f"Toplam Oyun: {kasa1_total_bets:,} el")
print(f"âœ… Kazanan: {kasa1_total_wins:,} oyun ({kasa1_win_rate:.1f}%)")
print(f"âŒ Kaybeden: {kasa1_total_losses:,} oyun ({100-kasa1_win_rate:.1f}%)")
print(f"")
print(f"ğŸ’° BaÅŸlangÄ±Ã§ KasasÄ±: {initial_bankroll:,.2f} TL")
print(f"ğŸ’° Final Kasa: {kasa1_wallet:,.2f} TL")
print(f"ğŸ“ˆ Net Kar/Zarar: {kasa1_profit_loss:+,.2f} TL")
print(f"ğŸ“Š ROI: {kasa1_roi:+.2f}%")
print(f"ğŸ¯ DoÄŸruluk (Kazanma OranÄ±): {kasa1_accuracy:.1f}%")
print(f"{'='*70}\n")

# =============================================================================
# KASA 2: %80 Ã‡IKIÅ SÄ°STEMÄ° (Yeni)
# =============================================================================
print("="*80)
print("ğŸ’° KASA 2: %80 Ã‡IKIÅ SÄ°STEMÄ° (YÃ¼ksek Tahminler)")
print("="*80)
print("Strateji: Model 2.0x+ tahmin ederse â†’ Tahmin Ã— 0.80'de Ã§Ä±kÄ±ÅŸ")
print()

kasa2_wallet = initial_bankroll
kasa2_total_bets = 0
kasa2_total_wins = 0
kasa2_total_losses = 0
kasa2_exit_points = []  # Ã‡Ä±kÄ±ÅŸ noktalarÄ±nÄ± kaydet

# Model tahminlerini al (CatBoost regressor'dan)
y_reg_pred = regressor.predict(X_test)

for i in range(len(y_reg_te)):
    model_pred_value = y_reg_pred[i]  # Tahmin edilen deÄŸer
    actual_value = y_reg_te[i]
    
    # SADECE 2.0x ve Ã¼zeri tahminlerde oyna
    if model_pred_value >= 2.0:
        kasa2_wallet -= bet_amount  # Bahis yap
        kasa2_total_bets += 1
        
        # Ã‡Ä±kÄ±ÅŸ noktasÄ±: Tahmin Ã— 0.80
        exit_point = model_pred_value * 0.80
        kasa2_exit_points.append(exit_point)
        
        # GerÃ§ek deÄŸer Ã§Ä±kÄ±ÅŸ noktasÄ±ndan bÃ¼yÃ¼k veya eÅŸitse kazandÄ±k
        if actual_value >= exit_point:
            # KazandÄ±k! exit_point Ã— 10 TL geri al
            kasa2_wallet += exit_point * bet_amount
            kasa2_total_wins += 1
        else:
            # Kaybettik (bahis zaten kesildi)
            kasa2_total_losses += 1

# Kasa 2 sonuÃ§larÄ±
kasa2_profit_loss = kasa2_wallet - initial_bankroll
kasa2_roi = (kasa2_profit_loss / initial_bankroll) * 100
kasa2_win_rate = (kasa2_total_wins / kasa2_total_bets * 100) if kasa2_total_bets > 0 else 0
kasa2_accuracy = kasa2_win_rate
kasa2_avg_exit = np.mean(kasa2_exit_points) if kasa2_exit_points else 0

print(f"\nğŸ“Š KASA 2 SONUÃ‡LARI:")
print(f"{'='*70}")
print(f"Toplam Oyun: {kasa2_total_bets:,} el")
print(f"âœ… Kazanan: {kasa2_total_wins:,} oyun ({kasa2_win_rate:.1f}%)")
print(f"âŒ Kaybeden: {kasa2_total_losses:,} oyun ({100-kasa2_win_rate:.1f}%)")
print(f"")
print(f"ğŸ’° BaÅŸlangÄ±Ã§ KasasÄ±: {initial_bankroll:,.2f} TL")
print(f"ğŸ’° Final Kasa: {kasa2_wallet:,.2f} TL")
print(f"ğŸ“ˆ Net Kar/Zarar: {kasa2_profit_loss:+,.2f} TL")
print(f"ğŸ“Š ROI: {kasa2_roi:+.2f}%")
print(f"ğŸ¯ DoÄŸruluk (Kazanma OranÄ±): {kasa2_accuracy:.1f}%")
print(f"ğŸ“Š Ortalama Ã‡Ä±kÄ±ÅŸ NoktasÄ±: {kasa2_avg_exit:.2f}x")
print(f"{'='*70}\n")

# =============================================================================
# KARÅILAÅTIRMA
# =============================================================================
print("="*80)
print("ğŸ“Š KASA KARÅILAÅTIRMASI")
print("="*80)
print(f"{'Metrik':<30} {'Kasa 1 (1.5x)':<20} {'Kasa 2 (%80)':<20}")
print(f"{'-'*70}")
print(f"{'Toplam Oyun':<30} {kasa1_total_bets:<20,} {kasa2_total_bets:<20,}")
print(f"{'Kazanan Oyun':<30} {kasa1_total_wins:<20,} {kasa2_total_wins:<20,}")
print(f"{'Kazanma OranÄ±':<30} {kasa1_win_rate:<20.1f}% {kasa2_win_rate:<20.1f}%")
print(f"{'Net Kar/Zarar':<30} {kasa1_profit_loss:<20,.2f} TL {kasa2_profit_loss:<20,.2f} TL")
print(f"{'ROI':<30} {kasa1_roi:<20.2f}% {kasa2_roi:<20.2f}%")
print(f"{'-'*70}")

# Hangi kasa daha karlÄ±?
if kasa1_profit_loss > kasa2_profit_loss:
    print(f"ğŸ† KASA 1 daha karlÄ± (+{kasa1_profit_loss - kasa2_profit_loss:,.2f} TL fark)")
elif kasa2_profit_loss > kasa1_profit_loss:
    print(f"ğŸ† KASA 2 daha karlÄ± (+{kasa2_profit_loss - kasa1_profit_loss:,.2f} TL fark)")
else:
    print(f"âš–ï¸ Her iki kasa eÅŸit karlÄ±lÄ±kta")

print(f"{'='*80}\n")
```

**Nereye Eklenecek:**
Colab notebook'unda, Progressive NN eÄŸitiminin **SONUNDA**, "Final Evaluation" bÃ¶lÃ¼mÃ¼nden sonra eklenecek.

---

## FAZ 2: COLAB ENTEGRASYONU

### ADIM 2.1: KÃ¼tÃ¼phane GÃ¼ncellemesi

**Ne YapÄ±lacak:**
Colab notebook'unun baÅŸÄ±ndaki kÃ¼tÃ¼phane kurulum hÃ¼cresini gÃ¼ncellemek.

**Mevcut Kod:**
```python
!pip install -q tensorflow scikit-learn pandas numpy scipy joblib matplotlib seaborn tqdm PyWavelets nolds
```

**Yeni Kod:**
```python
!pip install -q tensorflow scikit-learn pandas numpy scipy joblib matplotlib seaborn tqdm PyWavelets nolds catboost
```

**DeÄŸiÅŸiklik:** `catboost` eklendi.

---

### ADIM 2.2: Model Mimarisi GÃ¼ncellemesi

**Ne YapÄ±lacak:**
`build_progressive_model()` fonksiyonuna Transformer branch eklemek.

**HÃ¼cre SÄ±rasÄ±:**
1. Ã–nce **ADIM 1.1**'deki Transformer sÄ±nÄ±flarÄ±nÄ± ekle (yeni hÃ¼cre)
2. Sonra `build_progressive_model()` fonksiyonunu **ADIM 1.2**'deki gibi gÃ¼ncelle

**SatÄ±r NumarasÄ±:**
`build_progressive_model()` fonksiyonu yaklaÅŸÄ±k **220-310** satÄ±r arasÄ±nda.

---

### ADIM 2.3: CatBoost EÄŸitim BloÄŸu

**Ne YapÄ±lacak:**
XGBoost eÄŸitim bloÄŸunu CatBoost ile deÄŸiÅŸtirmek.

**DeÄŸiÅŸtirilecek BÃ¶lÃ¼m:**
Progressive NN eÄŸitiminden **SONRA**, ayrÄ± bir bÃ¶lÃ¼m olarak CatBoost eÄŸitimi eklenecek.

**HÃ¼cre Ä°Ã§eriÄŸi:** **ADIM 1.3**'teki CatBoost kodlarÄ±

---

### ADIM 2.4: Ã‡ift Sanal Kasa SimÃ¼lasyonu

**Ne YapÄ±lacak:**
Mevcut sanal kasa simÃ¼lasyonunu kaldÄ±rÄ±p, **ADIM 1.4**'teki Ã§ift kasa sistemini eklemek.

**Yer:** Progressive NN + CatBoost eÄŸitiminden **SONRA**, "Final Evaluation" bÃ¶lÃ¼mÃ¼nde.

---

### ADIM 2.5: Model Kaydetme ve Ä°ndirme

**Ne YapÄ±lacak:**
TÃ¼m modelleri kaydet ve tek bir ZIP dosyasÄ± olarak indirilebilir hale getir.

**Kod:**

```python
# =============================================================================
# MODEL KAYDETME
# =============================================================================
print("\n" + "="*80)
print("ğŸ’¾ MODELLER KAYDEDÄ°LÄ°YOR")
print("="*80)

import os
import shutil

# models/ klasÃ¶rÃ¼nÃ¼ oluÅŸtur
os.makedirs('/content/jetxpredictor/models', exist_ok=True)

# 1. Progressive NN modeli
model.save('/content/jetxpredictor/models/jetx_progressive_transformer.h5')
print("âœ… Progressive NN (Transformer) kaydedildi: jetx_progressive_transformer.h5")

# 2. Scaler
import joblib
joblib.dump(scaler, '/content/jetxpredictor/models/scaler_progressive_transformer.pkl')
print("âœ… Scaler kaydedildi: scaler_progressive_transformer.pkl")

# 3. CatBoost Regressor
regressor.save_model('/content/jetxpredictor/models/catboost_regressor.cbm')
print("âœ… CatBoost Regressor kaydedildi: catboost_regressor.cbm")

# 4. CatBoost Classifier
classifier.save_model('/content/jetxpredictor/models/catboost_classifier.cbm')
print("âœ… CatBoost Classifier kaydedildi: catboost_classifier.cbm")

# 5. Model bilgileri (JSON)
import json
model_info = {
    'model': 'Progressive_NN_Transformer_CatBoost',
    'version': '2.0',
    'date': '2025-10-12',
    'architecture': {
        'progressive_nn': {
            'n_beats': True,
            'tcn': True,
            'transformer': {
                'd_model': 256,
                'num_layers': 4,
                'num_heads': 8,
                'dff': 1024
            }
        },
        'catboost': {
            'regressor': 'catboost_regressor.cbm',
            'classifier': 'catboost_classifier.cbm'
        }
    },
    'performance': {
        'kasa_1_roi': kasa1_roi,
        'kasa_1_accuracy': kasa1_accuracy,
        'kasa_2_roi': kasa2_roi,
        'kasa_2_accuracy': kasa2_accuracy
    }
}

with open('/content/jetxpredictor/models/model_info.json', 'w') as f:
    json.dump(model_info, f, indent=2)
print("âœ… Model bilgileri kaydedildi: model_info.json")

print("\nğŸ“ Kaydedilen dosyalar:")
print("  â€¢ jetx_progressive_transformer.h5 (Progressive NN)")
print("  â€¢ scaler_progressive_transformer.pkl (Scaler)")
print("  â€¢ catboost_regressor.cbm (CatBoost Regressor)")
print("  â€¢ catboost_classifier.cbm (CatBoost Classifier)")
print("  â€¢ model_info.json (Model bilgileri)")
print("="*80)

# =============================================================================
# MODELLERÄ° ZIP'LE VE Ä°NDÄ°R
# =============================================================================
print("\n" + "="*80)
print("ğŸ“¦ MODELLER ZIP'LENIYOR")
print("="*80)

# ZIP dosyasÄ± oluÅŸtur
zip_filename = 'jetx_models_v2.0.zip'
shutil.make_archive(
    '/content/jetx_models_v2.0', 
    'zip', 
    '/content/jetxpredictor/models'
)

print(f"âœ… ZIP dosyasÄ± oluÅŸturuldu: {zip_filename}")
print(f"ğŸ“¦ Boyut: {os.path.getsize(f'/content/{zip_filename}') / (1024*1024):.2f} MB")

# Google Colab'da indirme
try:
    from google.colab import files
    files.download(f'/content/{zip_filename}')
    print(f"âœ… {zip_filename} indiriliyor...")
except:
    print(f"âš ï¸ Manuel indirme gerekli: /content/{zip_filename}")

print("\nğŸ“Œ Ä°NDÄ°RDÄ°ÄÄ°NÄ°Z DOSYAYI AÃ‡IP models/ KLASÃ–RÃœNE KOPYALAYIN:")
print("  1. ZIP'i aÃ§Ä±n")
print("  2. TÃ¼m dosyalarÄ± lokal projenizin models/ klasÃ¶rÃ¼ne kopyalayÄ±n")
print("  3. Streamlit uygulamasÄ±nÄ± yeniden baÅŸlatÄ±n")
print("="*80)
```

**Nereye Eklenecek:**
TÃ¼m eÄŸitim ve simÃ¼lasyonlarÄ±n **EN SONUNA** eklenecek.

---

## FAZ 3: TEST VE RAPORLAMA

### ADIM 3.1: Final Test

**Ne YapÄ±lacak:**
1. Colab notebook'u baÅŸtan sona Ã§alÄ±ÅŸtÄ±r
2. Her hÃ¼crenin baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrula
3. Hata varsa dÃ¼zelt

**Kontrol Listesi:**
- [ ] KÃ¼tÃ¼phaneler yÃ¼klendi mi?
- [ ] Transformer sÄ±nÄ±flarÄ± tanÄ±mlandÄ± mÄ±?
- [ ] Model baÅŸarÄ±yla oluÅŸturuldu mu?
- [ ] CatBoost baÅŸarÄ±yla eÄŸitildi mi?
- [ ] Ä°ki kasa simÃ¼lasyonu Ã§alÄ±ÅŸtÄ± mÄ±?
- [ ] Modeller kaydedildi mi?
- [ ] ZIP dosyasÄ± indirildi mi?

---

### ADIM 3.2: DokÃ¼mantasyon GÃ¼ncelleme

**Ne YapÄ±lacak:**
README.md ve diÄŸer dokÃ¼mantasyon dosyalarÄ±nÄ± gÃ¼ncelle.

**DeÄŸiÅŸiklikler:**
1. XGBoost â†’ CatBoost deÄŸiÅŸikliÄŸini belirt
2. Transformer eklentisini aÃ§Ä±kla
3. Ä°ki kasalÄ± sistemi dokÃ¼mante et
4. Model dosyalarÄ±nÄ± listele

---

### ADIM 3.3: Cleanup

**Ne YapÄ±lacak:**
Gereksiz kodlarÄ± temizle, yorumlarÄ± dÃ¼zenle.

---

## ğŸ“ DOSYA YÃ–NETÄ°MÄ°

### Colab'da OluÅŸturulacak Dosyalar:

```
/content/jetxpredictor/models/
â”œâ”€â”€ jetx_progressive_transformer.h5  (Progressive NN + Transformer)
â”œâ”€â”€ scaler_progressive_transformer.pkl  (Scaler)
â”œâ”€â”€ catboost_regressor.cbm  (CatBoost Regressor)
â”œâ”€â”€ catboost_classifier.cbm  (CatBoost Classifier)
â””â”€â”€ model_info.json  (Model bilgileri)
```

### Ä°ndirilecek Dosya:

```
jetx_models_v2.0.zip  (TÃ¼m modeller tek ZIP'te)
```

### Lokal Projeye Kopyalanacak:

```
/Users/numanondes/Desktop/jetxpredictor/models/
â”œâ”€â”€ jetx_progressive_transformer.h5
â”œâ”€â”€ scaler_progressive_transformer.pkl
â”œâ”€â”€ catboost_regressor.cbm
â”œâ”€â”€ catboost_classifier.cbm
â””â”€â”€ model_info.json
```

---

## ğŸš¨ YARIM KALIRSA DEVAM ETME REHBERÄ°

### EÄŸer FAZ 1'de YarÄ±m KaldÄ±ysa:

1. `YENI_MODEL_GELISTIRME_PLANI.md` dosyasÄ±nÄ± aÃ§
2. **ADIM 1.1, 1.2, 1.3, 1.4**'teki kodlarÄ± kopyala
3. Colab notebook'una ekle
4. FAZ 2'ye geÃ§

### EÄŸer FAZ 2'de YarÄ±m KaldÄ±ysa:

1. Hangi adÄ±mda kaldÄ±ÄŸÄ±nÄ± belirle
2. Ä°lgili ADIM'daki kodu kopyala
3. Colab notebook'una ekle
4. Devam et

### EÄŸer FAZ 3'te YarÄ±m KaldÄ±ysa:

1. Test et
2. HatalarÄ± dÃ¼zelt
3. DokÃ¼mante et

---

## ğŸ¯ BEKLENEN SONUÃ‡LAR

### Model PerformansÄ±:

**Progressive NN (Transformer ile):**
- 1.5 AltÄ± DoÄŸruluk: **%70-80**
- 1.5 ÃœstÃ¼ DoÄŸruluk: **%75-85**
- Para KaybÄ± Riski: **<%20**

**CatBoost:**
- MAE: **< 2.0**
- 1.5 EÅŸik DoÄŸruluÄŸu: **%75-85**

### Sanal Kasa SonuÃ§larÄ±:

**Kasa 1 (1.5x EÅŸik):**
- ROI: **+%5 - +%15**
- Kazanma OranÄ±: **%70-75**

**Kasa 2 (%80 Ã‡Ä±kÄ±ÅŸ):**
- ROI: **+%10 - +%25** (potansiyel daha yÃ¼ksek)
- Kazanma OranÄ±: **%65-75**
- Ortalama Ã‡Ä±kÄ±ÅŸ: **2.5x - 3.5x**

---

## ğŸ“ NOTLAR

1. **GPU KullanÄ±mÄ±:** Colab'da GPU runtime kullan (Runtime â†’ Change runtime type â†’ GPU)
2. **EÄŸitim SÃ¼resi:** Toplam ~2-2.5 saat
3. **RAM KullanÄ±mÄ±:** ~12-15 GB (Colab Ã¼cretsiz versiyonda yeterli)
4. **Model Boyutu:** ZIP dosyasÄ± ~50-100 MB olacak

---

## âœ… KONTROL LÄ°STESÄ°

### BaÅŸlamadan Ã–nce:
- [ ] Colab'da GPU runtime aktif mi?
- [ ] `JetX_Progressive_Training_Colab.ipynb` dosyasÄ± aÃ§Ä±k mÄ±?
- [ ] Bu plan dosyasÄ± (`YENI_MODEL_GELISTIRME_PLANI.md`) aÃ§Ä±k mÄ±?

### FAZ 1: Kod HazÄ±rlama
- [ ] ADIM 1.1: Transformer sÄ±nÄ±flarÄ± hazÄ±rlandÄ±
- [ ] ADIM 1.2: Progressive model gÃ¼ncellendi
- [ ] ADIM 1.3: CatBoost kodu hazÄ±rlandÄ±
- [ ] ADIM 1.4: Ã‡ift kasa sistemi kodu hazÄ±rlandÄ±

### FAZ 2: Colab Entegrasyonu
- [ ] ADIM 2.1: KÃ¼tÃ¼phaneler gÃ¼ncellendi
- [ ] ADIM 2.2: Model mimarisi gÃ¼ncellendi
- [ ] ADIM 2.3: CatBoost eÄŸitim bloÄŸu eklendi
- [ ] ADIM 2.4: Ã‡ift kasa simÃ¼lasyonu eklendi
- [ ] ADIM 2.5: Model kaydetme eklendi

### FAZ 3: Test ve Raporlama
- [ ] ADIM 3.1: Final test yapÄ±ldÄ±
- [ ] ADIM 3.2: DokÃ¼mantasyon gÃ¼ncellendi
- [ ] ADIM 3.3: Cleanup yapÄ±ldÄ±

### SonuÃ§:
- [ ] Modeller baÅŸarÄ±yla eÄŸitildi
- [ ] ZIP dosyasÄ± indirildi
- [ ] Lokal projeye kopyalandÄ±
- [ ] Streamlit uygulamasÄ± test edildi

---

**BAÅARILI BÄ°R UYGULAMA DÄ°LERÄ°M! ğŸš€**

SorularÄ±nÄ±z olursa bu planÄ± referans alarak devam edebilirsiniz.