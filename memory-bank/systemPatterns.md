# JetX Predictor - Sistem Patternleri

## Mimari Genel BakÄ±ÅŸ

### 1. KatmanlÄ± Mimari

#### Presentation Layer (Streamlit)
```
app.py (Ana UI)
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_ðŸ“Š_Analiz.py (Veri analizi)
â”‚   â”œâ”€â”€ 2_ðŸ”¬_Model_Karsilastirma.py (Model karÅŸÄ±laÅŸtÄ±rma)
â”‚   â””â”€â”€ cpu/ (CPU modelleri iÃ§in Ã¶zel sayfalar)
â””â”€â”€ components/
    â”œâ”€â”€ Prediction Display
    â”œâ”€â”€ Risk Analysis
    â””â”€â”€ Performance Charts
```

#### Business Logic Layer (Utils)
```
utils/
â”œâ”€â”€ Core Prediction
â”‚   â”œâ”€â”€ predictor.py (Ana tahmin motoru)
â”‚   â”œâ”€â”€ ensemble_predictor.py (Ensemble sistemi)
â”‚   â””â”€â”€ consensus_predictor.py (Consensus voting)
â”œâ”€â”€ Model Management
â”‚   â”œâ”€â”€ all_models_predictor.py (TÃ¼m modeller)
â”‚   â”œâ”€â”€ model_loader.py (Model yÃ¼kleme)
â”‚   â””â”€â”€ model_versioning.py (Versiyon yÃ¶netimi)
â”œâ”€â”€ Risk Management
â”‚   â”œâ”€â”€ risk_manager.py (Risk analizi)
â”‚   â”œâ”€â”€ advanced_bankroll.py (Kelly Criterion)
â”‚   â””â”€â”€ dual_bankroll_system.py (Ä°kili kasa)
â”œâ”€â”€ Data Processing
â”‚   â”œâ”€â”€ database.py (VeritabanÄ± yÃ¶netimi)
â”‚   â”œâ”€â”€ category_definitions.py (Feature extraction)
â”‚   â””â”€â”€ multi_scale_window.py (Multi-scale windows)
â””â”€â”€ Analysis & Monitoring
    â”œâ”€â”€ backtesting.py (GeÃ§miÅŸ performans)
    â”œâ”€â”€ psychological_analyzer.py (Psikolojik analiz)
    â””â”€â”€ anomaly_streak_detector.py (Anomali tespiti)
```

#### Data Layer (SQLite + Models)
```
data/
â”œâ”€â”€ jetx_data.db (SQLite veritabanÄ±)
â””â”€â”€ cache/ (Ã–nbellek)
models/
â”œâ”€â”€ progressive_multiscale/ (NN modelleri)
â”œâ”€â”€ catboost_multiscale/ (CatBoost modelleri)
â””â”€â”€ cpu/ (CPU optimize modelleri)
```

## 2. Model Ensemble Patterni

### Multi-Model Stratejisi

#### 1. Weighted Voting (VarsayÄ±lan)
```python
final_prediction = (
    0.60 * catboost_prediction +  # %60 aÄŸÄ±rlÄ±k
    0.40 * neural_network_prediction  # %40 aÄŸÄ±rlÄ±k
)
```

#### 2. Unanimous Voting
```python
if catboost_pred == neural_pred:
    final_prediction = catboost_pred
else:
    skip_bet = True  # Fikir ayrÄ±lÄ±ÄŸÄ± varsa bekle
```

#### 3. Confidence-Based Voting
```python
if catboost_confidence > neural_confidence:
    final_prediction = catboost_prediction
else:
    final_prediction = neural_network_prediction
```

#### 4. Majority Voting
```python
predictions = [catboost, neural, autogluon, tabnet]
final_prediction = mode(predictions)  # En Ã§ok oylanmÄ±ÅŸ
```

### Multi-Scale Ensemble Patterni

#### Window Size Stratejisi
```python
window_weights = {
    20: 0.10,   # KÄ±sa dÃ¶nem (lokal volatilite)
    50: 0.15,   # KÄ±sa-orta dÃ¶nem
    100: 0.30,  # Orta dÃ¶nem (en yÃ¼ksek aÄŸÄ±rlÄ±k)
    250: 0.25,  # Orta-uzun dÃ¶nem
    500: 0.20   # Uzun dÃ¶nem (genel trend)
}

final_prediction = sum(weights[ws] * predictions[ws] for ws in window_sizes)
```

#### Model Adaptasyon Patterni
- **KÃ¼Ã§Ã¼k Pencereler (â‰¤50)**: Basit LSTM, hÄ±zlÄ± Ã¶ÄŸrenme
- **Orta Pencereler (â‰¤100)**: 2-layer LSTM, attention
- **BÃ¼yÃ¼k Pencereler (>100)**: 3-layer LSTM + attention mechanism

## 3. Veri AkÄ±ÅŸ Patternleri

### Time Series Data Flow
```
1. Manuel Input â†’ SQLite Database
2. Database Query â†’ Feature Extraction (150+ features)
3. Feature Processing â†’ Model Input Preparation
4. Model Prediction â†’ Confidence Scoring
5. Risk Analysis â†’ User Interface
6. Result Input â†’ Database Update â†’ Model Learning
```

### Feature Engineering Pipeline
```python
# 1. Temel Ä°statistikler
basic_stats = extract_basic_statistics(history)

# 2. Multi-Scale Windows
windows = create_multi_scale_windows(history, [20, 50, 100, 250, 500])

# 3. Advanced Features
advanced_features = {
    'volatility': calculate_volatility(history),
    'streaks': extract_streak_patterns(history),
    'threshold_analysis': analyze_threshold_patterns(history, 1.5),
    'psychological': analyze_psychological_patterns(history)
}

# 4. Feature BirleÅŸtirme
all_features = combine_features(basic_stats, windows, advanced_features)
```

### Data Validation Pattern
```python
def validate_input_data(data):
    # Minimum veri kontrolÃ¼
    if len(data) < 50:
        raise ValueError("En az 50 veri noktasÄ± gerekli")
    
    # Veri aralÄ±ÄŸÄ± kontrolÃ¼
    if not all(1.0 <= x <= 10000.0 for x in data):
        raise ValueError("Veri 1.0-10000.0 aralÄ±ÄŸÄ±nda olmalÄ±")
    
    # Kronolojik sÄ±ra kontrolÃ¼
    if not is_chronological(data):
        raise ValueError("Veri kronolojik sÄ±ralÄ± olmalÄ±")
    
    return True
```

## 4. Risk Management Patternleri

### ÃœÃ§ KatmanlÄ± Risk Sistemi

#### Level 1: Prediction Confidence
```python
confidence_thresholds = {
    'aggressive': 0.50,  # YÃ¼ksek risk, yÃ¼ksek potansiyel
    'normal': 0.65,     # Dengeli risk-getiri oranÄ±
    'rolling': 0.80      # DÃ¼ÅŸÃ¼k risk, konservatif
}

if confidence < confidence_thresholds[mode]:
    return {'should_play': False, 'reason': 'DÃ¼ÅŸÃ¼k gÃ¼ven skoru'}
```

#### Level 2: Consecutive Loss Tracking
```python
max_consecutive_losses = {
    'aggressive': 5,
    'normal': 3,
    'rolling': 2
}

if consecutive_losses >= max_consecutive_losses[mode]:
    return {'should_play': False, 'reason': 'ArdÄ±ÅŸÄ±k kayÄ±p limiti'}
```

#### Level 3: Bankroll Management
```python
# Kelly Criterion
kelly_fraction = (win_prob * win_multiplier - loss_prob) / win_multiplier
optimal_bet = bankroll * max(kelly_fraction, 0.25)  # Max %25

# Stop-Loss / Take-Profit
if cumulative_loss > stop_loss_threshold:
    force_stop_trading()
if cumulative_profit > take_profit_threshold:
    secure_profits()
```

## 5. Model Training Patternleri

### Google Colab â†’ Lokal Pipeline

#### Colab Training Pattern
```python
# 1. Veri HazÄ±rlÄ±ÄŸÄ±
data = load_from_sqlite()
X_train, X_val, X_test = time_series_split(data, [0.7, 0.15, 0.15])

# 2. Multi-Scale Training
for window_size in [500, 250, 100, 50, 20]:
    model = create_model_for_window(window_size)
    train_model(model, X_train, X_val)
    save_model(model, f'model_window_{window_size}.h5')

# 3. Ensemble DeÄŸerlendirmesi
ensemble_score = evaluate_ensemble(all_models, X_test)
save_best_models(ensemble_score)

# 4. ZIP ve Ä°ndirme
create_model_zip()
files.download('jetx_models_v3.0.zip')
```

#### Lokal Loading Pattern
```python
# 1. Otomatik Model Tespiti
available_models = scan_models_directory()
model_registry = create_model_registry(available_models)

# 2. Versiyon YÃ¶netimi
production_models = get_production_models()
latest_version = get_latest_version('progressive_nn')

# 3. Dinamik YÃ¼kleme
if production_models:
    load_production_models()
else:
    load_available_models_with_fallback()
```

### Training Optimization Patternleri

#### Learning Rate Scheduling
```python
# Cosine Annealing
lr_schedule = CosineAnnealingSchedule(
    initial_lr=0.001,
    max_lr=0.01,
    min_lr=0.0001,
    steps_per_epoch=len(X_train)//batch_size
)

# Adaptive Weight Scheduling
weight_scheduler = AdaptiveWeightScheduler(
    metrics=['val_accuracy', 'val_roi'],
    patience=10,
    factor=0.5
)
```

#### Early Stopping Pattern
```python
early_stopping = EarlyStopping(
    monitor='val_stability_score',  # Sadece loss deÄŸil
    patience=15,
    restore_best_weights=True,
    min_delta=0.01,
    mode='max'
)
```

## 6. Error Handling Patternleri

### KatmanlÄ± Error Management

#### Level 1: Input Validation
```python
try:
    prediction = predict(history)
except ValueError as e:
    logger.error(f"Input validation hatasÄ±: {e}")
    return {'error': 'GeÃ§ersiz veri', 'suggestion': 'Veri formatÄ±nÄ± kontrol edin'}
except IndexError as e:
    logger.error(f"Veri uzunluÄŸu hatasÄ±: {e}")
    return {'error': 'Yetersiz veri', 'suggestion': 'En az 50 veri noktasÄ± gerekli'}
```

#### Level 2: Model Error Recovery
```python
try:
    result = model.predict(input_data)
except ModelLoadError:
    logger.warning("Ana model yÃ¼klenemedi, fallback model deneniyor")
    result = fallback_model.predict(input_data)
except PredictionError:
    logger.error("Tahmin hatasÄ±, ensemble deneniyor")
    result = ensemble_predictor.predict(input_data)
```

#### Level 3: Graceful Degradation
```python
if primary_model.confidence < 0.5:
    # Ana model dÃ¼ÅŸÃ¼k gÃ¼ven veriyorsa
    if secondary_model.available:
        result = secondary_model.predict(input_data)
    else:
        result = conservative_strategy.default_prediction()
```

## 7. Performance Monitoring Patternleri

### Real-time Monitoring
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics_history = []
        self.alert_thresholds = {
            'accuracy_drop': 0.10,  # %10 dÃ¼ÅŸÃ¼ÅŸ
            'confidence_drop': 0.15,  # %15 dÃ¼ÅŸÃ¼ÅŸ
            'consecutive_losses': 5
        }
    
    def check_performance(self, current_metrics):
        alerts = []
        for metric, threshold in self.alert_thresholds.items():
            if self.detect_drop(metric, current_metrics[metric], threshold):
                alerts.append(f"{metric} dÃ¼ÅŸÃ¼ÅŸ tespiti")
        return alerts
```

### Model Drift Detection
```python
def detect_model_drift(recent_predictions, historical_performance):
    current_accuracy = calculate_accuracy(recent_predictions)
    historical_avg = historical_performance['avg_accuracy']
    
    drift_threshold = 0.15  # %15 fark
    
    if abs(current_accuracy - historical_avg) > drift_threshold:
        return {
            'drift_detected': True,
            'severity': 'high' if abs(current_accuracy - historical_avg) > 0.25 else 'medium',
            'suggestion': 'Model yeniden eÄŸitimi Ã¶neriliyor'
        }
    
    return {'drift_detected': False}
```

## 8. Configuration Management Patternleri

### Hierarchical Configuration
```yaml
# config/config.yaml (Ana konfigÃ¼rasyon)
database:
  path: "data/jetx_data.db"
  
model:
  path: "models/jetx_model.h5"
  scaler_path: "models/scaler.pkl"
  
prediction:
  confidence_thresholds:
    aggressive: 0.50
    normal: 0.65
    rolling: 0.80

# config/cpu_models_config.yaml (CPU modelleri)
models:
  lightgbm:
    enabled: true
    parameters: {...}
  tabnet:
    enabled: true
    parameters: {...}
```

### Environment-Specific Configuration
```python
class ConfigLoader:
    def __init__(self, environment='development'):
        self.config = self.load_config()
        self.environment = environment
        self.apply_environment_overrides()
    
    def apply_environment_overrides(self):
        if self.environment == 'production':
            self.config['logging']['level'] = 'WARNING'
            self.config['debug']['enabled'] = False
        elif self.environment == 'development':
            self.config['logging']['level'] = 'DEBUG'
            self.config['debug']['enabled'] = True
```

## 9. Testing Patternleri

### Multi-Level Testing Strategy

#### Unit Tests
```python
def test_feature_extraction():
    # Feature extraction doÄŸruluÄŸu
    sample_data = [1.2, 1.5, 2.1, 1.8, 3.2]
    features = extract_features(sample_data)
    assert len(features) == 150, "150 feature bekleniyordu"
    assert 'volatility' in features, "Volatilite feature eksik"

def test_risk_management():
    # Risk yÃ¶netimi mantÄ±ÄŸÄ±
    assert risk_manager.should_play({'confidence': 0.3}) == False
    assert risk_manager.should_play({'confidence': 0.8}) == True
```

#### Integration Tests
```python
def test_full_pipeline():
    # Tam pipeline testi
    # 1. Veri giriÅŸi
    db.add_result(1.5)
    
    # 2. Tahmin
    prediction = predictor.predict(db.get_recent_results(100))
    
    # 3. Risk analizi
    risk = risk_manager.should_play(prediction)
    
    # 4. SonuÃ§ gÃ¼ncelleme
    db.update_prediction_result(prediction['id'], 2.0, risk['was_correct'])
    
    assert prediction['predicted_value'] > 0
    assert 'confidence' in prediction
```

#### Performance Tests
```python
def test_prediction_speed():
    # Tahmin hÄ±zÄ± testi
    start_time = time.time()
    for _ in range(100):
        predictor.predict(large_history_dataset)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / 100
    assert avg_time < 1.0, "Tahmin <1 saniye olmalÄ±"
```

---

*Bu belge sistemin temel tasarÄ±m patternlerini, mimari kararlarÄ±nÄ± ve en iyi uygulamalarÄ±nÄ± tanÄ±mlar. TÃ¼m geliÅŸtirme bu patternlere uygun olmalÄ±dÄ±r.*
