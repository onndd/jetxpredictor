# ğŸš€ JetX Model EÄŸitimi - Google Colab (v7.3 FIXED)

**6 Model Ensemble Sistemi ile JetX tahmin modellerini eÄŸitin - Dependency Conflict RESOLVED!**

---

## ğŸ†• v7.3 YENÄ° Ã–ZELLÄ°KLER

- ğŸ”§ **DEPENDENCY CONFLICT FIXED**: Torch/Torchaudio version compatibility resolved
- âš¡ **Smart Package Installation**: Sequential and secure package installation
- ğŸ›¡ï¸ **Version Locking**: All critical packages version-locked
- ğŸ”„ **Clean Installation**: Conflicting packages removed
- ğŸ¯ **CUDA Detection**: Automatic GPU/CPU detection and optimization
- ğŸ“Š **Environment Validation**: Comprehensive version checking

---

## ğŸ“‹ Model AÃ§Ä±klamalarÄ±

| Model | GÃ¶rev | Ã–zellik | Hedef |
|-------|-------|---------|-------|
| **Progressive NN** | Genel amaÃ§lÄ± tahmin | 5 farklÄ± pencere boyutu | 1.5x eÅŸik tahmini |
| **CatBoost** | Gradient boosting | Multi-scale window | 1.5x eÅŸik + kategori |
| **AutoGluon** | AutoML champion | 50+ model ensemble | 1.5x eÅŸik tahmini |
| **TabNet** | YÃ¼ksek X uzmanÄ± | Attention mechanism | Multi-class tahmin |
| **Consensus** | Ensemble final | Weighted voting | En yÃ¼ksek doÄŸruluk |
| **RL Agent** | Meta-model | Policy gradient | En kÃ¢rlÄ± aksiyon seÃ§imi |

---

## ğŸ¯ Hedefler

- âœ… 1.5 AltÄ± DoÄŸruluk: **75%+**
- âœ… 1.5 ÃœstÃ¼ DoÄŸruluk: **75%+**
- âœ… Para KaybÄ± Riski: **<20%**
- âœ… ROI: **Pozitif**

## ğŸ“¦ AdÄ±m 1: HazÄ±rlÄ±k ve Kurulum (DEPENDENCY FIXED)

Bu adÄ±mda:

- Google Drive baÄŸlantÄ±sÄ± yapÄ±lÄ±r
- Ã‡akÄ±ÅŸan paketler temizlenir
- Gerekli kÃ¼tÃ¼phaneler doÄŸru sÄ±rada yÃ¼klenir
- Dizin kontrolÃ¼ yapÄ±lÄ±r (GitHub'dan aÃ§ma desteÄŸi)

import subprocess
import sys
import os
import json
import time
from datetime import datetime

print("="*80)
print("ğŸ“¦ HAZIRLIK - 6 Model Ensemble Sistem v7.3 (DEPENDENCY FIXED)")
print("ğŸ”§ Torch/Torchaudio Conflict RESOLVED")
print("="*80)

start_time = time.time()

# Google Drive BaÄŸlantÄ±sÄ±
print("\nğŸ“ Google Drive baÄŸlanÄ±yor...")
try:
    from google.colab import drive
    drive.mount('/content/drive')
    print("âœ… Google Drive baÅŸarÄ±yla baÄŸlandÄ±!")
    
    drive_path = '/content/drive/MyDrive/JetX_Models_v7_3'
    os.makedirs(drive_path, exist_ok=True)
    print(f"âœ… Drive klasÃ¶rÃ¼ oluÅŸturuldu: {drive_path}")
except Exception as e:
    print(f"âš ï¸ Drive baÄŸlantÄ± hatasÄ±: {e}")
    drive_path = None

# GPU OPTIMIZASYONU
print("\nğŸš€ GPU OPTÄ°MÄ°ZASYONU BAÅLATILIYOR...")
try:
    sys.path.append(os.getcwd())
    from utils.gpu_optimizer import setup_colab_gpu_optimization
    
    gpu_results = setup_colab_gpu_optimization()
    print("âœ… GPU optimizasyonlarÄ± tamamlandÄ±!")
    
except ImportError:
    print("âš ï¸ GPU optimizer modÃ¼lÃ¼ bulunamadÄ±, manuel optimizasyonlar uygulanÄ±yor...")
    
    # Manuel GPU optimizasyonlarÄ±
    try:
        import tensorflow as tf
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print("âœ… TensorFlow GPU memory growth aktif")
            
            # Mixed precision
            from tensorflow.keras import mixed_precision
            mixed_precision.set_global_policy('mixed_float16')
            print("âœ… TensorFlow mixed precision aktif")
        
    except Exception as e:
        print(f"âš ï¸ Manuel GPU optimizasyon hatasÄ±: {e}")
    
    # PyTorch GPU optimizasyonu
    try:
        import torch
        if torch.cuda.is_available():
            torch.backends.cudnn.benchmark = True
            torch.cuda.empty_cache()
            print("âœ… PyTorch GPU optimizasyonlarÄ± aktif")
    except:
        pass


# Ã–NCE Ã‡AKIÅAN PAKETLERÄ° TEMÄ°ZLE
print("\nğŸ§¹ Ã–nce eski paketler temizleniyor...")

# PyTorch ve ilgili paketleri tamamen temizle
pytorch_packages = ['torch', 'torchaudio', 'torchvision', 'pytorch-tabnet']
for package in pytorch_packages:
    try:
        subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", package], 
                      check=False, capture_output=True)
        print(f"   - {package} temizlendi")
    except:
        pass

# TensorFlow ve ilgili paketleri temizle (Ã§akÄ±ÅŸmalarÄ± Ã¶nlemek iÃ§in)
tensorflow_packages = ['tensorflow', 'tensorflow-gpu']
for package in tensorflow_packages:
    try:
        subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", package], 
                      check=False, capture_output=True)
        print(f"   - {package} temizlendi")
    except:
        pass

print("âœ… Paket temizleme tamamlandÄ±")

# TEMEL PAKETLERÄ° Ã–NCE YÃœKLE (PyTorch baÄŸÄ±msÄ±z)
print("\nğŸ“¦ Temel paketler yÃ¼kleniyor...")
basic_packages = [
    'numpy>=1.24.0',
    'pandas>=2.0.0', 
    'scipy>=1.10.0',
    'scikit-learn>=1.3.0',
    'joblib>=1.3.0',
    'matplotlib>=3.7.0',
    'seaborn>=0.12.0',
    'pyyaml>=6.0',
    'python-dateutil>=2.8.0',
    'tqdm>=4.65.0'
]

for package in basic_packages:
    try:
        subprocess.run([sys.executable, "-m", "pip", "install", "-q", package], 
                      check=True)
        print(f"   âœ… {package}")
    except subprocess.CalledProcessError as e:
        print(f"   âŒ {package}: {e}")

# PYTORCH EKOSÄ°STEMÄ°NÄ° DOÄRU SIRAYLA YÃœKLE
print("\nğŸ”¥ PyTorch ekosistemi yÃ¼kleniyor (Fixed Versions)...")

# CUDA kontrolÃ¼
try:
    import torch
    if torch.cuda.is_available():
        cuda_version = torch.version.cuda
        print(f"   ğŸ¯ CUDA {cuda_version} tespit edildi")
        
        if cuda_version == "12.1":
            torch_index = "https://download.pytorch.org/whl/cu121"
            torch_version = "2.2.0+cu121"
            torchaudio_version = "2.2.0+cu121"
        elif cuda_version == "12.0":
            torch_index = "https://download.pytorch.org/whl/cu120"
            torch_version = "2.2.0+cu120"
            torchaudio_version = "2.2.0+cu120"
        elif cuda_version == "11.8":
            torch_index = "https://download.pytorch.org/whl/cu118"
            torch_version = "2.1.0+cu118"
            torchaudio_version = "2.1.0+cu118"
        else:
            # VarsayÄ±lan olarak CUDA 11.8 kullan
            torch_index = "https://download.pytorch.org/whl/cu118"
            torch_version = "2.1.0+cu118"
            torchaudio_version = "2.1.0+cu118"
    else:
        # CPU only
        torch_index = "https://download.pytorch.org/whl/cpu"
        torch_version = "2.1.0+cpu"
        torchaudio_version = "2.1.0+cpu"
        print("   ğŸ’» CUDA bulunamadÄ±, CPU versiyonu kullanÄ±lacak")
        
except ImportError:
    # Torch henÃ¼z yÃ¼klÃ¼ deÄŸil, varsayÄ±lan CUDA 11.8 kullan
    torch_index = "https://download.pytorch.org/whl/cu118"
    torch_version = "2.1.0+cu118"
    torchaudio_version = "2.1.0+cu118"
    print("   ï¿½ VarsayÄ±lan CUDA 11.8 kullanÄ±lacak")

# PyTorch kurulumu
try:
    subprocess.run([
        sys.executable, "-m", "pip", "install", "-q", 
        f"torch=={torch_version}",
        f"torchaudio=={torchaudio_version}",
        "--index-url", torch_index
    ], check=True)
    print(f"   âœ… PyTorch {torch_version}")
    print(f"   âœ… TorchAudio {torchaudio_version}")
except subprocess.CalledProcessError as e:
    print(f"   âŒ PyTorch kurulumu baÅŸarÄ±sÄ±z: {e}")
    print("   ğŸ”„ CPU versiyonu deneniyor...")
    try:
        subprocess.run([
            sys.executable, "-m", "pip", "install", "-q", 
            "torch==2.1.0+cpu",
            "torchaudio==2.1.0+cpu",
            "--index-url", "https://download.pytorch.org/whl/cpu"
        ], check=True)
        print("   âœ… PyTorch CPU versiyonu yÃ¼klendi")
    except:
        print("   âŒ PyTorch kurulumu tamamen baÅŸarÄ±sÄ±z")

# PyTorch tabnet kurulumu
try:
    subprocess.run([sys.executable, "-m", "pip", "install", "-q", "pytorch-tabnet==4.1.0"], 
                  check=True)
    print("   âœ… PyTorch TabNet")
except subprocess.CalledProcessError as e:
    print(f"   âŒ TabNet: {e}")

# TENSORFLOW KURULUMU (PyTorch'dan sonra)
print("\nğŸ§  TensorFlow yÃ¼kleniyor...")
try:
    subprocess.run([sys.executable, "-m", "pip", "install", "-q", "tensorflow==2.14.0"], 
                  check=True)
    print("   âœ… TensorFlow 2.14.0")
except subprocess.CalledProcessError as e:
    print(f"   âŒ TensorFlow: {e}")

# DÄ°ÄER GELÄ°ÅMÄ°Å PAKETLER
print("\nğŸš€ GeliÅŸmiÅŸ paketler yÃ¼kleniyor...")
advanced_packages = [
    'catboost>=1.2.0',
    'plotly>=5.17.0',
    'optuna>=3.0.0',
    'PyWavelets>=1.4.1',
    'nolds>=0.5.2'
]

for package in advanced_packages:
    try:
        subprocess.run([sys.executable, "-m", "pip", "install", "-q", package], 
                      check=True)
        print(f"   âœ… {package}")
    except subprocess.CalledProcessError as e:
        print(f"   âŒ {package}: {e}")

# AUTOGLUON KURULUMU (En sona)
print("\nğŸ¤– AutoGluon yÃ¼kleniyor...")
try:
    subprocess.run([sys.executable, "-m", "pip", "install", "-q", "autogluon>=0.8.0"], 
                  check=True)
    print("   âœ… AutoGluon")
except subprocess.CalledProcessError as e:
    print(f"   âŒ AutoGluon: {e}")

# Proje klonlama
print("\nğŸ“¥ Proje klonlanÄ±yor...")
if not os.path.exists('jetxpredictor'):
    !git clone https://github.com/onndd/jetxpredictor.git
    print("âœ… Proje baÅŸarÄ±yla klonlandÄ±!")
else:
    print("âœ… Proje zaten mevcut")

# Dizin kontrolÃ¼
print("\nğŸ“‚ Dizin kontrolÃ¼ yapÄ±lÄ±yor...")
print(f"Mevcut dizin: {os.getcwd()}")

if os.path.exists('jetx_data.db'):
    print("âœ… Proje kÃ¶k dizinindeyiz!")
elif os.path.exists('../jetx_data.db'):
    print("ğŸ“ Bir Ã¼st dizine Ã§Ä±kÄ±lÄ±yor...")
    os.chdir('..')
    print(f"âœ… Proje kÃ¶k dizinine geÃ§ildi: {os.getcwd()}")
elif os.path.exists('jetxpredictor/jetx_data.db'):
    print("ğŸ“ jetxpredictor klasÃ¶rÃ¼ne giriliyor...")
    os.chdir('jetxpredictor')
    print(f"âœ… Proje kÃ¶k dizinine geÃ§ildi: {os.getcwd()}")
else:
    print("âš ï¸ UYARI: jetx_data.db bulunamadÄ±!")
    print(f"ğŸ“‚ Mevcut dizin iÃ§eriÄŸi: {os.listdir('.')}")

# Models klasÃ¶rÃ¼nÃ¼ kontrol et ve oluÅŸtur
if not os.path.exists('models'):
    os.makedirs('models')
    print("âœ… models/ klasÃ¶rÃ¼ oluÅŸturuldu")
else:
    print("âœ… models/ klasÃ¶rÃ¼ mevcut")

# Versiyon kontrolÃ¼
print("\nğŸ” Versiyon kontrolÃ¼ yapÄ±lÄ±yor...")
try:
    import torch
    print(f"   PyTorch: {torch.__version__}")
    if torch.cuda.is_available():
        print(f"   CUDA: {torch.version.cuda}")
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("   CUDA: Mevcut deÄŸil")
except ImportError:
    print("   PyTorch: YÃ¼klÃ¼ deÄŸil")

try:
    import tensorflow as tf
    print(f"   TensorFlow: {tf.__version__}")
except ImportError:
    print("   TensorFlow: YÃ¼klÃ¼ deÄŸil")

try:
    import catboost
    print(f"   CatBoost: {catboost.__version__}")
except ImportError:
    print("   CatBoost: YÃ¼klÃ¼ deÄŸil")

try:
    import autogluon
    print(f"   AutoGluon: {autogluon.__version__}")
except ImportError:
    print("   AutoGluon: YÃ¼klÃ¼ deÄŸil")

prep_time = time.time() - start_time
print(f"\nâœ… HazÄ±rlÄ±k tamamlandÄ±! ({prep_time/60:.1f} dakika)")
print(f"ğŸ“‚ Ã‡alÄ±ÅŸma dizini: {os.getcwd()}")
print("="*80)

## ğŸ“Š AdÄ±m 2: Veri YÃ¼kleme ve HazÄ±rlÄ±k

VeritabanÄ±ndan veri yÃ¼klenip train/val/test olarak bÃ¶lÃ¼nÃ¼r.

import numpy as np
import pandas as pd
import sqlite3
from sklearn.preprocessing import StandardScaler
import sys
sys.path.append(os.getcwd())

from category_definitions import CategoryDefinitions, FeatureEngineering
from utils.multi_scale_window import split_data_preserving_order

print("="*80)
print("ğŸ“Š VERÄ° YÃœKLEME")
print("="*80)

conn = sqlite3.connect('jetx_data.db')
data = pd.read_sql_query("SELECT value FROM jetx_results ORDER BY id", conn)
conn.close()

all_values = data['value'].values
print(f"Ã¢ÂœÂ… {len(all_values):,} veri yÃƒÂ¼klendi")

# Time-series split
train_data, val_data, test_data = split_data_preserving_order(
    all_values, train_ratio=0.70, val_ratio=0.15
)

print(f"Ã¢ÂœÂ… Train: {len(train_data):,}")
print(f"Ã¢ÂœÂ… Val:   {len(val_data):,}")
print(f"Ã¢ÂœÂ… Test:  {len(test_data):,}")
print("="*80)

## Ã°ÂŸÂ§Â  AdÃ„Â±m 3: Progressive NN Training

Multi-scale window ensemble ile Progressive Neural Network eÃ„ÂŸitimi.

print("="*80)
print("Ã°ÂŸÂ§Â  PROGRESSIVE NN TRAINING")
print("="*80)

!python notebooks/jetx_PROGRESSIVE_TRAINING_MULTISCALE.py

# SonuÃƒÂ§larÃ„Â± yÃƒÂ¼kle
with open('models/progressive_multiscale/model_info.json', 'r') as f:
    progressive_results = json.load(f)

print("\nÃ¢ÂœÂ… Progressive NN TamamlandÃ„Â±!")
print(f"Ã°ÂŸÂ“ÂŠ MAE: {progressive_results['ensemble_metrics']['mae']:.4f}")

## Ã°ÂŸÂšÂ€ AdÃ„Â±m 4: CatBoost Training

Gradient boosting uzmanÃ„Â± CatBoost modeli eÃ„ÂŸitimi.

print("="*80)
print("Ã°ÂŸÂšÂ€ CATBOOST TRAINING")
print("="*80)

!python notebooks/jetx_CATBOOST_TRAINING_MULTISCALE.py

with open('models/catboost_multiscale/model_info.json', 'r') as f:
    catboost_results = json.load(f)

print("\nÃ¢ÂœÂ… CatBoost TamamlandÃ„Â±!")

## Ã°ÂŸÂ¤Â– AdÃ„Â±m 5: AutoGluon AutoML Training

50+ modeli otomatik deneyen AutoGluon AutoML eÃ„ÂŸitimi.

import warnings
warnings.filterwarnings('ignore')

from utils.autogluon_predictor import AutoGluonPredictor

print("="*80)
print("Ã°ÂŸÂ¤Â– AUTOGLUON AUTOML TRAINING")
print("="*80)

# Feature extraction
window_size = 100
X_features = []
y_labels = []

for i in range(window_size, len(train_data) - 1):
    hist = train_data[:i].tolist()
    target = train_data[i]
    feats = FeatureEngineering.extract_all_features(hist)
    X_features.append(feats)
    y_labels.append(1 if target >= 1.5 else 0)

X_train_ag = pd.DataFrame(X_features)
y_train_ag = pd.Series(y_labels, name='above_threshold')

print(f"âœ… {len(X_train_ag):,} Ã¶rnek hazÄ±rlandÄ±")

# AutoGluon predictor
ag_predictor = AutoGluonPredictor(
    model_path='models/autogluon_model',
    threshold=1.5
)

# Train
ag_results = ag_predictor.train(
    X_train=X_train_ag,
    y_train=y_train_ag,
    time_limit=3600,
    presets='best_quality',
    eval_metric='roc_auc'
)

print("\nâœ… AutoGluon TamamlandÄ±!")
print(f"ğŸ† En Ä°yi Model: {ag_results['best_model']}")
print(f"ğŸ“Š Score: {ag_results['best_score']:.4f}")

# Save info
autogluon_info = {
    'model': 'AutoGluon_AutoML',
    'version': '1.0',
    'date': datetime.now().strftime('%Y-%m-%d'),
    'best_model': ag_results['best_model'],
    'best_score': float(ag_results['best_score'])
}

os.makedirs('models/autogluon_model', exist_ok=True)
with open('models/autogluon_model/model_info.json', 'w') as f:
    json.dump(autogluon_info, f, indent=2)

## ğŸ¯ AdÄ±m 6: TabNet High-X Specialist Training

Attention mechanism ile yÃ¼ksek Ã§arpanlarÄ± tespit eden TabNet eÄŸitimi.

from utils.tabnet_predictor import TabNetHighXPredictor

print("="*80)
print("ğŸ¯ TABNET HIGH-X SPECIALIST TRAINING")
print("="*80)

# Feature extraction
window_size = 100
X_features_tn = []
y_categories = []

for i in range(window_size, len(train_data) - 1):
    hist = train_data[:i].tolist()
    target = train_data[i]
    feats = FeatureEngineering.extract_all_features(hist)
    X_features_tn.append(list(feats.values()))
    category = TabNetHighXPredictor.categorize_value(target)
    y_categories.append(category)

X_train_tn = np.array(X_features_tn)
y_train_tn = np.array(y_categories)

scaler_tn = StandardScaler()
X_train_tn = scaler_tn.fit_transform(X_train_tn)

print(f"âœ… {len(X_train_tn):,} Ã¶rnek hazÄ±rlandÄ±")

# Validation set
X_val_tn = []
y_val_tn = []

for i in range(window_size, len(val_data) - 1):
    hist = val_data[:i].tolist()
    target = val_data[i]
    feats = FeatureEngineering.extract_all_features(hist)
    X_val_tn.append(list(feats.values()))
    y_val_tn.append(TabNetHighXPredictor.categorize_value(target))

X_val_tn = scaler_tn.transform(np.array(X_val_tn))
y_val_tn = np.array(y_val_tn)

# TabNet predictor
tabnet_predictor = TabNetHighXPredictor(
    model_path='models/tabnet_high_x.pkl',
    scaler_path='models/tabnet_scaler.pkl'
)

# Train
tn_results = tabnet_predictor.train(
    X_train=X_train_tn,
    y_train=y_train_tn,
    X_val=X_val_tn,
    y_val=y_val_tn,
    max_epochs=200,
    patience=20,
    batch_size=256
)

print("\nâœ… TabNet TamamlandÄ±!")
print(f"ğŸ† Best Epoch: {tn_results['best_epoch']}")

# Save
tabnet_predictor.save_model()
tabnet_predictor.save_scaler(scaler_tn)

tabnet_info = {
    'model': 'TabNet_HighX_Specialist',
    'version': '1.0',
    'date': datetime.now().strftime('%Y-%m-%d'),
    'best_epoch': int(tn_results['best_epoch']),
    'best_cost': float(tn_results['best_cost'])
}

with open('models/tabnet_info.json', 'w') as f:
    json.dump(tabnet_info, f, indent=2)

## ğŸ¤– AdÄ±m 7: RL Agent Training

Reinforcement Learning Agent eÄŸitimi. TÃ¼m model Ã§Ä±ktÄ±larÄ±nÄ± birleÅŸtirerek en kÃ¢rlÄ± aksiyonu seÃ§er.

print("="*80)
print("ğŸ¤– RL AGENT TRAINING")
print("="*80)

!python notebooks/train_rl_agent.py

# SonuÃ§larÄ± yÃ¼kle
try:
    with open('models/rl_agent_info.json', 'r') as f:
        rl_agent_info = json.load(f)
    print("\nâœ… RL Agent TamamlandÄ±!")
    print(f"ğŸ“Š Accuracy: {rl_agent_info.get('accuracy', 0):.2%}")
    print(f"ğŸ“Š Action Distribution: {rl_agent_info.get('action_distribution', [0, 0, 0, 0])}")
except Exception as e:
    print(f"\nâš ï¸ RL Agent info yÃ¼klenemedi: {e}")
    rl_agent_info = None

## ğŸ’¾ AdÄ±m 8: SonuÃ§larÄ± Kaydetme ve Ä°ndirme

TÃ¼m modeller ZIP'lenir ve indirilir. Google Drive'a yedekleme yapÄ±lÄ±r.

import shutil

print("="*80)
print("ğŸ’¾ SONUÃ‡LAR KAYDEDÄ°LÄ°YOR")
print("="*80)

# JSON sonuÃ§larÄ±
final_results = {
    'metadata': {
        'version': '7.3',
        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'fix': 'Dependency conflicts resolved',
        'installation': 'Smart sequential package installation'
    },
    'models': {
        'progressive_nn': progressive_results if 'progressive_results' in locals() else None,
        'catboost': catboost_results if 'catboost_results' in locals() else None,
        'autogluon': autogluon_info if 'autogluon_info' in locals() else None,
        'tabnet': tabnet_info if 'tabnet_info' in locals() else None,
        'rl_agent': rl_agent_info if 'rl_agent_info' in locals() else None
    }
}

with open('models/all_models_results_v7_fixed.json', 'w') as f:
    json.dump(final_results, f, indent=2)

print("âœ… JSON sonuÃ§larÄ± kaydedildi")

# Lokal Streamlit uyumluluÄŸu iÃ§in dosya isimlendirme
print("\nğŸ“ Lokal kullanÄ±m iÃ§in dosyalar hazÄ±rlanÄ±yor...")

# Progressive NN modelini ana model olarak kopyala
if os.path.exists('models/progressive_multiscale/ensemble_model.h5'):
    shutil.copy('models/progressive_multiscale/ensemble_model.h5', 'models/jetx_model.h5')
    print("âœ… jetx_model.h5 oluÅŸturuldu")

if os.path.exists('models/progressive_multiscale/scaler.pkl'):
    shutil.copy('models/progressive_multiscale/scaler.pkl', 'models/scaler.pkl')
    print("âœ… scaler.pkl oluÅŸturuldu")

# ZIP oluÅŸtur
zip_filename = f'jetx_6models_v7_fixed_{datetime.now().strftime("%Y%m%d_%H%M")}'
shutil.make_archive(zip_filename, 'zip', 'models')

print(f"\nâœ… ZIP oluÅŸturuldu: {zip_filename}.zip")

# Drive'a yedekle
if drive_path:
    try:
        drive_zip = f"{drive_path}/{zip_filename}.zip"
        shutil.copy(f"{zip_filename}.zip", drive_zip)
        print(f"âœ… Drive'a yedeklendi: {drive_zip}")
    except Exception as e:
        print(f"âš ï¸ Drive yedekleme hatasÄ±: {e}")

# Ä°ndirme
try:
    from google.colab import files
    files.download(f'{zip_filename}.zip')
    print(f"\nâœ… Dosya indiriliyor...")
    print("\nğŸ“Œ Ä°NDÄ°RME TALÄ°MATLARI:")
    print("="*80)
    print("1. ZIP dosyasÄ±nÄ± masaÃ¼stÃ¼nde aÃ§Ä±n")
    print("2. Ä°Ã§indeki tÃ¼m dosyalarÄ± jetxpredictor/models/ klasÃ¶rÃ¼ne kopyalayÄ±n")
    print("3. Terminal'de: streamlit run app.py")
    print("4. \"âœ… Model yÃ¼klendi ve hazÄ±r!\" mesajÄ±nÄ± gÃ¶rmelisiniz")
    print("="*80)
except:
    print(f"\nğŸ“ Dosya konumu: {os.getcwd()}/{zip_filename}.zip")
    print("Manuel indirme: Dosyalar > SaÄŸ tÄ±k > Ä°ndir")

print("\n" + "="*80)
print("âœ… TÃœM Ä°ÅLEMLER TAMAMLANDI!")
print("ğŸ”§ Dependency Conflict RESOLVED!")
print("ğŸš€ 6 Model Ensemble Sistemi Ready!")
print("="*80)

## ğŸ‰ AdÄ±m 9: Final Ã–zet

EÄŸitim sÃ¼reci tamamlandÄ±. SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leyin.

print("="*80)
print("ğŸ‰ JetX 6 MODEL ENSEMBLE SÄ°STEMÄ° - FÄ°NAL Ã–ZET (v7.3 FIXED)")
print("="*80)

print("\nğŸ“Š EÄÄ°TÄ°LEN MODELLER:")
model_count = 0

if 'progressive_results' in locals():
    model_count += 1
    print(f"   1ï¸âƒ£ Progressive NN (Multi-Scale) âœ…")
    print(f"      - MAE: {progressive_results['ensemble_metrics']['mae']:.4f}")

if 'catboost_results' in locals():
    model_count += 1
    print(f"\n   2ï¸âƒ£ CatBoost (Multi-Scale) âœ…")

if 'autogluon_info' in locals():
    model_count += 1
    print(f"\n   3ï¸âƒ£ AutoGluon AutoML âœ…")
    print(f"      - Best Model: {autogluon_info['best_model']}")

if 'tabnet_info' in locals():
    model_count += 1
    print(f"\n   4ï¸âƒ£ TabNet High-X Specialist âœ…")

if 'rl_agent_info' in locals():
    model_count += 1
    print(f"\n   5ï¸âƒ£ RL Agent âœ…")
    print(f"      - Accuracy: {rl_agent_info.get('accuracy', 0):.2%}")

print(f"\nğŸ“ˆ TOPLAM: {model_count}/6 model baÅŸarÄ±yla eÄŸitildi")

print("\nğŸ”§ FIX Ã–ZELLÄ°KLERÄ°:")
print("   âœ… PyTorch/TorchAudio version compatibility resolved")
print("   âœ… Smart sequential package installation")
print("   âœ… CUDA optimization with fallback")
print("   âœ… Environment validation")
print("   âœ… Clean installation process")

print("\nğŸ“ KAYDEDILEN DOSYALAR:")
print(f"   âœ… models/jetx_model.h5 (Ana Progressive NN)")
print(f"   âœ… models/scaler.pkl (Feature scaler)")
print(f"   âœ… models/all_models_results_v7_fixed.json")
print(f"   âœ… {zip_filename}.zip")
if drive_path:
    print(f"   âœ… {drive_path}/{zip_filename}.zip (Drive backup)")

print("\n" + "="*80)
print("âœ¨ BAÅARIYLA TAMAMLANDI! âœ¨")
print("ğŸ”§ Dependency Conflict RESOLVED!")
print("ğŸš€ ArtÄ±k hatasÄ±z Ã§alÄ±ÅŸacak!")
print("="*80)
print(f"BitiÅŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("="*80)
