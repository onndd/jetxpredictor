{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸš€ JetX Model EÄŸitimi - Google Colab (v7.2)\n",
    "\n",
    "**6 Model Ensemble Sistemi ile JetX tahmin modellerini eÄŸitin**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ†• v7.2 Yeni Ã–zellikler\n",
    "\n",
    "- ğŸ”§ **Ä°Ã§ Ä°Ã§e KlasÃ¶r Sorunu DÃ¼zeltildi**: GitHub'dan direkt aÃ§ma desteÄŸi\n",
    "- ğŸ¤– **6 Model Tam DesteÄŸi**: Progressive NN, CatBoost, AutoGluon, TabNet, Consensus, RL Agent\n",
    "- ğŸ§  **AutoGluon AutoML**: 50+ modeli otomatik dener ve en iyisini seÃ§er\n",
    "- ğŸ¯ **TabNet High-X Specialist**: Attention mechanism ile yÃ¼ksek Ã§arpanlarÄ± tespit eder\n",
    "- ğŸ¤– **RL Agent**: TÃ¼m model Ã§Ä±ktÄ±larÄ±nÄ± birleÅŸtirerek en kÃ¢rlÄ± aksiyonu seÃ§er\n",
    "- ğŸ“ **Google Drive Entegrasyonu**: Modeller otomatik Drive'a yedeklenir\n",
    "- ğŸ“Š **KapsamlÄ± Model KarÅŸÄ±laÅŸtÄ±rma**: Her modelin performans metrikleri\n",
    "- ğŸ’° **Sanal Kasa SimÃ¼lasyonu**: ROI ve kazanÃ§ oranlarÄ±\n",
    "- ğŸ“¦ **GeliÅŸmiÅŸ Ä°ndirme Sistemi**: ZIP indirme + Drive backup\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Model AÃ§Ä±klamalarÄ±\n",
    "\n",
    "| Model | GÃ¶rev | Ã–zellik | Hedef |\n",
    "|-------|-------|---------|-------|\n",
    "| **Progressive NN** | Genel amaÃ§lÄ± tahmin | 5 farklÄ± pencere boyutu | 1.5x eÅŸik tahmini |\n",
    "| **CatBoost** | Gradient boosting | Multi-scale window | 1.5x eÅŸik + kategori |\n",
    "| **AutoGluon** | AutoML champion | 50+ model ensemble | 1.5x eÅŸik tahmini |\n",
    "| **TabNet** | YÃ¼ksek X uzmanÄ± | Attention mechanism | Multi-class tahmin |\n",
    "| **Consensus** | Ensemble final | Weighted voting | En yÃ¼ksek doÄŸruluk |\n",
    "| **RL Agent** | Meta-model | Policy gradient | En kÃ¢rlÄ± aksiyon seÃ§imi |\n",
    "\n",
    "## ğŸ¯ Hedefler\n",
    "\n",
    "- âœ… 1.5 AltÄ± DoÄŸruluk: **75%+**\n",
    "- âœ… 1.5 ÃœstÃ¼ DoÄŸruluk: **75%+**\n",
    "- âœ… Para KaybÄ± Riski: **<20%**\n",
    "- âœ… ROI: **Pozitif**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ğŸ“¦ AdÄ±m 1: HazÄ±rlÄ±k ve Kurulum\n",
    "\n",
    "Bu adÄ±mda:\n",
    "- Google Drive baÄŸlantÄ±sÄ± yapÄ±lÄ±r\n",
    "- Gerekli kÃ¼tÃ¼phaneler yÃ¼klenir\n",
    "- Dizin kontrolÃ¼ yapÄ±lÄ±r (GitHub'dan aÃ§ma desteÄŸi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_code"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“¦ HAZIRLIK - 6 Model Ensemble Sistem v7.2\")\n",
    "print(\"ğŸ†• RL Agent Entegrasyonu\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Google Drive BaÄŸlantÄ±sÄ±\n",
    "print(\"\\nğŸ“ Google Drive baÄŸlanÄ±yor...\")\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"âœ… Google Drive baÅŸarÄ±yla baÄŸlandÄ±!\")\n",
    "    \n",
    "    drive_path = '/content/drive/MyDrive/JetX_Models_v7.2'\n",
    "    os.makedirs(drive_path, exist_ok=True)\n",
    "    print(f\"âœ… Drive klasÃ¶rÃ¼ oluÅŸturuldu: {drive_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Drive baÄŸlantÄ± hatasÄ±: {e}\")\n",
    "    drive_path = None\n",
    "\n",
    "# KÃ¼tÃ¼phaneleri yÃ¼kle\n",
    "print(\"\\nğŸ“¦ KÃ¼tÃ¼phaneler yÃ¼kleniyor...\")\n",
    "!pip install -q tensorflow scikit-learn catboost pandas numpy scipy joblib matplotlib seaborn tqdm PyWavelets nolds autogluon pytorch-tabnet torch\n",
    "\n",
    "# Proje klonlama - GitHub'dan jetxpredictor'Ä± indir\n",
    "print(\"\\nğŸ“¥ Proje klonlanÄ±yor...\")\n",
    "if not os.path.exists('jetxpredictor'):\n",
    "    !git clone https://github.com/onndd/jetxpredictor.git\n",
    "    print(\"âœ… Proje baÅŸarÄ±yla klonlandÄ±!\")\n",
    "else:\n",
    "    print(\"âœ… Proje zaten mevcut\")\n",
    "\n",
    "\n",
    "# Dizin kontrolÃ¼ - GitHub'dan direkt aÃ§ma desteÄŸi\n",
    "print(\"\\nğŸ“‚ Dizin kontrolÃ¼ yapÄ±lÄ±yor...\")\n",
    "print(f\"Mevcut dizin: {os.getcwd()}\")\n",
    "\n",
    "# Proje kÃ¶k dizinini bul\n",
    "if os.path.exists('jetx_data.db'):\n",
    "    print(\"âœ… Proje kÃ¶k dizinindeyiz!\")\n",
    "elif os.path.exists('../jetx_data.db'):\n",
    "    print(\"ğŸ“ Bir Ã¼st dizine Ã§Ä±kÄ±lÄ±yor...\")\n",
    "    os.chdir('..')\n",
    "    print(f\"âœ… Proje kÃ¶k dizinine geÃ§ildi: {os.getcwd()}\")\n",
    "elif os.path.exists('jetxpredictor/jetx_data.db'):\n",
    "    print(\"ğŸ“ jetxpredictor klasÃ¶rÃ¼ne giriliyor...\")\n",
    "    os.chdir('jetxpredictor')\n",
    "    print(f\"âœ… Proje kÃ¶k dizinine geÃ§ildi: {os.getcwd()}\")\n",
    "else:\n",
    "    print(\"âš ï¸ UYARI: jetx_data.db bulunamadÄ±!\")\n",
    "    print(f\"ğŸ“‚ Mevcut dizin iÃ§eriÄŸi: {os.listdir('.')}\")\n",
    "    \n",
    "# Models klasÃ¶rÃ¼nÃ¼ kontrol et ve oluÅŸtur\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "    print(\"âœ… models/ klasÃ¶rÃ¼ oluÅŸturuldu\")\n",
    "else:\n",
    "    print(\"âœ… models/ klasÃ¶rÃ¼ mevcut\")\n",
    "\n",
    "prep_time = time.time() - start_time\n",
    "print(f\"\\nâœ… HazÄ±rlÄ±k tamamlandÄ±! ({prep_time/60:.1f} dakika)\")\n",
    "print(f\"ğŸ“‚ Ã‡alÄ±ÅŸma dizini: {os.getcwd()}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_loading"
   },
   "source": [
    "## ğŸ“Š AdÄ±m 2: Veri YÃ¼kleme ve HazÄ±rlÄ±k\n",
    "\n",
    "VeritabanÄ±ndan veri yÃ¼klenip train/val/test olarak bÃ¶lÃ¼nÃ¼r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_loading_code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from category_definitions import CategoryDefinitions, FeatureEngineering\n",
    "from utils.multi_scale_window import split_data_preserving_order\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š VERÄ° YÃœKLEME\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "conn = sqlite3.connect('jetx_data.db')\n",
    "data = pd.read_sql_query(\"SELECT value FROM jetx_results ORDER BY id\", conn)\n",
    "conn.close()\n",
    "\n",
    "all_values = data['value'].values\n",
    "print(f\"âœ… {len(all_values):,} veri yÃ¼klendi\")\n",
    "\n",
    "# Time-series split\n",
    "train_data, val_data, test_data = split_data_preserving_order(\n",
    "    all_values, train_ratio=0.70, val_ratio=0.15\n",
    ")\n",
    "\n",
    "print(f\"âœ… Train: {len(train_data):,}\")\n",
    "print(f\"âœ… Val:   {len(val_data):,}\")\n",
    "print(f\"âœ… Test:  {len(test_data):,}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "progressive_nn"
   },
   "source": [
    "## ğŸ§  AdÄ±m 3: Progressive NN Training\n",
    "\n",
    "Multi-scale window ensemble ile Progressive Neural Network eÄŸitimi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "progressive_nn_code"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ğŸ§  PROGRESSIVE NN TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "!python notebooks/jetx_PROGRESSIVE_TRAINING_MULTISCALE.py\n",
    "\n",
    "# SonuÃ§larÄ± yÃ¼kle\n",
    "with open('models/progressive_multiscale/model_info.json', 'r') as f:\n",
    "    progressive_results = json.load(f)\n",
    "\n",
    "print(\"\\nâœ… Progressive NN TamamlandÄ±!\")\n",
    "print(f\"ğŸ“Š MAE: {progressive_results['ensemble_metrics']['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "catboost"
   },
   "source": [
    "## ğŸš€ AdÄ±m 4: CatBoost Training\n",
    "\n",
    "Gradient boosting uzmanÄ± CatBoost modeli eÄŸitimi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "catboost_code"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ CATBOOST TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "!python notebooks/jetx_CATBOOST_TRAINING_MULTISCALE.py\n",
    "\n",
    "with open('models/catboost_multiscale/model_info.json', 'r') as f:\n",
    "    catboost_results = json.load(f)\n",
    "\n",
    "print(\"\\nâœ… CatBoost TamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "autogluon"
   },
   "source": [
    "## ğŸ¤– AdÄ±m 5: AutoGluon AutoML Training\n",
    "\n",
    "50+ modeli otomatik deneyen AutoGluon AutoML eÄŸitimi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "autogluon_code"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils.autogluon_predictor import AutoGluonPredictor\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ¤– AUTOGLUON AUTOML TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Feature extraction\n",
    "window_size = 100\n",
    "X_features = []\n",
    "y_labels = []\n",
    "\n",
    "for i in range(window_size, len(train_data) - 1):\n",
    "    hist = train_data[:i].tolist()\n",
    "    target = train_data[i]\n",
    "    feats = FeatureEngineering.extract_all_features(hist)\n",
    "    X_features.append(feats)\n",
    "    y_labels.append(1 if target >= 1.5 else 0)\n",
    "\n",
    "X_train_ag = pd.DataFrame(X_features)\n",
    "y_train_ag = pd.Series(y_labels, name='above_threshold')\n",
    "\n",
    "print(f\"âœ… {len(X_train_ag):,} Ã¶rnek hazÄ±rlandÄ±\")\n",
    "\n",
    "# AutoGluon predictor\n",
    "ag_predictor = AutoGluonPredictor(\n",
    "    model_path='models/autogluon_model',\n",
    "    threshold=1.5\n",
    ")\n",
    "\n",
    "# Train\n",
    "ag_results = ag_predictor.train(\n",
    "    X_train=X_train_ag,\n",
    "    y_train=y_train_ag,\n",
    "    time_limit=3600,\n",
    "    presets='best_quality',\n",
    "    eval_metric='roc_auc'\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… AutoGluon TamamlandÄ±!\")\n",
    "print(f\"ğŸ† En Ä°yi Model: {ag_results['best_model']}\")\n",
    "print(f\"ğŸ“Š Score: {ag_results['best_score']:.4f}\")\n",
    "\n",
    "# Save info\n",
    "autogluon_info = {\n",
    "    'model': 'AutoGluon_AutoML',\n",
    "    'version': '1.0',\n",
    "    'date': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'best_model': ag_results['best_model'],\n",
    "    'best_score': float(ag_results['best_score'])\n",
    "}\n",
    "\n",
    "os.makedirs('models/autogluon_model', exist_ok=True)\n",
    "with open('models/autogluon_model/model_info.json', 'w') as f:\n",
    "    json.dump(autogluon_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tabnet"
   },
   "source": [
    "## ğŸ¯ AdÄ±m 6: TabNet High-X Specialist Training\n",
    "\n",
    "Attention mechanism ile yÃ¼ksek Ã§arpanlarÄ± tespit eden TabNet eÄŸitimi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tabnet_code"
   },
   "outputs": [],
   "source": [
    "from utils.tabnet_predictor import TabNetHighXPredictor\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ¯ TABNET HIGH-X SPECIALIST TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Feature extraction\n",
    "window_size = 100\n",
    "X_features_tn = []\n",
    "y_categories = []\n",
    "\n",
    "for i in range(window_size, len(train_data) - 1):\n",
    "    hist = train_data[:i].tolist()\n",
    "    target = train_data[i]\n",
    "    feats = FeatureEngineering.extract_all_features(hist)\n",
    "    X_features_tn.append(list(feats.values()))\n",
    "    category = TabNetHighXPredictor.categorize_value(target)\n",
    "    y_categories.append(category)\n",
    "\n",
    "X_train_tn = np.array(X_features_tn)\n",
    "y_train_tn = np.array(y_categories)\n",
    "\n",
    "scaler_tn = StandardScaler()\n",
    "X_train_tn = scaler_tn.fit_transform(X_train_tn)\n",
    "\n",
    "print(f\"âœ… {len(X_train_tn):,} Ã¶rnek hazÄ±rlandÄ±\")\n",
    "\n",
    "# Validation set\n",
    "X_val_tn = []\n",
    "y_val_tn = []\n",
    "\n",
    "for i in range(window_size, len(val_data) - 1):\n",
    "    hist = val_data[:i].tolist()\n",
    "    target = val_data[i]\n",
    "    feats = FeatureEngineering.extract_all_features(hist)\n",
    "    X_val_tn.append(list(feats.values()))\n",
    "    y_val_tn.append(TabNetHighXPredictor.categorize_value(target))\n",
    "\n",
    "X_val_tn = scaler_tn.transform(np.array(X_val_tn))\n",
    "y_val_tn = np.array(y_val_tn)\n",
    "\n",
    "# TabNet predictor\n",
    "tabnet_predictor = TabNetHighXPredictor(\n",
    "    model_path='models/tabnet_high_x.pkl',\n",
    "    scaler_path='models/tabnet_scaler.pkl'\n",
    ")\n",
    "\n",
    "# Train\n",
    "tn_results = tabnet_predictor.train(\n",
    "    X_train=X_train_tn,\n",
    "    y_train=y_train_tn,\n",
    "    X_val=X_val_tn,\n",
    "    y_val=y_val_tn,\n",
    "    max_epochs=200,\n",
    "    patience=20,\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… TabNet TamamlandÄ±!\")\n",
    "print(f\"ğŸ† Best Epoch: {tn_results['best_epoch']}\")\n",
    "\n",
    "# Save\n",
    "tabnet_predictor.save_model()\n",
    "tabnet_predictor.save_scaler(scaler_tn)\n",
    "\n",
    "tabnet_info = {\n",
    "    'model': 'TabNet_HighX_Specialist',\n",
    "    'version': '1.0',\n",
    "    'date': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'best_epoch': int(tn_results['best_epoch']),\n",
    "    'best_cost': float(tn_results['best_cost'])\n",
    "}\n",
    "\n",
    "with open('models/tabnet_info.json', 'w') as f:\n",
    "    json.dump(tabnet_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– AdÄ±m 7: RL Agent Training\n",
    "\n",
    "Reinforcement Learning Agent eÄŸitimi. TÃ¼m model Ã§Ä±ktÄ±larÄ±nÄ± birleÅŸtirerek en kÃ¢rlÄ± aksiyonu seÃ§er.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ğŸ¤– RL AGENT TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "!python notebooks/train_rl_agent.py\n",
    "\n",
    "# SonuÃ§larÄ± yÃ¼kle\n",
    "try:\n",
    "    with open('models/rl_agent_info.json', 'r') as f:\n",
    "        rl_agent_info = json.load(f)\n",
    "    print(\"\\nâœ… RL Agent TamamlandÄ±!\")\n",
    "    print(f\"ğŸ“Š Accuracy: {rl_agent_info.get('accuracy', 0):.2%}\")\n",
    "    print(f\"ğŸ“Š Action Distribution: {rl_agent_info.get('action_distribution', [0, 0, 0, 0])}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ RL Agent info yÃ¼klenemedi: {e}\")\n",
    "    rl_agent_info = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_results"
   },
   "source": [
    "## ğŸ’¾ AdÄ±m 8: SonuÃ§larÄ± Kaydetme ve Ä°ndirme\n",
    "\n",
    "TÃ¼m modeller ZIP'lenir ve indirilir. Google Drive'a yedekleme yapÄ±lÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_results_code"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ’¾ SONUÃ‡LAR KAYDEDÄ°LÄ°YOR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# JSON sonuÃ§larÄ±\n",
    "final_results = {\n",
    "    'metadata': {\n",
    "        'version': '7.2',\n",
    "        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    },\n",
    "    'models': {\n",
    "        'progressive_nn': progressive_results if 'progressive_results' in locals() else None,\n",
    "        'catboost': catboost_results if 'catboost_results' in locals() else None,\n",
    "        'autogluon': autogluon_info if 'autogluon_info' in locals() else None,\n",
    "        'tabnet': tabnet_info if 'tabnet_info' in locals() else None,\n",
    "        'rl_agent': rl_agent_info if 'rl_agent_info' in locals() else None\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('models/all_models_results_v7.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "print(\"âœ… JSON sonuÃ§larÄ± kaydedildi\")\n",
    "\n",
    "# Lokal Streamlit uyumluluÄŸu iÃ§in dosya isimlendirme\n",
    "print(\"\\nğŸ“ Lokal kullanÄ±m iÃ§in dosyalar hazÄ±rlanÄ±yor...\")\n",
    "\n",
    "# Progressive NN modelini ana model olarak kopyala\n",
    "if os.path.exists('models/progressive_multiscale/ensemble_model.h5'):\n",
    "    shutil.copy('models/progressive_multiscale/ensemble_model.h5', 'models/jetx_model.h5')\n",
    "    print(\"âœ… jetx_model.h5 oluÅŸturuldu\")\n",
    "\n",
    "if os.path.exists('models/progressive_multiscale/scaler.pkl'):\n",
    "    shutil.copy('models/progressive_multiscale/scaler.pkl', 'models/scaler.pkl')\n",
    "    print(\"âœ… scaler.pkl oluÅŸturuldu\")\n",
    "\n",
    "# ZIP oluÅŸtur\n",
    "zip_filename = f'jetx_6models_v7_{datetime.now().strftime(\"%Y%m%d_%H%M\")}'\n",
    "shutil.make_archive(zip_filename, 'zip', 'models')\n",
    "\n",
    "print(f\"\\nâœ… ZIP oluÅŸturuldu: {zip_filename}.zip\")\n",
    "\n",
    "# Drive'a yedekle\n",
    "if drive_path:\n",
    "    try:\n",
    "        drive_zip = f\"{drive_path}/{zip_filename}.zip\"\n",
    "        shutil.copy(f\"{zip_filename}.zip\", drive_zip)\n",
    "        print(f\"âœ… Drive'a yedeklendi: {drive_zip}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Drive yedekleme hatasÄ±: {e}\")\n",
    "\n",
    "# Ä°ndirme\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(f'{zip_filename}.zip')\n",
    "    print(f\"\\nâœ… Dosya indiriliyor...\")\n",
    "    print(\"\\nğŸ“Œ Ä°NDÄ°RME TALÄ°MATLARI:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"1. ZIP dosyasÄ±nÄ± masaÃ¼stÃ¼nde aÃ§Ä±n\")\n",
    "    print(\"2. Ä°Ã§indeki tÃ¼m dosyalarÄ± jetxpredictor/models/ klasÃ¶rÃ¼ne kopyalayÄ±n\")\n",
    "    print(\"3. Terminal'de: streamlit run app.py\")\n",
    "    print(\"4. \\\"âœ… Model yÃ¼klendi ve hazÄ±r!\\\" mesajÄ±nÄ± gÃ¶rmelisiniz\")\n",
    "    print(\"=\"*80)\n",
    "except:\n",
    "    print(f\"\\nğŸ“ Dosya konumu: {os.getcwd()}/{zip_filename}.zip\")\n",
    "    print(\"Manuel indirme: Dosyalar > SaÄŸ tÄ±k > Ä°ndir\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… TÃœM Ä°ÅLEMLER TAMAMLANDI!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## ğŸ‰ AdÄ±m 9: Final Ã–zet\n",
    "\n",
    "EÄŸitim sÃ¼reci tamamlandÄ±. SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary_code"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ğŸ‰ JetX 6 MODEL ENSEMBLE SÄ°STEMÄ° - FÄ°NAL Ã–ZET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š EÄÄ°TÄ°LEN MODELLER:\")\n",
    "model_count = 0\n",
    "\n",
    "if 'progressive_results' in locals():\n",
    "    model_count += 1\n",
    "    print(f\"   1ï¸âƒ£ Progressive NN (Multi-Scale) âœ…\")\n",
    "    print(f\"      - MAE: {progressive_results['ensemble_metrics']['mae']:.4f}\")\n",
    "\n",
    "if 'catboost_results' in locals():\n",
    "    model_count += 1\n",
    "    print(f\"\\n   2ï¸âƒ£ CatBoost (Multi-Scale) âœ…\")\n",
    "\n",
    "if 'autogluon_info' in locals():\n",
    "    model_count += 1\n",
    "    print(f\"\\n   3ï¸âƒ£ AutoGluon AutoML âœ…\")\n",
    "    print(f\"      - Best Model: {autogluon_info['best_model']}\")\n",
    "\n",
    "if 'tabnet_info' in locals():\n",
    "    model_count += 1\n",
    "    print(f\"\\n   4ï¸âƒ£ TabNet High-X Specialist âœ…\")\n",
    "\n",
    "if 'rl_agent_info' in locals():\n",
    "    model_count += 1\n",
    "    print(f\"\\n   5ï¸âƒ£ RL Agent âœ…\")\n",
    "    print(f\"      - Accuracy: {rl_agent_info.get('accuracy', 0):.2%}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ TOPLAM: {model_count}/6 model baÅŸarÄ±yla eÄŸitildi\")\n",
    "\n",
    "print(\"\\nğŸ“ KAYDEDILEN DOSYALAR:\")\n",
    "print(f\"   âœ… models/jetx_model.h5 (Ana Progressive NN)\")\n",
    "print(f\"   âœ… models/scaler.pkl (Feature scaler)\")\n",
    "print(f\"   âœ… models/rl_agent_model.h5 (RL Agent)\")\n",
    "print(f\"   âœ… models/rl_agent_model_scaler.pkl (RL Agent Scaler)\")\n",
    "print(f\"   âœ… models/all_models_results_v7.json\")\n",
    "print(f\"   âœ… {zip_filename}.zip\")\n",
    "if drive_path:\n",
    "    print(f\"   âœ… {drive_path}/{zip_filename}.zip (Drive backup)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ¨ BAÅARIYLA TAMAMLANDI! âœ¨\")\n",
    "print(\"=\"*80)\n",
    "print(f\"BitiÅŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "JetX_PROGRESSIVE_TRAINING_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
