#!/usr/bin/env python3
"""
ğŸ¯ JetX PROGRESSIVE TRAINING - 3 AÅŸamalÄ± EÄŸitim Stratejisi

AMAÃ‡: 1.5 altÄ± deÄŸerleri tahmin edebilen model eÄŸitmek (YÃ¼ksek GÃ¼venli)

STRATEJI:
â”œâ”€â”€ AÅAMA 1: Foundation Training (100 epoch) - Threshold baÅŸtan aktif
â”œâ”€â”€ AÅAMA 2: Threshold Fine-Tuning (80 epoch) - YumuÅŸak class weights (5x)
â””â”€â”€ AÅAMA 3: Full Model Fine-Tuning (80 epoch) - Dengeli final (7x)

HEDEFLER (GÃœNCELLENDÄ° - %85 GÃ¼ven EÅŸiÄŸi Ä°le):
- 1.5 ALTI DoÄŸruluk: %75+ (EÅŸik 0.85)
- 1.5 ÃœSTÃœ DoÄŸruluk: %75+ (EÅŸik 0.85)
- Para kaybÄ± riski: %20 altÄ±
- MAE: < 2.0

SÃœRE: ~1.5 saat (GPU ile)
"""

import subprocess
import sys
import os
import time
from datetime import datetime

print("="*80)
print("ğŸ¯ JetX PROGRESSIVE TRAINING - 3 AÅŸamalÄ± EÄŸitim (Keskin NiÅŸancÄ± Modu)")
print("="*80)
print(f"BaÅŸlangÄ±Ã§: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print()

# KÃ¼tÃ¼phaneleri yÃ¼kle
print("ğŸ“¦ KÃ¼tÃ¼phaneler yÃ¼kleniyor...")
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", 
                      "tensorflow", "scikit-learn", "pandas", "numpy", 
                      "scipy", "joblib", "matplotlib", "seaborn", "tqdm",
                      "PyWavelets", "nolds"])

import numpy as np
import pandas as pd
import joblib
import sqlite3
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, confusion_matrix
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks, backend as K
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import warnings
import pickle
from datetime import datetime
warnings.filterwarnings('ignore')

print(f"âœ… TensorFlow: {tf.__version__}")
print(f"âœ… GPU: {'Mevcut' if len(tf.config.list_physical_devices('GPU')) > 0 else 'Yok (CPU)'}")

# Proje yÃ¼kle
if not os.path.exists('jetxpredictor'):
    print("\nğŸ“¥ Proje klonlanÄ±yor...")
    subprocess.check_call(["git", "clone", "https://github.com/onndd/jetxpredictor.git"])

os.chdir('jetxpredictor')
sys.path.append(os.getcwd())

# GPU KonfigÃ¼rasyonunu yÃ¼kle ve uygula
from utils.gpu_config import setup_tensorflow_gpu, print_gpu_status
print_gpu_status()
gpu_config = setup_tensorflow_gpu()
print()

from category_definitions import CategoryDefinitions, FeatureEngineering
from utils.balanced_batch_generator import BalancedBatchGenerator
from utils.adaptive_weight_scheduler import AdaptiveWeightScheduler
from utils.advanced_bankroll import AdvancedBankrollManager
from utils.custom_losses import balanced_threshold_killer_loss, balanced_focal_loss, create_weighted_binary_crossentropy, percentage_aware_regression_loss
from utils.virtual_bankroll_callback import VirtualBankrollCallback
print(f"âœ… Proje yÃ¼klendi - Kritik eÅŸik: {CategoryDefinitions.CRITICAL_THRESHOLD}x\n")

# KRITIK GÃœVEN EÅÄ°ÄÄ°
CONFIDENCE_THRESHOLD = 0.85

# =============================================================================
# TRANSFORMER LAYERS (YENÄ° - FAZ 2)
# =============================================================================
class PositionalEncoding(layers.Layer):
    """
    Positional Encoding for Transformer
    Time series iÃ§in zamansal bilgi ekler
    TensorFlow 2.x uyumlu - build() metodunda oluÅŸturulur
    """
    def __init__(self, max_seq_len=1000, d_model=256, **kwargs):
        super().__init__(**kwargs)
        self.max_seq_len = max_seq_len
        self.d_model = d_model
        self.pe = None
        
    def build(self, input_shape):
        # Positional encoding matrix'i build'de oluÅŸtur
        position = tf.range(self.max_seq_len, dtype=tf.float32)[:, tf.newaxis]
        div_term = tf.exp(tf.range(0, self.d_model, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / self.d_model))
        
        pe_sin = tf.sin(position * div_term)
        pe_cos = tf.cos(position * div_term)
        
        # Alternating sin/cos pattern oluÅŸtur
        pe_list = []
        for i in range(self.d_model):
            if i % 2 == 0:
                pe_list.append(pe_sin[:, i // 2:i // 2 + 1])
            else:
                pe_list.append(pe_cos[:, i // 2:i // 2 + 1])
        
        pe = tf.concat(pe_list, axis=1)
        self.pe = tf.constant(pe, dtype=tf.float32)
        super().build(input_shape)
    
    def call(self, x):
        seq_len = tf.shape(x)[1]
        return x + self.pe[:seq_len, :]
    
    def get_config(self):
        config = super().get_config()
        config.update({
            'max_seq_len': self.max_seq_len,
            'd_model': self.d_model
        })
        return config


class LightweightTransformerEncoder(layers.Layer):
    """
    Lightweight Transformer Encoder for Time Series
    
    Args:
        d_model: Model dimension (256)
        num_layers: Number of transformer layers (4)
        num_heads: Number of attention heads (8)
        dff: Feedforward dimension (1024)
        dropout: Dropout rate (0.2)
    """
    def __init__(
        self, 
        d_model=256, 
        num_layers=4, 
        num_heads=8, 
        dff=1024, 
        dropout=0.2,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.d_model = d_model
        self.num_layers = num_layers
        self.num_heads = num_heads
        self.dff = dff
        self.dropout_rate = dropout
        
        # Input projection (sequence_len, 1) â†’ (sequence_len, d_model)
        self.input_projection = layers.Dense(d_model)
        
        # Positional encoding
        self.pos_encoding = PositionalEncoding(max_seq_len=1000, d_model=d_model)
        
        # Transformer encoder layers
        self.encoder_layers = []
        for _ in range(num_layers):
            # Multi-head attention
            mha = layers.MultiHeadAttention(
                num_heads=num_heads,
                key_dim=d_model // num_heads,
                dropout=dropout
            )
            
            # Feedforward network
            ffn = tf.keras.Sequential([
                layers.Dense(dff, activation='relu'),
                layers.Dropout(dropout),
                layers.Dense(d_model)
            ])
            
            # Layer normalization
            layernorm1 = layers.LayerNormalization(epsilon=1e-6)
            layernorm2 = layers.LayerNormalization(epsilon=1e-6)
            
            # Dropout
            dropout1 = layers.Dropout(dropout)
            dropout2 = layers.Dropout(dropout)
            
            self.encoder_layers.append({
                'mha': mha,
                'ffn': ffn,
                'layernorm1': layernorm1,
                'layernorm2': layernorm2,
                'dropout1': dropout1,
                'dropout2': dropout2
            })
        
        # Global average pooling
        self.global_pool = layers.GlobalAveragePooling1D()
        
        # Output projection
        self.output_projection = layers.Dense(d_model)
        self.dropout_final = layers.Dropout(dropout)
    
    def call(self, inputs, training=None):
        """
        Forward pass
        
        Args:
            inputs: (batch_size, seq_len, 1) - Time series input
            training: Training mode flag
            
        Returns:
            (batch_size, d_model) - Encoded representation
        """
        # Input projection
        x = self.input_projection(inputs)  # (batch, seq_len, d_model)
        
        # Positional encoding
        x = self.pos_encoding(x)
        
        # Transformer encoder layers
        for layer in self.encoder_layers:
            # Multi-head attention
            attn_output = layer['mha'](
                query=x,
                key=x,
                value=x,
                training=training
            )
            attn_output = layer['dropout1'](attn_output, training=training)
            x = layer['layernorm1'](x + attn_output)  # Residual connection
            
            # Feedforward network
            ffn_output = layer['ffn'](x)
            ffn_output = layer['dropout2'](ffn_output, training=training)
            x = layer['layernorm2'](x + ffn_output)  # Residual connection
        
        # Global pooling
        x = self.global_pool(x)  # (batch, d_model)
        
        # Output projection
        x = self.output_projection(x)
        x = self.dropout_final(x, training=training)
        
        return x
    
    def get_config(self):
        config = super().get_config()
        config.update({
            'd_model': self.d_model,
            'num_layers': self.num_layers,
            'num_heads': self.num_heads,
            'dff': self.dff,
            'dropout': self.dropout_rate
        })
        return config


# =============================================================================
# VERÄ° YÃœKLEME
# =============================================================================
print("ğŸ“Š Veri yÃ¼kleniyor...")
conn = sqlite3.connect('jetx_data.db')
data = pd.read_sql_query("SELECT value FROM jetx_results ORDER BY id", conn)
conn.close()

all_values = data['value'].values
print(f"âœ… {len(all_values):,} veri yÃ¼klendi")
print(f"AralÄ±k: {all_values.min():.2f}x - {all_values.max():.2f}x")

below = (all_values < 1.5).sum()
above = (all_values >= 1.5).sum()
print(f"\nğŸ“Š CLASS DAÄILIMI:")
print(f"  1.5 altÄ±: {below:,} ({below/len(all_values)*100:.1f}%)")
print(f"  1.5 Ã¼stÃ¼: {above:,} ({above/len(all_values)*100:.1f}%)")
print(f"  Dengesizlik: 1:{above/below:.2f}")

# =============================================================================
# FEATURE ENGINEERING
# =============================================================================
print("\nğŸ”§ Feature extraction...")
window_size = 1000  # 500 â†’ 1000 (daha uzun vadeli pattern analizi)
X_f, X_50, X_200, X_500, X_1000 = [], [], [], [], []
y_reg, y_cls, y_thr = [], [], []

for i in tqdm(range(window_size, len(all_values)-1), desc='Features'):
    hist = all_values[:i].tolist()
    target = all_values[i]
    
    feats = FeatureEngineering.extract_all_features(hist)
    X_f.append(list(feats.values()))
    X_50.append(all_values[i-50:i])
    X_200.append(all_values[i-200:i])
    X_500.append(all_values[i-500:i])
    X_1000.append(all_values[i-1000:i])  # YENÄ°: 1000'lik pencere
    
    y_reg.append(target)
    cat = CategoryDefinitions.get_category_numeric(target)
    onehot = np.zeros(3)
    onehot[cat] = 1
    y_cls.append(onehot)
    y_thr.append(1.0 if target >= 1.5 else 0.0)

X_f = np.array(X_f)
X_50 = np.array(X_50).reshape(-1, 50, 1)
X_200 = np.array(X_200).reshape(-1, 200, 1)
X_500 = np.array(X_500).reshape(-1, 500, 1)
X_1000 = np.array(X_1000).reshape(-1, 1000, 1)  # YENÄ°: 1000'lik pencere
y_reg = np.array(y_reg)
y_cls = np.array(y_cls)
y_thr = np.array(y_thr).reshape(-1, 1)

print(f"âœ… {len(X_f):,} Ã¶rnek hazÄ±rlandÄ±")
print(f"âœ… Feature sayÄ±sÄ±: {X_f.shape[1]}")

# Normalizasyon
print("\nğŸ“Š Normalizasyon...")
scaler = StandardScaler()
X_f = scaler.fit_transform(X_f)
X_50 = np.log10(X_50 + 1e-8)
X_200 = np.log10(X_200 + 1e-8)
X_500 = np.log10(X_500 + 1e-8)
X_1000 = np.log10(X_1000 + 1e-8)  # YENÄ°: 1000'lik pencere normalizasyonu

# =============================================================================
# TIME-SERIES SPLIT (KRONOLOJIK) - SABÄ°T SAYILAR
# =============================================================================
print("\nğŸ“Š TIME-SERIES SPLIT (Kronolojik BÃ¶lme)...")
print("âš ï¸  UYARI: Shuffle devre dÄ±ÅŸÄ± - Zaman serisi yapÄ±sÄ± korunuyor!")

# Sabit split sayÄ±larÄ±
test_size = 1500
val_size = 1000
total_samples = len(X_f)
train_size = total_samples - test_size - val_size

print(f"ğŸ“Š Veri DaÄŸÄ±lÄ±mÄ± (Sabit SayÄ±lar):")
print(f"  Train: {train_size:,} sample")
print(f"  Validation: {val_size:,} sample")
print(f"  Test: {test_size:,} sample")
print(f"  Toplam: {total_samples:,} sample\n")

# Kronolojik split: Train -> Val -> Test
train_end = train_size
val_end = train_size + val_size

# Train set
X_f_tr = X_f[:train_end]
X_50_tr = X_50[:train_end]
X_200_tr = X_200[:train_end]
X_500_tr = X_500[:train_end]
X_1000_tr = X_1000[:train_end]
y_reg_tr = y_reg[:train_end]
y_cls_tr = y_cls[:train_end]
y_thr_tr = y_thr[:train_end]

# Validation set
X_f_val = X_f[train_end:val_end]
X_50_val = X_50[train_end:val_end]
X_200_val = X_200[train_end:val_end]
X_500_val = X_500[train_end:val_end]
X_1000_val = X_1000[train_end:val_end]
y_reg_val = y_reg[train_end:val_end]
y_cls_val = y_cls[train_end:val_end]
y_thr_val = y_thr[train_end:val_end]

# Test set
X_f_te = X_f[val_end:]
X_50_te = X_50[val_end:]
X_200_te = X_200[val_end:]
X_500_te = X_500[val_end:]
X_1000_te = X_1000[val_end:]
y_reg_te = y_reg[val_end:]
y_cls_te = y_cls[val_end:]
y_thr_te = y_thr[val_end:]

print(f"âœ… Veri split tamamlandÄ±")

# =============================================================================
# CUSTOM LOSS FUNCTIONS
# =============================================================================
def threshold_killer_loss(y_true, y_pred):
    """1.5 altÄ± yanlÄ±ÅŸ tahmine DENGELI CEZA - Lazy learning'i Ã¶nler"""
    mae = K.abs(y_true - y_pred)
    
    # 1.5 altÄ±yken Ã¼stÃ¼ tahmin = 2x ceza (PARA KAYBI - yumuÅŸatÄ±ldÄ±: 4â†’2)
    false_positive = K.cast(
        tf.logical_and(y_true < 1.5, y_pred >= 1.5),
        'float32'
    ) * 2.0
    
    # 1.5 Ã¼stÃ¼yken altÄ± tahmin = 1.5x ceza (yumuÅŸatÄ±ldÄ±: 2â†’1.5)
    false_negative = K.cast(
        tf.logical_and(y_true >= 1.5, y_pred < 1.5),
        'float32'
    ) * 1.5
    
    # Kritik bÃ¶lge (1.4-1.6) = 2.5x ceza (yumuÅŸatÄ±ldÄ±: 3â†’2.5)
    critical_zone = K.cast(
        tf.logical_and(y_true >= 1.4, y_true <= 1.6),
        'float32'
    ) * 2.5
    
    weight = K.maximum(K.maximum(false_positive, false_negative), critical_zone)
    weight = K.maximum(weight, 1.0)
    
    return K.mean(mae * weight)

def ultra_focal_loss(gamma=2.5, alpha=0.75):
    """Focal loss - yanlÄ±ÅŸ tahminlere dengeli ceza (yumuÅŸatÄ±ldÄ±: gamma 4.0â†’2.5)"""
    def loss(y_true, y_pred):
        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())
        pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)
        focal_weight = alpha * K.pow(1 - pt, gamma)
        return -K.mean(focal_weight * K.log(pt))
    return loss

def create_weighted_binary_crossentropy(weight_0, weight_1):
    """
    SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±nÄ± doÄŸrudan iÃ§eren weighted binary crossentropy loss fonksiyonu
    
    Args:
        weight_0: 1.5 altÄ± (class 0) iÃ§in aÄŸÄ±rlÄ±k
        weight_1: 1.5 Ã¼stÃ¼ (class 1) iÃ§in aÄŸÄ±rlÄ±k
    
    Returns:
        AÄŸÄ±rlÄ±klÄ± binary crossentropy loss fonksiyonu
    """
    def loss(y_true, y_pred):
        # Binary crossentropy hesapla
        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())
        bce = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))
        
        # Class weight'leri uygula
        # y_true = 1 ise weight_1, y_true = 0 ise weight_0 kullan
        weights = y_true * weight_1 + (1 - y_true) * weight_0
        
        # AÄŸÄ±rlÄ±klÄ± loss'u dÃ¶ndÃ¼r
        return K.mean(bce * weights)
    
    return loss

# =============================================================================
# OPTIMIZE EDÄ°LMÄ°Å MODEL MÄ°MARÄ°SÄ° (8-10M parametre)
# =============================================================================
def build_progressive_model(n_features):
    """
    Optimize edilmiÅŸ model - Dengeli derinlik
    ~12-15M parametre (1000 penceresi ile artÄ±ÅŸ)
    """
    inp_f = layers.Input((n_features,), name='features')
    inp_50 = layers.Input((50, 1), name='seq50')
    inp_200 = layers.Input((200, 1), name='seq200')
    inp_500 = layers.Input((500, 1), name='seq500')
    inp_1000 = layers.Input((1000, 1), name='seq1000')  # YENÄ°: 1000'lik pencere giriÅŸi
    
    # N-BEATS (Optimize - 5-7 block)
    def nbeats_block(x, units, blocks, name):
        for i in range(blocks):
            x = layers.Dense(units, activation='relu', kernel_regularizer='l2')(x)
            x = layers.BatchNormalization()(x)
            x = layers.Dropout(0.2)(x)
        return x
    
    # KÄ±sa sequence (50)
    nb_s = layers.Flatten()(inp_50)
    nb_s = nbeats_block(nb_s, 128, 5, 's')
    nb_s = layers.Dense(128, activation='relu')(nb_s)
    nb_s = layers.Dropout(0.2)(nb_s)
    
    # Orta sequence (200)
    nb_m = layers.Flatten()(inp_200)
    nb_m = nbeats_block(nb_m, 192, 6, 'm')
    nb_m = layers.Dense(192, activation='relu')(nb_m)
    nb_m = layers.Dropout(0.2)(nb_m)
    
    # Uzun sequence (500)
    nb_l = layers.Flatten()(inp_500)
    nb_l = nbeats_block(nb_l, 256, 7, 'l')
    nb_l = layers.Dense(256, activation='relu')(nb_l)
    nb_l = layers.Dropout(0.2)(nb_l)
    
    # YENÄ°: Ã‡ok uzun sequence (1000) - daha derin analiz
    nb_xl = layers.Flatten()(inp_1000)
    nb_xl = nbeats_block(nb_xl, 384, 9, 'xl')  # 9 block, 384 units
    nb_xl = layers.Dense(384, activation='relu')(nb_xl)
    nb_xl = layers.Dropout(0.2)(nb_xl)
    
    nb_all = layers.Concatenate()([nb_s, nb_m, nb_l, nb_xl])  # nb_xl eklendi
    
    # TCN (Optimize - 7 layer)
    def tcn_block(x, filters, dilation, name):
        conv = layers.Conv1D(filters, 3, dilation_rate=dilation, padding='causal', 
                            activation='relu', kernel_regularizer='l2')(x)
        conv = layers.BatchNormalization()(conv)
        conv = layers.Dropout(0.2)(conv)
        residual = layers.Conv1D(filters, 1, padding='same')(x) if x.shape[-1] != filters else x
        return layers.Add()([conv, residual])
    
    tcn = inp_500
    tcn = tcn_block(tcn, 128, 1, '1')
    tcn = tcn_block(tcn, 128, 2, '2')
    tcn = tcn_block(tcn, 256, 4, '3')
    tcn = tcn_block(tcn, 256, 8, '4')
    tcn = tcn_block(tcn, 512, 16, '5')
    tcn = tcn_block(tcn, 512, 32, '6')
    tcn = tcn_block(tcn, 512, 64, '7')
    tcn = layers.GlobalAveragePooling1D()(tcn)
    tcn = layers.Dense(512, activation='relu')(tcn)
    tcn = layers.Dropout(0.25)(tcn)
    
    # YENÄ°: Transformer branch (FAZ 2)
    # 1000'lik sequence iÃ§in Transformer encoder kullan
    transformer = LightweightTransformerEncoder(
        d_model=256,
        num_layers=4,
        num_heads=8,
        dff=1024,
        dropout=0.2
    )(inp_1000)
    # Transformer output: (batch, 256)
    
    # Fusion (Optimize) - YENÄ°: Transformer eklendi
    fus = layers.Concatenate()([inp_f, nb_all, tcn, transformer])
    fus = layers.Dense(512, activation='relu', kernel_regularizer='l2')(fus)
    fus = layers.BatchNormalization()(fus)
    fus = layers.Dropout(0.3)(fus)
    fus = layers.Dense(256, activation='relu')(fus)
    fus = layers.BatchNormalization()(fus)
    fus = layers.Dropout(0.25)(fus)
    fus = layers.Dense(128, activation='relu')(fus)
    fus = layers.Dropout(0.2)(fus)
    
    # Outputs
    reg_branch = layers.Dense(64, activation='relu')(fus)
    reg_branch = layers.Dropout(0.2)(reg_branch)
    out_reg = layers.Dense(1, activation='linear', name='regression')(reg_branch)
    
    cls_branch = layers.Dense(64, activation='relu')(fus)
    cls_branch = out_cls = layers.Dense(3, activation='softmax', name='classification')(cls_branch)
    
    thr_branch = layers.Dense(32, activation='relu')(fus)
    thr_branch = layers.Dropout(0.2)(thr_branch)
    out_thr = layers.Dense(1, activation='sigmoid', name='threshold')(thr_branch)
    
    model = models.Model([inp_f, inp_50, inp_200, inp_500, inp_1000], [out_reg, out_cls, out_thr])
    return model

# =============================================================================
# DYNAMIC WEIGHT CALLBACK - Otomatik Class Weight Ayarlama
# =============================================================================
class DynamicWeightCallback(callbacks.Callback):
    """
    EÄŸitim sÄ±rasÄ±nda 1.5 altÄ± doÄŸruluÄŸunu izler ve class weight'i otomatik ayarlar.
    GÃœNCELLEME: BaÅŸarÄ±yÄ± 0.85 eÅŸiÄŸine gÃ¶re Ã¶lÃ§er.
    """
    def __init__(self, stage_name, initial_weight=3.0, target_below_acc=0.70):
        super().__init__()
        self.stage_name = stage_name
        self.current_weight = initial_weight
        self.target_below_acc = target_below_acc
        self.best_below_acc = 0
        self.best_weight = initial_weight
        self.weight_history = []
        
    def on_epoch_end(self, epoch, logs=None):
        if epoch % 5 == 0:  # Her 5 epoch'ta bir kontrol et
            # VALIDATION seti Ã¼zerinde threshold metrics (test leakage Ã¶nlendi!)
            p = self.model.predict([X_f_val, X_50_val, X_200_val, X_500_val, X_1000_val], verbose=0)[2].flatten()
            # GÃœNCELLEME: 0.85 GÃ¼ven eÅŸiÄŸi
            p_thr = (p >= CONFIDENCE_THRESHOLD).astype(int)
            t_thr = (y_reg_val >= 1.5).astype(int)
            
            below_mask = t_thr == 0
            above_mask = t_thr == 1
            
            below_acc = accuracy_score(t_thr[below_mask], p_thr[below_mask]) if below_mask.sum() > 0 else 0
            above_acc = accuracy_score(t_thr[above_mask], p_thr[above_mask]) if above_mask.sum() > 0 else 0
            
            # Class weight ayarlamasÄ± (otomatik)
            old_weight = self.current_weight
            
            if below_acc < 0.15:  # Ã‡ok dÃ¼ÅŸÃ¼k - ciddi artÄ±ÅŸ gerekli
                self.current_weight *= 1.8
                adjustment = "ğŸ”´ Ciddi ArtÄ±ÅŸ (Ã—1.8)"
            elif below_acc < 0.40:  # DÃ¼ÅŸÃ¼k - artÄ±ÅŸ gerekli
                self.current_weight *= 1.3
                adjustment = "ğŸŸ  Orta ArtÄ±ÅŸ (Ã—1.3)"
            elif below_acc < 0.60:  # Hedefin altÄ±nda - hafif artÄ±ÅŸ
                self.current_weight *= 1.1
                adjustment = "ğŸŸ¡ Hafif ArtÄ±ÅŸ (Ã—1.1)"
            elif below_acc > 0.85 and above_acc < 0.50:  # Ã‡ok yÃ¼ksek - azaltma gerekli
                self.current_weight *= 0.7
                adjustment = "ğŸŸ¢ Azaltma (Ã—0.7)"
            else:
                adjustment = "âœ… DeÄŸiÅŸiklik Yok (Dengeli)"
            
            # Weight'i sÄ±nÄ±rla (1.0 - 25.0 arasÄ±)
            self.current_weight = max(1.0, min(25.0, self.current_weight))
            
            # En iyi sonucu kaydet
            if below_acc > self.best_below_acc:
                self.best_below_acc = below_acc
                self.best_weight = self.current_weight
            
            # GeÃ§miÅŸi kaydet
            self.weight_history.append({
                'epoch': epoch,
                'weight': self.current_weight,
                'below_acc': below_acc,
                'above_acc': above_acc
            })
            
            # Rapor
            print(f"\n{'='*70}")
            print(f"ğŸ“Š {self.stage_name} - Epoch {epoch+1} - DYNAMIC WEIGHT ADJUSTMENT")
            print(f"{'='*70}")
            print(f"ğŸ”´ 1.5 ALTI: {below_acc*100:.1f}% (EÅŸik: 0.85)")
            print(f"ğŸŸ¢ 1.5 ÃœSTÃœ: {above_acc*100:.1f}% (EÅŸik: 0.85)")
            print(f"âš–ï¸  Weight AyarlamasÄ±: {old_weight:.2f} â†’ {self.current_weight:.2f} ({adjustment})")
            print(f"ğŸ† En Ä°yi 1.5 AltÄ±: {self.best_below_acc*100:.1f}% (Weight: {self.best_weight:.2f})")
            print(f"{'='*70}\n")

# =============================================================================
# METRICS CALLBACK (Raporlama iÃ§in)
# =============================================================================
class ProgressiveMetricsCallback(callbacks.Callback):
    def __init__(self, stage_name):
        super().__init__()
        self.stage_name = stage_name
        self.best_below_acc = 0
        
    def on_epoch_end(self, epoch, logs=None):
        if epoch % 5 == 0:
            # VALIDATION seti Ã¼zerinde threshold metrics (test leakage Ã¶nlendi!)
            p = self.model.predict([X_f_val, X_50_val, X_200_val, X_500_val, X_1000_val], verbose=0)[2].flatten()
            # GÃœNCELLEME: 0.85 GÃ¼ven eÅŸiÄŸi
            p_thr = (p >= CONFIDENCE_THRESHOLD).astype(int)
            t_thr = (y_reg_val >= 1.5).astype(int)
            
            below_mask = t_thr == 0
            above_mask = t_thr == 1
            
            below_acc = accuracy_score(t_thr[below_mask], p_thr[below_mask]) if below_mask.sum() > 0 else 0
            above_acc = accuracy_score(t_thr[above_mask], p_thr[above_mask]) if above_mask.sum() > 0 else 0
            
            false_positive = ((p_thr == 1) & (t_thr == 0)).sum()
            total_below = below_mask.sum()
            risk = false_positive / total_below if total_below > 0 else 0
            
            print(f"\n{'='*70}")
            print(f"ğŸ“Š {self.stage_name} - Epoch {epoch+1} METRIKLER")
            print(f"{'='*70}")
            
            # 1.5 AltÄ± DoÄŸruluÄŸu
            below_emoji = "âœ…" if below_acc >= 0.75 else "âš ï¸" if below_acc >= 0.50 else "âŒ"
            print(f"\nğŸ”´ 1.5 ALTI DOÄRULUÄU: {below_acc*100:.1f}% {below_emoji}")
            print(f"   â””â”€ Ne anlama geliyor?")
            print(f"      Model 1.5 altÄ±ndaki deÄŸerleri ne kadar iyi tahmin ediyor?")
            print(f"      Ã–rnek: 100 adet 1.5 altÄ± deÄŸerden {int(below_acc*100)} tanesini doÄŸru buldu")
            print(f"   â””â”€ Hedef: %75+ (ÅŸu an: {'HEDEF AÅILDI! âœ…' if below_acc >= 0.75 else f'%{(75-below_acc*100):.1f} daha gerekli'})")
            
            # 1.5 ÃœstÃ¼ DoÄŸruluÄŸu
            above_emoji = "âœ…" if above_acc >= 0.75 else "âš ï¸" if above_acc >= 0.50 else "âŒ"
            print(f"\nğŸŸ¢ 1.5 ÃœSTÃœ DOÄRULUÄU: {above_acc*100:.1f}% {above_emoji}")
            print(f"   â””â”€ Ne anlama geliyor?")
            print(f"      Model 1.5 Ã¼stÃ¼ndeki deÄŸerleri ne kadar iyi tahmin ediyor?")
            print(f"      Ã–rnek: 100 adet 1.5 Ã¼stÃ¼ deÄŸerden {int(above_acc*100)} tanesini doÄŸru buldu")
            print(f"   â””â”€ Hedef: %75+ (ÅŸu an: {'HEDEF AÅILDI! âœ…' if above_acc >= 0.75 else f'%{(75-above_acc*100):.1f} daha gerekli'})")
            
            # Para KaybÄ± Riski
            risk_emoji = "âœ…" if risk < 0.20 else "âš ï¸" if risk < 0.40 else "âŒ"
            print(f"\nğŸ’° PARA KAYBI RÄ°SKÄ°: {risk*100:.1f}% {risk_emoji}")
            print(f"   â””â”€ Ne anlama geliyor?")
            print(f"      Model 1.5 altÄ± olduÄŸunda yanlÄ±ÅŸlÄ±kla '1.5 Ã¼stÃ¼' deme oranÄ±")
            print(f"      Bu durumda bahis yapar ve PARA KAYBEDERSÄ°NÄ°Z!")
            print(f"      Ã–rnek: 100 oyunun {int(risk*100)}'Ä±nda yanlÄ±ÅŸ tahminle para kaybÄ±")
            print(f"   â””â”€ Hedef: <%20 (ÅŸu an: {'GÃœVENLÄ°! âœ…' if risk < 0.20 else f'%{(risk*100-20):.1f} daha fazla risk var'})")
            
            # Model Durumu Ã–zeti
            print(f"\nğŸ¯ MODEL DURUMU (EÅŸik: 0.85):")
            if below_acc >= 0.75 and above_acc >= 0.75 and risk < 0.20:
                print(f"   âœ… âœ… âœ… MÃœKEMMEL! Model kullanÄ±ma hazÄ±r!")
            elif below_acc >= 0.60 and risk < 0.30:
                print(f"   âœ… Ä°YÄ° - Biraz daha eÄŸitimle hedeflere ulaÅŸÄ±labilir")
            elif below_acc == 0.0 or below_acc == 1.0:
                print(f"   âŒ KÃ–TÃœ! Model bir tarafa KILITLENIYOR!")
                print(f"      â†’ Model dengesiz Ã¶ÄŸreniyor, class weight ayarlanmalÄ±")
            else:
                print(f"   âš ï¸ ORTA - Devam ediyor...")
            
            # Sanal Kasa SimÃ¼lasyonu
            print(f"\nğŸ’° SANAL KASA SÄ°MÃœLASYONU (Test Seti):")
            wallet = 1000.0  # BaÅŸlangÄ±Ã§ kasasÄ±
            bet_amount = 10.0  # Her bahis miktarÄ±
            win_amount = 15.0  # KazanÄ±nca eklenen miktar
            
            total_bets = 0
            total_wins = 0
            total_losses = 0
            
            # Test verileri Ã¼zerinde simÃ¼lasyon
            for i in range(len(p_thr)):
                model_pred = p_thr[i]  # Model tahmini (1.5 Ã¼stÃ¼ ve gÃ¼venli mi?)
                actual_value = y_reg_te[i]  # GerÃ§ek deÄŸer
                
                # Model "1.5 Ã¼stÃ¼" diyorsa (zaten 0.85 Ã¼stÃ¼ filtrelendi)
                if model_pred == 1:
                    wallet -= bet_amount  # Bahis yap
                    total_bets += 1
                    
                    # GerÃ§ek sonuca bak
                    if actual_value >= 1.5:
                        # KazandÄ±k!
                        wallet += win_amount
                        total_wins += 1
                    else:
                        # Kaybettik
                        total_losses += 1
                # Model "1.5 altÄ±" diyorsa pas geÃ§
            
            # SonuÃ§larÄ± hesapla
            profit_loss = wallet - 1000.0
            roi = (profit_loss / 1000.0) * 100 if total_bets > 0 else 0
            win_rate = (total_wins / total_bets * 100) if total_bets > 0 else 0
            
            # Emoji seÃ§
            if profit_loss > 100:
                wallet_emoji = "ğŸš€"
            elif profit_loss > 0:
                wallet_emoji = "âœ…"
            elif profit_loss > -100:
                wallet_emoji = "âš ï¸"
            else:
                wallet_emoji = "âŒ"
            
            # GeliÅŸtirilmiÅŸ rapor formatÄ±
            net_wins = total_wins * (win_amount - bet_amount)  # Net kazanÃ§
            net_losses = total_losses * bet_amount  # Net kayÄ±p
            
            print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            print(f"   ")
            print(f"   ğŸ“Š OYUN PARAMETRELERÄ°:")
            print(f"      BaÅŸlangÄ±Ã§ Sermayesi: {1000.0:,.2f} TL")
            print(f"      Bahis TutarÄ±: {bet_amount:.2f} TL (sabit)")
            print(f"      KazanÃ§ Hedefi: 1.5x â†’ {win_amount:.2f} TL geri alma")
            print(f"      ")
            print(f"      Her KazanÃ§ta: +{win_amount - bet_amount:.2f} TL ({win_amount:.0f} - {bet_amount:.0f} = {win_amount - bet_amount:.0f})")
            print(f"      Her KayÄ±pta: -{bet_amount:.2f} TL (bahis kaybÄ±)")
            print(f"   ")
            print(f"   ğŸ¯ TEST SETÄ° SONUÃ‡LARI:")
            print(f"      Toplam Oyun: {total_bets} el")
            print(f"      âœ… Kazanan: {total_wins} oyun ({win_rate:.1f}%)")
            print(f"      âŒ Kaybeden: {total_losses} oyun ({100-win_rate:.1f}%)")
            print(f"   ")
            print(f"   ğŸ’¸ DETAYLI HESAPLAMA:")
            print(f"      ")
            print(f"      KazanÄ±lan Oyunlar ({total_wins} el):")
            print(f"      â””â”€ {total_wins} Ã— {win_amount - bet_amount:.2f} TL = +{net_wins:,.2f} TL âœ…")
            print(f"      ")
            print(f"      Kaybedilen Oyunlar ({total_losses} el):")
            print(f"      â””â”€ {total_losses} Ã— {bet_amount:.2f} TL = -{net_losses:,.2f} TL âŒ")
            print(f"      ")
            print(f"      {'â”€'*50}")
            print(f"      Net Kar/Zarar: {net_wins:,.2f} - {net_losses:,.2f} = {profit_loss:+,.2f} TL")
            print(f"      Final Sermaye: 1,000 {profit_loss:+,.0f} = {wallet:,.2f} TL (kalan)")
            print(f"   ")
            print(f"   ğŸ“ˆ PERFORMANS ANALÄ°ZÄ°:")
            print(f"      ")
            print(f"      ROI: {roi:+.1f}% {wallet_emoji}")
            print(f"      â””â”€ Sermayenin {'%'+str(round((wallet/1000.0)*100, 1)) if wallet > 0 else '0'}'si kaldÄ±")
            print(f"      ")
            print(f"      ğŸ¯ BAÅABAÅ Ä°Ã‡Ä°N GEREKLÄ°:")
            print(f"         2 kazanÃ§ = 1 kayÄ±p dengelemeli (2Ã—{win_amount - bet_amount:.0f} = 1Ã—{bet_amount:.0f})")
            print(f"         Gerekli Kazanma OranÄ±: %66.7 (3'te 2)")
            print(f"      ")
            print(f"      ğŸ“Š MEVCUT DURUM:")
            print(f"         Kazanma OranÄ±: {win_rate:.1f}% ({total_bets}'de {total_wins})")
            print(f"         Hedeften Fark: {win_rate - 66.7:+.1f}% {'âš ï¸' if win_rate < 66.7 else 'âœ…'}")
            print(f"      ")
            print(f"   ğŸ’¡ DEÄERLENDÄ°RME:")
            print(f"      ")
            if profit_loss > 0:
                print(f"      âœ… Model bu performansla kar ettiriyor!")
            else:
                print(f"      âŒ Model bu performansla zarar ettiriyor!")
            print(f"      ")
            print(f"      ğŸ“Š Matematik:")
            print(f"         â€¢ 2 kazanÃ§ = +{(win_amount - bet_amount) * 2:.0f} TL (2 Ã— {win_amount - bet_amount:.0f})")
            print(f"         â€¢ 1 kayÄ±p = -{bet_amount:.0f} TL")
            print(f"         â€¢ Bu yÃ¼zden en az %67 kazanma ÅŸart!")
            print(f"      ")
            if win_rate < 66.7:
                print(f"      âš ï¸ %{win_rate:.1f} kazanma oranÄ± yetersiz:")
                games_per_100 = 100
                wins_per_100 = round(win_rate)
                losses_per_100 = 100 - wins_per_100
                net_per_100 = (wins_per_100 * (win_amount - bet_amount)) - (losses_per_100 * bet_amount)
                print(f"         â€¢ Her 100 oyunda ~{wins_per_100} kazanÃ§, ~{losses_per_100} kayÄ±p")
                print(f"         â€¢ Net: ({wins_per_100}Ã—{win_amount - bet_amount:.0f}) - ({losses_per_100}Ã—{bet_amount:.0f}) = {net_per_100:+.0f} TL")
                print(f"         â€¢ 100 oyunda ~{abs(net_per_100):.0f} TL {'kayÄ±p!' if net_per_100 < 0 else 'kar!'}")
            print(f"   ")
            print(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            
            print(f"\n{'='*70}\n")
            
            if below_acc > self.best_below_acc:
                self.best_below_acc = below_acc
                print(f"  âœ¨ YENÄ° REKOR! En iyi 1.5 altÄ±: {below_acc*100:.1f}%\n")

# =============================================================================
# CHECKPOINT YARDIMCI FONKSÄ°YONLARI
# =============================================================================
def save_checkpoint(stage, epoch, model, optimizer, metrics_history, class_weights, filename=None):
    """
    EÄŸitim checkpoint'i kaydet
    
    Args:
        stage: Hangi aÅŸama (1, 2, 3)
        epoch: KaÃ§Ä±ncÄ± epoch
        model: Model instance
        optimizer: Optimizer instance (kullanÄ±lmÄ±yor - TensorFlow uyumluluk sorunu)
        metrics_history: Metrics geÃ§miÅŸi
        class_weights: Class weight deÄŸerleri
        filename: Checkpoint dosya adÄ± (opsiyonel)
    """
    if filename is None:
        filename = f'checkpoint_stage{stage}_epoch{epoch}.pkl'
    
    checkpoint = {
        'stage': stage,
        'epoch': epoch,
        'model_weights': model.get_weights(),
        # optimizer_weights kaldÄ±rÄ±ldÄ± - TensorFlow/Keras Adam optimizer'Ä± get_weights() desteklemiyor
        'metrics_history': metrics_history,
        'class_weights': class_weights,
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    with open(filename, 'wb') as f:
        pickle.dump(checkpoint, f)
    
    print(f"ğŸ’¾ Checkpoint kaydedildi: {filename}")
    return filename

def load_checkpoint(filename):
    """
    Checkpoint yÃ¼kle
    
    Args:
        filename: Checkpoint dosya adÄ±
        
    Returns:
        Checkpoint dictionary veya None
    """
    try:
        with open(filename, 'rb') as f:
            checkpoint = pickle.load(f)
        print(f"âœ… Checkpoint yÃ¼klendi: {filename}")
        print(f"   AÅŸama: {checkpoint['stage']}, Epoch: {checkpoint['epoch']}")
        print(f"   Zaman: {checkpoint['timestamp']}")
        return checkpoint
    except FileNotFoundError:
        print(f"âš ï¸ Checkpoint bulunamadÄ±: {filename}")
        return None
    except Exception as e:
        print(f"âŒ Checkpoint yÃ¼kleme hatasÄ±: {e}")
        return None

# =============================================================================
# AÅAMA 1: REGRESSION-ONLY (200 epoch)
# =============================================================================
print("\n" + "="*80)
print("ğŸ”¥ AÅAMA 1: FOUNDATION TRAINING")
print("="*80)
print("Hedef: Model hem deÄŸer tahmin etmeyi HEM DE 1.5 eÅŸiÄŸini birlikte Ã¶ÄŸrensin")
print("Epoch: 100 | Batch: 64 | LR: 0.0001")
print("Loss Weights: Regression 60%, Classification 10%, Threshold 30%")
print("Monitor: val_threshold_accuracy | Patience: 10")
print("="*80 + "\n")

# Checkpoint kontrolÃ¼ - AÅAMA 1 iÃ§in resume
stage1_checkpoint = load_checkpoint('checkpoint_stage1_latest.pkl')
initial_epoch_stage1 = 0

stage1_start = time.time()

model = build_progressive_model(X_f.shape[1])
print(f"âœ… Model: {model.count_params():,} parametre")

# Checkpoint varsa yÃ¼kle
if stage1_checkpoint and stage1_checkpoint['stage'] == 1:
    print("ğŸ”„ AÅAMA 1 checkpoint'inden devam ediliyor...")
    model.set_weights(stage1_checkpoint['model_weights'])
    initial_epoch_stage1 = stage1_checkpoint['epoch']
    print(f"   Epoch {initial_epoch_stage1} 'den devam edilecek")

# Class weights - LAZY LEARNING Ã–NLEME (yeterince yÃ¼ksek)
w0_stage1 = 25.0  # 1.5 altÄ± iÃ§in: 25.0x (lazy learning'i kesin Ã¶nler)
w1_stage1 = 1.0   # 1.5 Ã¼stÃ¼ baseline

print(f"ğŸ“Š CLASS WEIGHTS (AÅAMA 1 - Lazy Learning Ã–nleme - TIME-SERIES SPLIT):")
print(f"  1.5 altÄ±: {w0_stage1:.2f}x (yÃ¼ksek - lazy learning'i Ã¶nler)")
print(f"  1.5 Ã¼stÃ¼: {w1_stage1:.2f}x\n")

# AÅAMA 1: Foundation Training - SADECE WEIGHTED BCE (Ã§akÄ±ÅŸma yok!)
model.compile(
    optimizer=Adam(0.0001),
    loss={
        'regression': percentage_aware_regression_loss,  # YENÄ°: YÃ¼zde hataya dayalÄ± regression loss
        'classification': 'categorical_crossentropy',
        'threshold': create_weighted_binary_crossentropy(w0_stage1, w1_stage1)  # SADECE weighted BCE
    },
    loss_weights={'regression': 0.65, 'classification': 0.10, 'threshold': 0.25},  # Regression aÄŸÄ±rlÄ±ÄŸÄ± artÄ±rÄ±ldÄ±: 0.55 â†’ 0.65
    metrics={'regression': ['mae'], 'classification': ['accuracy'], 'threshold': ['accuracy']}
)

# Dynamic Weight Callback baÅŸlat (otomatik ayarlama iÃ§in)
dynamic_callback_1 = DynamicWeightCallback("AÅAMA 1", initial_weight=1.5, target_below_acc=0.70)

# Virtual Bankroll Callback (HER EPOCH iÃ§in sanal kasa)
virtual_bankroll_1 = VirtualBankrollCallback(
    stage_name="AÅAMA 1",
    X_test=[X_f_te, X_50_te, X_200_te, X_500_te, X_1000_te],
    y_test=y_reg_te,
    threshold=1.5,
    starting_capital=1000.0,
    bet_amount=10.0
)

cb1 = [
    callbacks.ModelCheckpoint('stage1_best.h5', monitor='val_threshold_accuracy', save_best_only=True, mode='max', verbose=1),
    callbacks.EarlyStopping(monitor='val_threshold_accuracy', patience=12, min_delta=0.001, mode='max', restore_best_weights=True, verbose=1),
    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=12, min_lr=1e-6, verbose=1),
    dynamic_callback_1,
    virtual_bankroll_1,  # YENÄ°: Her epoch sanal kasa gÃ¶sterimi
    ProgressiveMetricsCallback("AÅAMA 1")
]

hist1 = model.fit(
    [X_f_tr, X_50_tr, X_200_tr, X_500_tr, X_1000_tr],
    {'regression': y_reg_tr, 'classification': y_cls_tr, 'threshold': y_thr_tr},
    epochs=100,
    batch_size=64,
    validation_data=(  # âœ… MANUEL VALIDATION (kronolojik!)
        [X_f_val, X_50_val, X_200_val, X_500_val, X_1000_val],
        {'regression': y_reg_val, 'classification': y_cls_val, 'threshold': y_thr_val}
    ),
    shuffle=False,  # âœ… KRITIK: Shuffle devre dÄ±ÅŸÄ± (TIME-SERIES)!
    callbacks=cb1,
    verbose=1,
    initial_epoch=initial_epoch_stage1
)

# AÅAMA 1 Checkpoint kaydet
save_checkpoint(
    stage=1,
    epoch=len(hist1.history['loss']),
    model=model,
    optimizer=model.optimizer,
    metrics_history=hist1.history,
    class_weights={'w0': w0_stage1, 'w1': w1_stage1},
    filename='checkpoint_stage1_latest.pkl'
)

stage1_time = time.time() - stage1_start
print(f"\nâœ… AÅAMA 1 TamamlandÄ±! SÃ¼re: {stage1_time/60:.1f} dakika")

# AÅAMA 1 DeÄŸerlendirme
pred1 = model.predict([X_f_te, X_50_te, X_200_te, X_500_te, X_1000_te], verbose=0)
mae1 = mean_absolute_error(y_reg_te, pred1[0])
print(f"ğŸ“Š AÅAMA 1 SonuÃ§: MAE = {mae1:.4f}")

# =============================================================================
# AÅAMA 2: THRESHOLD FINE-TUNING (150 epoch)
# =============================================================================
print("\n" + "="*80)
print("ğŸ”¥ AÅAMA 2: THRESHOLD FINE-TUNING (Hafif ArtÄ±ÅŸ)")
print("="*80)
print("Hedef: 1.5 altÄ±/Ã¼stÃ¼ ayrÄ±mÄ±nÄ± keskinleÅŸtir (dengeli class weights)")
print("Epoch: 80 | Batch: 32 | LR: 0.0001 | Class Weight: 1.5x (YumuÅŸak!)")
print("Monitor: val_threshold_accuracy | Patience: 10")
print("="*80 + "\n")

stage2_start = time.time()

# Checkpoint kontrolÃ¼ - AÅAMA 2 iÃ§in resume
stage2_checkpoint = load_checkpoint('checkpoint_stage2_latest.pkl')
initial_epoch_stage2 = 0

# AÅAMA 1 modelini yÃ¼kle
if stage2_checkpoint and stage2_checkpoint['stage'] == 2:
    print("ğŸ”„ AÅAMA 2 checkpoint'inden devam ediliyor...")
    model.set_weights(stage2_checkpoint['model_weights'])
    # optimizer weights kaldÄ±rÄ±ldÄ± - TensorFlow uyumluluk sorunu
    initial_epoch_stage2 = stage2_checkpoint['epoch']
    print(f"   Epoch {initial_epoch_stage2}'den devam edilecek")
else:
    model.load_weights('stage1_best.h5')

# Class weights - LAZY LEARNING Ã–NLEME (yeterince yÃ¼ksek)
w0 = 30.0  # 1.5 altÄ± iÃ§in: 30.0x (lazy learning'i kesin Ã¶nler)
w1 = 1.0   # 1.5 Ã¼stÃ¼ baseline

print(f"ğŸ“Š CLASS WEIGHTS (AÅAMA 2 - Lazy Learning Ã–nleme - TIME-SERIES SPLIT):")
print(f"  1.5 altÄ±: {w0:.2f}x (yÃ¼ksek - lazy learning Ã¶nleme)")
print(f"  1.5 Ã¼stÃ¼: {w1:.2f}x\n")

# AÅAMA 2: Regression + Threshold - SADECE WEIGHTED BCE (Ã§akÄ±ÅŸma yok!)
model.compile(
    optimizer=Adam(0.0001),
    loss={
        'regression': percentage_aware_regression_loss,  # YENÄ°: YÃ¼zde hataya dayalÄ± regression loss
        'classification': 'categorical_crossentropy',
        'threshold': create_weighted_binary_crossentropy(w0, w1)  # SADECE weighted BCE
    },
    loss_weights={'regression': 0.55, 'classification': 0.10, 'threshold': 0.35},  # Regression aÄŸÄ±rlÄ±ÄŸÄ± artÄ±rÄ±ldÄ±: 0.45 â†’ 0.55
    metrics={'regression': ['mae'], 'classification': ['accuracy'], 'threshold': ['accuracy', 'binary_crossentropy']}
)

# Adaptive Weight Scheduler (GÃœÃ‡LENDIRILDI - Lazy Learning Ã–nleme)
adaptive_scheduler_2 = AdaptiveWeightScheduler(
    initial_weight=2.0,    # DÃœZELTME: 20.0 â†’ 2.0 (10x azaltma!)
    min_weight=1.0,        # DÃœZELTME: 10.0 â†’ 1.0 (normal seviye)
    max_weight=5.0,        # DÃœZELTME: 50.0 â†’ 5.0 (reasonable limit)
    target_below_acc=0.70,
    target_above_acc=0.75,
    test_data=([X_f_te, X_50_te, X_200_te, X_500_te, X_1000_te], y_reg_te),
    threshold=1.5,
    check_interval=5
)

# Dynamic Weight Callback (mevcut - opsiyonel)
dynamic_callback_2 = DynamicWeightCallback("AÅAMA 2", initial_weight=1.5, target_below_acc=0.70)

# Virtual Bankroll Callback (HER EPOCH iÃ§in sanal kasa)
virtual_bankroll_2 = VirtualBankrollCallback(
    stage_name="AÅAMA 2",
    X_test=[X_f_te, X_50_te, X_200_te, X_500_te, X_1000_te],
    y_test=y_reg_te,
    threshold=1.5,
    starting_capital=1000.0,
    bet_amount=10.0
)

cb2 = [
    callbacks.ModelCheckpoint('stage2_best.h5', monitor='val_threshold_accuracy', save_best_only=True, mode='max', verbose=1),
    callbacks.EarlyStopping(monitor='val_threshold_accuracy', patience=10, min_delta=0.001, mode='max', restore_best_weights=True, verbose=1),
    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7, verbose=1),
    adaptive_scheduler_2,  # YENÄ°: Adaptive weight scheduler
    virtual_bankroll_2,  # YENÄ°: Her epoch sanal kasa gÃ¶sterimi
    ProgressiveMetricsCallback("AÅAMA 2")
]

hist2 = model.fit(
    [X_f_tr, X_50_tr, X_200_tr, X_500_tr, X_1000_tr],
    {'regression': y_reg_tr, 'classification': y_cls_tr, 'threshold': y_thr_tr},
    epochs=80,
    batch_size=32,
    validation_data=(  # âœ… MANUEL VALIDATION (kronolojik!)
        [X_f_val, X_50_val, X_200_val, X_500_val, X_1000_val],
        {'regression': y_reg_val, 'classification': y_cls_val, 'threshold': y_thr_val}
    ),
    shuffle=False,  # âœ… KRITIK: Shuffle devre dÄ±ÅŸÄ± (TIME-SERIES)!
    callbacks=cb2,
    verbose=1,
    initial_epoch=initial_epoch_stage2
)

# AÅAMA 2 Checkpoint kaydet
save_checkpoint(
    stage=2,
    epoch=len(hist2.history['loss']),
    model=model,
    optimizer=model.optimizer,
    metrics_history=hist2.history,
    class_weights={'w0': w0, 'w1': w1},
    filename='checkpoint_stage2_latest.pkl'
)

stage2_time = time.time() - stage2_start
print(f"\nâœ… AÅAMA 2 TamamlandÄ±! SÃ¼re: {stage2_time/60:.1f} dakika")

# =============================================================================
# AÅAMA 3: FULL MODEL FINE-TUNING (150 epoch)
# =============================================================================
print("\n" + "="*80)
print("ğŸ”¥ AÅAMA 3: FULL MODEL FINE-TUNING (Dengeli Final)")
print("="*80)
print("Hedef: TÃ¼m output'larÄ± birlikte optimize et (dengeli final push)")
print("Epoch: 80 | Batch: 16 | LR: 0.00005 | Class Weight: 2.0x (Dengeli!)")
print("Loss Weights: Regression 40%, Classification 15%, Threshold 45%")
print("Monitor: val_threshold_accuracy | Patience: 8")
print("="*80 + "\n")

stage3_start = time.time()

# Checkpoint kontrolÃ¼ - AÅAMA 3 iÃ§in resume
stage3_checkpoint = load_checkpoint('checkpoint_stage3_latest.pkl')
initial_epoch_stage3 = 0

# AÅAMA 2 modelini yÃ¼kle
if stage3_checkpoint and stage3_checkpoint['stage'] == 3:
    print("ğŸ”„ AÅAMA 3 checkpoint'inden devam ediliyor...")
    model.set_weights(stage3_checkpoint['model_weights'])
    # optimizer weights kaldÄ±rÄ±ldÄ± - TensorFlow uyumluluk sorunu
    initial_epoch_stage3 = stage3_checkpoint['epoch']
    print(f"   Epoch {initial_epoch_stage3}'den devam edilecek")
else:
    model.load_weights('stage2_best.h5')

# Class weights - MAKSIMUM FINAL (lazy learning'i kesin Ã¶nler)
w0_final = 35.0  # 1.5 altÄ± iÃ§in: 35.0x (maksimum - final push)
w1_final = 1.0   # 1.5 Ã¼stÃ¼ baseline

print(f"ğŸ“Š CLASS WEIGHTS (AÅAMA 3 - Maksimum Final - TIME-SERIES SPLIT):")
print(f"  1.5 altÄ±: {w0_final:.2f}x (maksimum - final push)")
print(f"  1.5 Ã¼stÃ¼: {w1_final:.2f}x\n")

# AÅAMA 3: TÃ¼m output'lar aktif - SADECE FOCAL LOSS (Ã§akÄ±ÅŸma yok!)
model.compile(
    optimizer=Adam(0.00005),
    loss={
        'regression': percentage_aware_regression_loss,  # YENÄ°: YÃ¼zde hataya dayalÄ± regression loss
        'classification': 'categorical_crossentropy',
        'threshold': balanced_focal_loss()  # SADECE focal loss (gamma=2.0, alpha=0.7)
    },
    loss_weights={'regression': 0.50, 'classification': 0.15, 'threshold': 0.35},  # Regression aÄŸÄ±rlÄ±ÄŸÄ± artÄ±rÄ±ldÄ±: 0.40 â†’ 0.50
    metrics={'regression': ['mae'], 'classification': ['accuracy'], 'threshold': ['accuracy', 'binary_crossentropy']}
)

# Adaptive Weight Scheduler (GÃœÃ‡LENDIRILDI - Lazy Learning Ã–nleme)
adaptive_scheduler_3 = AdaptiveWeightScheduler(
    initial_weight=2.5,    # DÃœZELTME: 25.0 â†’ 2.5 (10x azaltma!)
    min_weight=1.5,        # DÃœZELTME: 15.0 â†’ 1.5 (normal seviye)
    max_weight=6.0,        # DÃœZELTME: 50.0 â†’ 6.0 (reasonable limit)
    target_below_acc=0.70,
    target_above_acc=0.75,
    test_data=([X_f_te, X_50_te, X_200_te, X_500_te, X_1000_te], y_reg_te),
    threshold=1.5,
    check_interval=5
)

# Dynamic Weight Callback (mevcut - opsiyonel)
dynamic_callback_3 = DynamicWeightCallback("AÅAMA 3", initial_weight=2.0, target_below_acc=0.70)

# Virtual Bankroll Callback (HER EPOCH iÃ§in sanal kasa)
virtual_bankroll_3 = VirtualBankrollCallback(
    stage_name="AÅAMA 3",
    X_test=[X_f_te, X_50_te, X_200_te, X_500_te, X_1000_te],
    y_test=y_reg_te,
    threshold=1.5,
    starting_capital=1000.0,
    bet_amount=10.0
)

cb3 = [
    callbacks.ModelCheckpoint('stage3_best.h5', monitor='val_threshold_accuracy', save_best_only=True, mode='max', verbose=1),
    callbacks.EarlyStopping(monitor='val_threshold_accuracy', patience=8, min_delta=0.001, mode='max', restore_best_weights=True, verbose=1),
    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-8, verbose=1),
    adaptive_scheduler_3,  # YENÄ°: Adaptive weight scheduler
    virtual_bankroll_3,  # YENÄ°: Her epoch sanal kasa gÃ¶sterimi
    ProgressiveMetricsCallback("AÅAMA 3")
]

hist3 = model.fit(
    [X_f_tr, X_50_tr, X_200_tr, X_500_tr, X_1000_tr],
    {'regression': y_reg_tr, 'classification': y_cls_tr, 'threshold': y_thr_tr},
    epochs=80,
    batch_size=16,
    validation_data=(  # âœ… MANUEL VALIDATION (kronolojik!)
        [X_f_val, X_50_val, X_200_val, X_500_val, X_1000_val],
        {'regression': y_reg_val, 'classification': y_cls_val, 'threshold': y_thr_val}
    ),
    shuffle=False,  # âœ… KRITIK: Shuffle devre dÄ±ÅŸÄ± (TIME-SERIES)!
    callbacks=cb3,
    verbose=1,
    initial_epoch=initial_epoch_stage3
)

# AÅAMA 3 Checkpoint kaydet
save_checkpoint(
    stage=3,
    epoch=len(hist3.history['loss']),
    model=model,
    optimizer=model.optimizer,
    metrics_history=hist3.history,
    class_weights={'w0': w0_final, 'w1': w1_final},
    filename='checkpoint_stage3_latest.pkl'
)

stage3_time = time.time() - stage3_start
print(f"\nâœ… AÅAMA 3 TamamlandÄ±! SÃ¼re: {stage3_time/60:.1f} dakika")

# =============================================================================
# FINAL EVALUATION
# =============================================================================
print("\n" + "="*80)
print("ğŸ“Š FINAL DEÄERLENDÄ°RME (Test Seti)")
print("="*80)

# En iyi modeli yÃ¼kle
model.load_weights('stage3_best.h5')

pred = model.predict([X_f_te, X_50_te, X_200_te, X_500_te, X_1000_te], verbose=0)
p_reg = pred[0].flatten()
p_cls = pred[1]
p_thr = pred[2].flatten()

# Regression metrics
mae_final = mean_absolute_error(y_reg_te, p_reg)
rmse_final = np.sqrt(mean_squared_error(y_reg_te, p_reg))

print(f"\nğŸ“ˆ REGRESSION:")
print(f"  MAE: {mae_final:.4f}")
print(f"  RMSE: {rmse_final:.4f}")

# Threshold metrics
thr_true = (y_reg_te >= 1.5).astype(int)
# GÃœNCELLEME: %85 GÃ¼ven EÅŸiÄŸi
thr_pred = (p_thr >= CONFIDENCE_THRESHOLD).astype(int)
thr_acc = accuracy_score(thr_true, thr_pred)

below_mask = thr_true == 0
above_mask = thr_true == 1
below_acc = accuracy_score(thr_true[below_mask], thr_pred[below_mask]) if below_mask.sum() > 0 else 0
above_acc = accuracy_score(thr_true[above_mask], thr_pred[above_mask]) if above_mask.sum() > 0 else 0

print(f"\nğŸ¯ THRESHOLD (1.5x) - EÅŸik: {CONFIDENCE_THRESHOLD}:")
print(f"  Genel Accuracy: {thr_acc*100:.2f}%")
print(f"\nğŸ”´ 1.5 ALTI:")
print(f"  DoÄŸruluk: {below_acc*100:.2f}%", end="")
if below_acc >= 0.75:
    print(" âœ… HEDEF AÅILDI!")
else:
    print(f" (Hedef: 75%+)")

print(f"\nğŸŸ¢ 1.5 ÃœSTÃœ:")
print(f"  DoÄŸruluk: {above_acc*100:.2f}%")

# Confusion matrix
cm = confusion_matrix(thr_true, thr_pred)
print(f"\nğŸ“‹ CONFUSION MATRIX:")
print(f"                Tahmin")
print(f"GerÃ§ek   1.5 AltÄ± | 1.5 ÃœstÃ¼")
print(f"1.5 AltÄ± {cm[0,0]:6d}   | {cm[0,1]:6d}  âš ï¸ PARA KAYBI")
print(f"1.5 ÃœstÃ¼ {cm[1,0]:6d}   | {cm[1,1]:6d}")

if cm[0,0] + cm[0,1] > 0:
    fpr = cm[0,1] / (cm[0,0] + cm[0,1])
    print(f"\nğŸ’° PARA KAYBI RÄ°SKÄ°: {fpr*100:.1f}%", end="")
    if fpr < 0.20:
        print(" âœ… HEDEF AÅILDI!")
    else:
        print(f" (Hedef: <20%)")

# Classification metrics
cls_true = np.argmax(y_cls_te, axis=1)
cls_pred = np.argmax(p_cls, axis=1)
cls_acc = accuracy_score(cls_true, cls_pred)
print(f"\nğŸ“ KATEGORÄ° CLASSIFICATION:")
print(f"  Accuracy: {cls_acc*100:.2f}%")

# =============================================================================
# Ã‡Ä°FT SANAL KASA SÄ°MÃœLASYONU (YENÄ° - FAZ 2)
# =============================================================================
print("\n" + "="*80)
print("ğŸ’° Ã‡Ä°FT SANAL KASA SÄ°MÃœLASYONU")
print("="*80)

# Dinamik kasa miktarÄ± hesapla
test_count = len(y_reg_te)
initial_bankroll = test_count * 10  # Her test verisi iÃ§in 10 TL
bet_amount = 10.0

print(f"ğŸ“Š Test Veri SayÄ±sÄ±: {test_count:,}")
print(f"ğŸ’° BaÅŸlangÄ±Ã§ KasasÄ±: {initial_bankroll:,.2f} TL (dinamik)")
print(f"ğŸ’µ Bahis TutarÄ±: {bet_amount:.2f} TL (sabit)")
print()

# =============================================================================
# KASA 1: 1.5x EÅÄ°K SÄ°STEMÄ° (Mevcut)
# =============================================================================
print("="*80)
print("ğŸ’° KASA 1: 1.5x EÅÄ°K SÄ°STEMÄ°")
print("="*80)
print("Strateji: Model 1.5x Ã¼stÃ¼ tahmin ederse (GÃ¼ven > %85) â†’ 1.5x'te Ã§Ä±kÄ±ÅŸ")
print()

kasa1_wallet = initial_bankroll
kasa1_total_bets = 0
kasa1_total_wins = 0
kasa1_total_losses = 0

# Model tahminlerini al (threshold output'tan)
# GÃœNCELLEME: thr_pred zaten 0.85 eÅŸiÄŸine gÃ¶re filtrelendi
threshold_predictions = thr_pred 

for i in range(len(y_reg_te)):
    model_pred_cls = threshold_predictions[i]  # 0 veya 1
    actual_value = y_reg_te[i]
    
    # Model "1.5 Ã¼stÃ¼" tahmin ediyorsa bahis yap
    if model_pred_cls == 1:
        kasa1_wallet -= bet_amount  # Bahis yap
        kasa1_total_bets += 1
        
        # 1.5x'te Ã§Ä±kÄ±ÅŸ yap
        exit_point = 1.5
        
        # GerÃ§ek deÄŸer Ã§Ä±kÄ±ÅŸ noktasÄ±ndan bÃ¼yÃ¼k veya eÅŸitse kazandÄ±k
        if actual_value >= exit_point:
            # KazandÄ±k! 1.5x Ã— 10 TL = 15 TL geri al
            kasa1_wallet += exit_point * bet_amount
            kasa1_total_wins += 1
        else:
            # Kaybettik (bahis zaten kesildi)
            kasa1_total_losses += 1

# Kasa 1 sonuÃ§larÄ±
kasa1_profit_loss = kasa1_wallet - initial_bankroll
kasa1_roi = (kasa1_profit_loss / initial_bankroll) * 100
kasa1_win_rate = (kasa1_total_wins / kasa1_total_bets * 100) if kasa1_total_bets > 0 else 0
kasa1_accuracy = kasa1_win_rate

print(f"\nğŸ“Š KASA 1 SONUÃ‡LARI:")
print(f"{'='*70}")
print(f"Toplam Oyun: {kasa1_total_bets:,} el")
print(f"âœ… Kazanan: {kasa1_total_wins:,} oyun ({kasa1_win_rate:.1f}%)")
print(f"âŒ Kaybeden: {kasa1_total_losses:,} oyun ({100-kasa1_win_rate:.1f}%)")
print(f"")
print(f"ğŸ’° BaÅŸlangÄ±Ã§ KasasÄ±: {initial_bankroll:,.2f} TL")
print(f"ğŸ’° Final Kasa: {kasa1_wallet:,.2f} TL")
print(f"ğŸ“ˆ Net Kar/Zarar: {kasa1_profit_loss:+,.2f} TL")
print(f"ğŸ“Š ROI: {kasa1_roi:+.2f}%")
print(f"ğŸ¯ DoÄŸruluk (Kazanma OranÄ±): {kasa1_accuracy:.1f}%")
print(f"{'='*70}\n")

# =============================================================================
# KASA 2: %80 Ã‡IKIÅ SÄ°STEMÄ° (Yeni)
# =============================================================================
print("="*80)
print("ğŸ’° KASA 2: %80 Ã‡IKIÅ SÄ°STEMÄ° (YÃ¼ksek Tahminler)")
print("="*80)
print("Strateji: Model 2.0x+ tahmin ederse VE GÃ¼ven > %85 â†’ Tahmin Ã— 0.80'de Ã§Ä±kÄ±ÅŸ")
print()

kasa2_wallet = initial_bankroll
kasa2_total_bets = 0
kasa2_total_wins = 0
kasa2_total_losses = 0
kasa2_exit_points = []  # Ã‡Ä±kÄ±ÅŸ noktalarÄ±nÄ± kaydet

# Model tahminlerini al (regression output'tan)
y_reg_pred = p_reg

for i in range(len(y_reg_te)):
    model_pred_value = y_reg_pred[i]  # Tahmin edilen deÄŸer
    actual_value = y_reg_te[i]
    is_confident = threshold_predictions[i] == 1 # %85 gÃ¼venli mi?
    
    # SADECE 2.0x ve Ã¼zeri tahminlerde VE YÃ¼ksek gÃ¼vende oyna
    if model_pred_value >= 2.0 and is_confident:
        kasa2_wallet -= bet_amount  # Bahis yap
        kasa2_total_bets += 1
        
        # Ã‡Ä±kÄ±ÅŸ noktasÄ±: Tahmin Ã— 0.80
        exit_point = model_pred_value * 0.80
        kasa2_exit_points.append(exit_point)
        
        # GerÃ§ek deÄŸer Ã§Ä±kÄ±ÅŸ noktasÄ±ndan bÃ¼yÃ¼k veya eÅŸitse kazandÄ±k
        if actual_value >= exit_point:
            # KazandÄ±k! exit_point Ã— 10 TL geri al
            kasa2_wallet += exit_point * bet_amount
            kasa2_total_wins += 1
        else:
            # Kaybettik (bahis zaten kesildi)
            kasa2_total_losses += 1

# Kasa 2 sonuÃ§larÄ±
kasa2_profit_loss = kasa2_wallet - initial_bankroll
kasa2_roi = (kasa2_profit_loss / initial_bankroll) * 100
kasa2_win_rate = (kasa2_total_wins / kasa2_total_bets * 100) if kasa2_total_bets > 0 else 0
kasa2_accuracy = kasa2_win_rate
kasa2_avg_exit = np.mean(kasa2_exit_points) if kasa2_exit_points else 0

print(f"\nğŸ“Š KASA 2 SONUÃ‡LARI:")
print(f"{'='*70}")
print(f"Toplam Oyun: {kasa2_total_bets:,} el")
print(f"âœ… Kazanan: {kasa2_total_wins:,} oyun ({kasa2_win_rate:.1f}%)")
print(f"âŒ Kaybeden: {kasa2_total_losses:,} oyun ({100-kasa2_win_rate:.1f}%)")
print(f"")
print(f"ğŸ’° BaÅŸlangÄ±Ã§ KasasÄ±: {initial_bankroll:,.2f} TL")
print(f"ğŸ’° Final Kasa: {kasa2_wallet:,.2f} TL")
print(f"ğŸ“ˆ Net Kar/Zarar: {kasa2_profit_loss:+,.2f} TL")
print(f"ğŸ“Š ROI: {kasa2_roi:+.2f}%")
print(f"ğŸ¯ DoÄŸruluk (Kazanma OranÄ±): {kasa2_accuracy:.1f}%")
print(f"ğŸ“Š Ortalama Ã‡Ä±kÄ±ÅŸ NoktasÄ±: {kasa2_avg_exit:.2f}x")
print(f"{'='*70}\n")

# =============================================================================
# KARÅILAÅTIRMA
# =============================================================================
print("="*80)
print("ğŸ“Š KASA KARÅILAÅTIRMASI")
print("="*80)
print(f"{'Metrik':<30} {'Kasa 1 (1.5x)':<20} {'Kasa 2 (%80)':<20}")
print(f"{'-'*70}")
print(f"{'Toplam Oyun':<30} {kasa1_total_bets:<20,} {kasa2_total_bets:<20,}")
print(f"{'Kazanan Oyun':<30} {kasa1_total_wins:<20,} {kasa2_total_wins:<20,}")
print(f"{'Kazanma OranÄ±':<30} {kasa1_win_rate:<20.1f}% {kasa2_win_rate:<20.1f}%")
print(f"{'Net Kar/Zarar':<30} {kasa1_profit_loss:<20,.2f} TL {kasa2_profit_loss:<20,.2f} TL")
print(f"{'ROI':<30} {kasa1_roi:<20.2f}% {kasa2_roi:<20.2f}%")
print(f"{'-'*70}")

# Hangi kasa daha karlÄ±?
if kasa1_profit_loss > kasa2_profit_loss:
    print(f"ğŸ† KASA 1 daha karlÄ± (+{kasa1_profit_loss - kasa2_profit_loss:,.2f} TL fark)")
elif kasa2_profit_loss > kasa1_profit_loss:
    print(f"ğŸ† KASA 2 daha karlÄ± (+{kasa2_profit_loss - kasa1_profit_loss:,.2f} TL fark)")
else:
    print(f"âš–ï¸ Her iki kasa eÅŸit karlÄ±lÄ±kta")

print(f"{'='*80}\n")

# =============================================================================
# MODEL KAYDETME + ZIP PAKETI (YENÄ° - FAZ 2)
# =============================================================================
print("\n" + "="*80)
print("ğŸ’¾ MODELLER KAYDEDÄ°LÄ°YOR")
print("="*80)

import json
import shutil

# models/ klasÃ¶rÃ¼nÃ¼ oluÅŸtur
os.makedirs('models', exist_ok=True)

# 1. Progressive NN modeli (Transformer ile)
model.save('models/jetx_progressive_transformer.h5')
print("âœ… Progressive NN (Transformer) kaydedildi: jetx_progressive_transformer.h5")

# 2. Scaler
joblib.dump(scaler, 'models/scaler_progressive_transformer.pkl')
print("âœ… Scaler kaydedildi: scaler_progressive_transformer.pkl")

# 3. Model bilgileri (JSON) - YENÄ°: Transformer ve Ã‡ift Kasa bilgileri eklendi
total_time = stage1_time + stage2_time + stage3_time
info = {
    'model': 'Progressive_NN_Transformer',
    'version': '2.0',
    'date': '2025-10-12',
    'architecture': {
        'progressive_nn': {
            'n_beats': True,
            'tcn': True,
            'transformer': {
                'd_model': 256,
                'num_layers': 4,
                'num_heads': 8,
                'dff': 1024
            }
        }
    },
    'params': int(model.count_params()),
    'training_time_minutes': round(total_time/60, 1),
    'stage_times': {
        'stage1_foundation': round(stage1_time/60, 1),
        'stage2_threshold': round(stage2_time/60, 1),
        'stage3_full': round(stage3_time/60, 1)
    },
    'total_epochs': {
        'stage1': len(hist1.history['loss']),
        'stage2': len(hist2.history['loss']),
        'stage3': len(hist3.history['loss'])
    },
    'metrics': {
        'threshold_accuracy': float(thr_acc),
        'below_15_accuracy': float(below_acc),
        'above_15_accuracy': float(above_acc),
        'class_accuracy': float(cls_acc),
        'mae': float(mae_final),
        'rmse': float(rmse_final),
        'money_loss_risk': float(fpr) if cm[0,0] + cm[0,1] > 0 else 0.0
    },
    'dual_bankroll_performance': {
        'kasa_1_15x': {
            'roi': float(kasa1_roi),
            'accuracy': float(kasa1_accuracy),
            'total_bets': int(kasa1_total_bets),
            'profit_loss': float(kasa1_profit_loss)
        },
        'kasa_2_80percent': {
            'roi': float(kasa2_roi),
            'accuracy': float(kasa2_accuracy),
            'total_bets': int(kasa2_total_bets),
            'profit_loss': float(kasa2_profit_loss),
            'avg_exit_point': float(kasa2_avg_exit)
        }
    }
}

with open('models/model_info.json', 'w') as f:
    json.dump(info, f, indent=2)
print("âœ… Model bilgileri kaydedildi: model_info.json")

print("\nğŸ“ Kaydedilen dosyalar:")
print("  â€¢ jetx_progressive_transformer.h5 (Progressive NN + Transformer)")
print("  â€¢ scaler_progressive_transformer.pkl (Scaler)")
print("  â€¢ model_info.json (Model bilgileri)")
print("  â€¢ stage1_best.h5 (Checkpoint)")
print("  â€¢ stage2_best.h5 (Checkpoint)")
print("  â€¢ stage3_best.h5 (Checkpoint)")
print("="*80)

# =============================================================================
# MODELLERÄ° ZIP'LE VE Ä°NDÄ°R (YENÄ° - FAZ 2)
# =============================================================================
print("\n" + "="*80)
print("ğŸ“¦ MODELLER ZIP'LENIYOR")
print("="*80)

# ZIP dosyasÄ± oluÅŸtur
zip_filename = 'jetx_models_progressive_v2.0.zip'
shutil.make_archive(
    'jetx_models_progressive_v2.0',
    'zip',
    'models'
)

print(f"âœ… ZIP dosyasÄ± oluÅŸturuldu: {zip_filename}")
print(f"ğŸ“¦ Boyut: {os.path.getsize(f'{zip_filename}') / (1024*1024):.2f} MB")

# Google Colab'da indirme
try:
    import google.colab
    IN_COLAB = True
except ImportError:
    IN_COLAB = False

if IN_COLAB:
    try:
        from google.colab import files
        files.download(f'{zip_filename}')
        print(f"âœ… {zip_filename} indiriliyor...")
        print("\nğŸ“Œ Ä°NDÄ°RDÄ°ÄÄ°NÄ°Z DOSYAYI AÃ‡IP models/ KLASÃ–RÃœNE KOPYALAYIN:")
        print("  1. ZIP'i aÃ§Ä±n")
        print("  2. TÃ¼m dosyalarÄ± lokal projenizin models/ klasÃ¶rÃ¼ne kopyalayÄ±n")
        print("  3. Streamlit uygulamasÄ±nÄ± yeniden baÅŸlatÄ±n")
    except Exception as e:
        print(f"âš ï¸ Ä°ndirme hatasÄ±: {e}")
        print(f"âš ï¸ Manuel indirme gerekli: {zip_filename}")
else:
    print("\nâš ï¸ Google Colab ortamÄ± algÄ±lanamadÄ± - dosyalar sadece kaydedildi")
    print(f"ğŸ“ ZIP dosyasÄ± mevcut: {zip_filename}")
    print("\nğŸ’¡ Not: Bu script Google Colab'da Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda dosyalar otomatik indirilir.")

print("="*80)

print(f"\nğŸ“Š Model Bilgisi:")
print(json.dumps(info, indent=2))

# Final rapor
print("\n" + "="*80)
print("ğŸ‰ PROGRESSIVE TRAINING TAMAMLANDI!")
print("="*80)
print(f"Toplam SÃ¼re: {total_time/60:.1f} dakika ({total_time/3600:.1f} saat)")
print(f"Toplam Epoch: {info['total_epochs']['stage1'] + info['total_epochs']['stage2'] + info['total_epochs']['stage3']}")
print()

if below_acc >= 0.75 and fpr < 0.20:
    print("âœ… âœ… âœ… TÃœM HEDEFLER BAÅARIYLA AÅILDI!")
    print(f"  ğŸ”´ 1.5 ALTI: {below_acc*100:.1f}% (Hedef: 75%+)")
    print(f"  ğŸ’° Para kaybÄ±: {fpr*100:.1f}% (Hedef: <20%)")
    print("\nğŸš€ Model artÄ±k production'da kullanÄ±labilir!")
elif below_acc >= 0.70:
    print("âœ… âœ… Ä°YÄ° PERFORMANS!")
    print(f"  ğŸ”´ 1.5 ALTI: {below_acc*100:.1f}%")
    print(f"  ğŸ’° Para kaybÄ±: {fpr*100:.1f}%")
    print("\nBiraz daha eÄŸitimle hedeflere ulaÅŸÄ±labilir.")
else:
    print("âš ï¸ Hedefin altÄ±nda")
    print(f"  ğŸ”´ 1.5 ALTI: {below_acc*100:.1f}% (Hedef: 75%+)")
    print("\nÃ–neriler:")
    print("  - Daha fazla veri toplayÄ±n")
    print("  - Class weight'i artÄ±rÄ±n (35-40x)")
    print("  - Epoch sayÄ±sÄ±nÄ± artÄ±rÄ±n")

print("\nğŸ“ Sonraki adÄ±m:")
print("  1. jetx_progressive_final.h5 -> models/jetx_model.h5")
print("  2. scaler_progressive.pkl -> models/scaler.pkl")
print("  3. Streamlit uygulamasÄ±nÄ± test edin")
print("="*80)
print(f"BitiÅŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("="*80)
