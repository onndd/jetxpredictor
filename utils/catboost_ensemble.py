"""
CatBoost Ensemble Manager - Ultra Aggressive Training iÃ§in

10 model ensemble yÃ¶netimi, weighted averaging, variance-based confidence tracking.

GÃœNCELLEME:
- Predict Proba desteÄŸi eklendi (Classifier iÃ§in)
- 2 Modlu yapÄ±ya uygun confidence hesaplamalarÄ±
"""

import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional
import logging
from pathlib import Path
import json
from catboost import CatBoostRegressor, CatBoostClassifier
import joblib

logger = logging.getLogger(__name__)


class CatBoostEnsemble:
    """
    CatBoost model ensemble'Ä± yÃ¶netir.
    
    Features:
    - Multiple model training with different seeds
    - Weighted averaging based on performance
    - Variance-based confidence scores
    - Performance tracking
    """
    
    def __init__(
        self, 
        model_type: str = 'regressor',
        n_models: int = 10,
        base_params: Optional[Dict] = None
    ):
        """
        Args:
            model_type: 'regressor' veya 'classifier'
            n_models: Ensemble'daki model sayÄ±sÄ±
            base_params: Temel CatBoost parametreleri
        """
        self.model_type = model_type
        self.n_models = n_models
        self.base_params = base_params or {}
        
        self.models: List = []
        self.weights: np.ndarray = np.ones(n_models) / n_models  # BaÅŸlangÄ±Ã§ta eÅŸit aÄŸÄ±rlÄ±k
        self.performance_history: List[Dict] = []
        
    def create_model(self, seed: int, subsample: float, bagging_temp: float) -> object:
        """
        Tekil model oluÅŸtur
        """
        params = self.base_params.copy()
        params.update({
            'random_seed': seed,
            'subsample': subsample,
            'bagging_temperature': bagging_temp
        })
        
        if self.model_type == 'regressor':
            return CatBoostRegressor(**params)
        else:
            return CatBoostClassifier(**params)
    
    def train_ensemble(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        verbose: bool = True
    ) -> Dict:
        """
        Ensemble'daki tÃ¼m modelleri eÄŸit
        """
        self.models = []
        individual_scores = []
        
        # FarklÄ± parametrelerle modeller oluÅŸtur
        seeds = [42 + i * 100 for i in range(self.n_models)]
        subsamples = np.linspace(0.7, 0.9, self.n_models)
        bagging_temps = np.linspace(0.5, 1.5, self.n_models)
        
        for i in range(self.n_models):
            if verbose:
                print(f"\n{'='*80}")
                print(f"ðŸ¤– MODEL {i+1}/{self.n_models} EÄžÄ°TÄ°MÄ°")
                print(f"{'='*80}")
                print(f"Seed: {seeds[i]}, Subsample: {subsamples[i]:.3f}, Bagging Temp: {bagging_temps[i]:.3f}")
            
            # Model oluÅŸtur ve eÄŸit
            model = self.create_model(seeds[i], subsamples[i], bagging_temps[i])
            
            model.fit(
                X_train, y_train,
                eval_set=(X_val, y_val),
                verbose=100 if verbose else False
            )
            
            self.models.append(model)
            
            # Validation performansÄ±
            if self.model_type == 'classifier':
                # Classifier iÃ§in predict_proba kullanmak daha iyi olabilir ama metric accuracy ise predict yeterli
                val_pred = model.predict(X_val)
                from sklearn.metrics import accuracy_score
                score = accuracy_score(y_val, val_pred)
                individual_scores.append(score)
                if verbose: print(f"\nâœ… Model {i+1} VAL ACC: {score*100:.2f}%")
            else:
                val_pred = model.predict(X_val)
                from sklearn.metrics import mean_absolute_error
                score = mean_absolute_error(y_val, val_pred)
                individual_scores.append(score)
                if verbose: print(f"\nâœ… Model {i+1} VAL MAE: {score:.4f}")
        
        # Performansa gÃ¶re aÄŸÄ±rlÄ±klarÄ± hesapla
        if self.model_type == 'regressor':
            # MAE iÃ§in dÃ¼ÅŸÃ¼k = iyi, tersini al
            inverse_scores = 1.0 / (np.array(individual_scores) + 1e-8)
            self.weights = inverse_scores / inverse_scores.sum()
        else:
            # Accuracy iÃ§in yÃ¼ksek = iyi
            scores_array = np.array(individual_scores)
            self.weights = scores_array / scores_array.sum()
        
        if verbose:
            print(f"\n{'='*80}")
            print(f"ðŸ“Š ENSEMBLE AÄžIRLIKLARI")
            print(f"{'='*80}")
            for i, (score, weight) in enumerate(zip(individual_scores, self.weights)):
                print(f"Model {i+1}: Score={score:.4f}, Weight={weight:.4f}")
        
        return {
            'individual_scores': individual_scores,
            'weights': self.weights.tolist(),
            'mean_score': np.mean(individual_scores),
            'std_score': np.std(individual_scores)
        }
    
    def predict(self, X, return_variance: bool = False) -> np.ndarray:
        """
        Ensemble tahmin (Regressor: DeÄŸer, Classifier: SÄ±nÄ±f)
        """
        if not self.models:
            raise ValueError("Ensemble henÃ¼z eÄŸitilmedi!")
        
        # Her modelden tahmin al
        predictions = []
        for model in self.models:
            pred = model.predict(X)
            predictions.append(pred)
        
        predictions = np.array(predictions)  # Shape: (n_models, n_samples)
        
        # AÄŸÄ±rlÄ±klÄ± ortalama (Regressor iÃ§in deÄŸer, Classifier iÃ§in sÄ±nÄ±f ortalamasÄ± - dikkat!)
        # Classifier iÃ§in hard voting daha doÄŸru olabilir, ama weighted average soft voting'e benzer.
        weighted_pred = np.average(predictions, axis=0, weights=self.weights)
        
        if self.model_type == 'classifier':
            # SÄ±nÄ±f tahminlerini tekrar 0/1'e yuvarla (Soft voting sonrasÄ± hard decision)
            weighted_pred = (weighted_pred >= 0.5).astype(int)
        
        if return_variance:
            # Variance hesapla (model agreement iÃ§in)
            variance = np.var(predictions, axis=0)
            return weighted_pred, variance
        
        return weighted_pred

    def predict_proba(self, X, return_variance: bool = False) -> np.ndarray:
        """
        Classifier iÃ§in probability tahmini (Soft Voting)
        """
        if self.model_type != 'classifier':
            raise ValueError("predict_proba sadece classifier iÃ§in kullanÄ±labilir!")
        
        if not self.models:
            raise ValueError("Ensemble henÃ¼z eÄŸitilmedi!")
        
        # Her modelden probability al
        probabilities = []
        for model in self.models:
            # [:, 1] -> Class 1 (1.5 Ã¼stÃ¼) olasÄ±lÄ±ÄŸÄ±
            # predict_proba (n_samples, 2) dÃ¶ner
            proba = model.predict_proba(X)
            probabilities.append(proba)
        
        probabilities = np.array(probabilities) # Shape: (n_models, n_samples, 2)
        
        # AÄŸÄ±rlÄ±klÄ± ortalama
        weighted_proba = np.average(probabilities, axis=0, weights=self.weights)
        
        if return_variance:
            # Class 1 iÃ§in variance (1.5 Ã¼stÃ¼ olma olasÄ±lÄ±ÄŸÄ± Ã¼zerinden)
            variance = np.var(probabilities[:, :, 1], axis=0)
            return weighted_proba, variance
        
        return weighted_proba
    
    def get_confidence(self, X: np.ndarray) -> np.ndarray:
        """
        Tahmin gÃ¼ven skorlarÄ± (variance-based)
        DÃ¼ÅŸÃ¼k variance = yÃ¼ksek gÃ¼ven
        """
        if self.model_type == 'regressor':
            _, variance = self.predict(X, return_variance=True)
        else:
            _, variance = self.predict_proba(X, return_variance=True)
        
        # Variance'Ä± confidence'a Ã§evir (0-1 arasÄ±)
        # DÃ¼ÅŸÃ¼k variance = yÃ¼ksek confidence
        max_variance = np.max(variance) if np.max(variance) > 0 else 1.0
        confidence = 1.0 - (variance / max_variance)
        
        return confidence
    
    def save_ensemble(self, save_dir: str):
        """Ensemble'Ä± kaydet"""
        save_path = Path(save_dir)
        save_path.mkdir(parents=True, exist_ok=True)
        
        # Her modeli kaydet
        for i, model in enumerate(self.models):
            model_path = save_path / f"model_{i}.cbm"
            model.save_model(str(model_path))
        
        # Metadata kaydet
        metadata = {
            'model_type': self.model_type,
            'n_models': self.n_models,
            'weights': self.weights.tolist(),
            'base_params': self.base_params,
            'performance_history': self.performance_history
        }
        
        with open(save_path / 'ensemble_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
        
        logger.info(f"Ensemble kaydedildi: {save_path}")
    
    def load_ensemble(self, load_dir: str):
        """Ensemble'Ä± yÃ¼kle"""
        load_path = Path(load_dir)
        
        # Metadata yÃ¼kle
        with open(load_path / 'ensemble_metadata.json', 'r') as f:
            metadata = json.load(f)
        
        self.model_type = metadata['model_type']
        self.n_models = metadata['n_models']
        self.weights = np.array(metadata['weights'])
        self.base_params = metadata['base_params']
        self.performance_history = metadata.get('performance_history', [])
        
        # Modelleri yÃ¼kle
        self.models = []
        for i in range(self.n_models):
            model_path = load_path / f"model_{i}.cbm"
            
            if self.model_type == 'regressor':
                model = CatBoostRegressor()
            else:
                model = CatBoostClassifier()
            
            model.load_model(str(model_path))
            self.models.append(model)
        
        logger.info(f"Ensemble yÃ¼klendi: {load_path}")


class CrossValidatedEnsemble:
    """
    Cross-validation ile eÄŸitilmiÅŸ ensemble
    """
    
    def __init__(
        self,
        model_type: str = 'regressor',
        n_folds: int = 5,
        base_params: Optional[Dict] = None
    ):
        self.model_type = model_type
        self.n_folds = n_folds
        self.base_params = base_params or {}
        
        self.fold_models: List = []
        self.fold_scores: List[float] = []
        
    def time_series_split(
        self,
        X: np.ndarray,
        y: np.ndarray,
        n_folds: int
    ) -> List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]]:
        """
        Kronolojik cross-validation split (time-series iÃ§in)
        """
        n_samples = len(X)
        fold_size = n_samples // (n_folds + 1)
        
        splits = []
        for i in range(n_folds):
            train_end = fold_size * (i + 1)
            val_end = train_end + fold_size
            
            X_train = X[:train_end]
            y_train = y[:train_end]
            X_val = X[train_end:val_end]
            y_val = y[train_end:val_end]
            
            splits.append((X_train, X_val, y_train, y_val))
        
        return splits
    
    def train_cv(
        self,
        X: np.ndarray,
        y: np.ndarray,
        verbose: bool = True
    ) -> Dict:
        """Cross-validation ile eÄŸit"""
        self.fold_models = []
        self.fold_scores = []
        
        # Time-series split
        splits = self.time_series_split(X, y, self.n_folds)
        
        for fold_idx, (X_train, X_val, y_train, y_val) in enumerate(splits):
            if verbose:
                print(f"\n{'='*80}")
                print(f"ðŸ“Š FOLD {fold_idx + 1}/{self.n_folds}")
                print(f"{'='*80}")
            
            # Model oluÅŸtur ve eÄŸit
            if self.model_type == 'regressor':
                model = CatBoostRegressor(**self.base_params)
            else:
                model = CatBoostClassifier(**self.base_params)
            
            model.fit(
                X_train, y_train,
                eval_set=(X_val, y_val),
                verbose=100 if verbose else False
            )
            
            self.fold_models.append(model)
            
            # Validation performansÄ±
            val_pred = model.predict(X_val)
            
            if self.model_type == 'regressor':
                from sklearn.metrics import mean_absolute_error
                score = mean_absolute_error(y_val, val_pred)
                self.fold_scores.append(score)
                if verbose: print(f"\nâœ… Fold {fold_idx + 1} VAL MAE: {score:.4f}")
            else:
                from sklearn.metrics import accuracy_score
                score = accuracy_score(y_val, val_pred)
                self.fold_scores.append(score)
                if verbose: print(f"\nâœ… Fold {fold_idx + 1} VAL ACC: {score*100:.2f}%")
        
        return {
            'fold_scores': self.fold_scores,
            'mean_score': np.mean(self.fold_scores),
            'std_score': np.std(self.fold_scores)
        }
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """CV ensemble tahmini (tÃ¼m fold modellerin ortalamasÄ±)"""
        if not self.fold_models:
            raise ValueError("CV ensemble henÃ¼z eÄŸitilmedi!")
        
        predictions = []
        for model in self.fold_models:
            pred = model.predict(X)
            predictions.append(pred)
        
        # Ortalama al
        return np.mean(predictions, axis=0)
