"""
JetX Predictor - Tahmin Motoru

Bu mod√ºl eƒüitilmi≈ü modeli y√ºkler ve tahmin yapar.
Hem kategorik hem de deƒüer tahmini yapar.
CatBoost ve Neural Network modellerini destekler.
"""

import numpy as np
import joblib
from typing import Dict, Tuple, List, Optional
import os
import sys
import logging

# Kategori tanƒ±mlarƒ±nƒ± import et
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from category_definitions import (
    CategoryDefinitions,
    FeatureEngineering,
    CONFIDENCE_THRESHOLDS
)
from utils.custom_losses import CUSTOM_OBJECTS

# Logging ayarla
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class JetXPredictor:
    """JetX tahmin sƒ±nƒ±fƒ± - Neural Network ve CatBoost destekli"""
    
    def __init__(
        self,
        model_path: str = "models/jetx_model.h5",
        scaler_path: str = "models/scaler.pkl",
        model_type: str = 'neural_network'
    ):
        """
        Args:
            model_path: Eƒüitilmi≈ü model dosyasƒ± yolu
            scaler_path: Scaler dosyasƒ± yolu
            model_type: Model tipi ('neural_network' veya 'catboost')
        """
        self.model_type = model_type
        self.model_path = model_path
        self.scaler_path = scaler_path
        self.model = None
        self.scaler = None
        self.feature_names = None
        
        # CatBoost i√ßin ek modeller
        self.regressor = None
        self.classifier = None
        
        # CatBoost kullanƒ±lƒ±yorsa dosya yollarƒ±nƒ± g√ºncelle
        if model_type == 'catboost':
            self.model_path = "models/catboost_regressor.cbm"
            self.classifier_path = "models/catboost_classifier.cbm"
            self.scaler_path = "models/catboost_scaler.pkl"
        
        # Model varsa y√ºkle
        if os.path.exists(model_path if model_type == 'neural_network' else self.model_path):
            self.load_model()
    
    def load_model(self):
        """Modeli ve scaler'ƒ± y√ºkler"""
        try:
            if self.model_type == 'neural_network':
                # TensorFlow/Keras modeli i√ßin
                try:
                    from tensorflow import keras
                    
                    # Custom objects kullanarak model y√ºkle
                    self.model = keras.models.load_model(self.model_path, custom_objects=CUSTOM_OBJECTS)
                    logger.info(f"‚úÖ Neural Network modeli y√ºklendi: {self.model_path}")
                except ImportError:
                    # PyTorch veya sklearn modeli i√ßin
                    import joblib
                    self.model = joblib.load(self.model_path)
                    logger.info(f"‚úÖ Model y√ºklendi: {self.model_path}")
                    
            elif self.model_type == 'catboost':
                # CatBoost modelleri i√ßin
                from catboost import CatBoostRegressor, CatBoostClassifier
                
                self.regressor = CatBoostRegressor()
                self.regressor.load_model(self.model_path)
                logger.info(f"‚úÖ CatBoost Regressor y√ºklendi: {self.model_path}")
                
                self.classifier = CatBoostClassifier()
                self.classifier.load_model(self.classifier_path)
                logger.info(f"‚úÖ CatBoost Classifier y√ºklendi: {self.classifier_path}")
            
            # Scaler'ƒ± y√ºkle
            if os.path.exists(self.scaler_path):
                self.scaler = joblib.load(self.scaler_path)
                logger.info(f"‚úÖ Scaler y√ºklendi: {self.scaler_path}")
            else:
                logger.warning(f"‚ö†Ô∏è Scaler bulunamadƒ±: {self.scaler_path}")
            
            # KRƒ∞Tƒ∞K: Feature Schema Validation
            self._validate_feature_schema_or_fail()
            
        except Exception as e:
            logger.error(f"‚ö†Ô∏è Model y√ºkleme hatasƒ±: {e}")
            logger.info("Model hen√ºz eƒüitilmemi≈ü olabilir. √ñnce Google Colab'da eƒüitin.")
    
    def _validate_feature_schema_or_fail(self):
        """
        Feature schema validation - ZORUNLU kontrol
        
        üîí G√úVENLƒ∞K: Feature skew ve data leakage riskini √∂nler
        üö® KRƒ∞Tƒ∞K: Model-features uyumsuzluƒüunda Sƒ∞STEM √á√ñKS√úN (fail-fast)
        
        Raises:
            RuntimeError: Feature schema uyumsuzluƒüunda
        """
        try:
            from utils.feature_validator import get_feature_validator
            
            # Dummy veriyle test feature'larƒ± olu≈ütur
            dummy_history = [1.5] * 1000  # 1000 adet √∂rnek veri
            current_features = FeatureEngineering.extract_all_features(dummy_history)
            
            # Feature validator'ƒ± al
            validator = get_feature_validator()
            
            # Model metadata path'ini belirle
            model_name = "jetx_model_v2"  # Default model name
            
            # Model tipine g√∂re metadata path'ini g√ºncelle
            if self.model_type == 'catboost':
                meta_path = self.model_path.replace("_regressor.cbm", "_metadata.json")
            else:
                meta_path = self.model_path.replace(".h5", "_metadata.json")
            
            # Metadata kontrol√º
            if not os.path.exists(meta_path):
                logger.warning(f"‚ö†Ô∏è Metadata bulunamadƒ±: {meta_path}")
                logger.warning("üîß Training sƒ±rasƒ±nda feature metadata kaydedilmemi≈ü olabilir.")
                logger.warning("üí° √á√∂z√ºm: Modeli yeniden eƒüitin ve metadata kaydedin.")
                # Continue without strict validation (development mode)
                return
            
            # Metadata'yƒ± y√ºkle
            import json
            with open(meta_path, 'r') as f:
                metadata = json.load(f)
                expected_features = metadata.get("feature_names", [])
                expected_count = metadata.get("feature_count", len(expected_features))
            
            # Feature sayƒ±sƒ± kontrol√º
            current_count = len(current_features)
            if expected_count != current_count:
                raise RuntimeError(
                    f"üö® FEATURE COUNT MISMATCH:\n"
                    f"   Model eƒüitildiƒüi: {expected_count} √∂zellik\n"
                    f"   Mevcut kod √ºrettiƒüi: {current_count} √∂zellik\n"
                    f"   Fark: {abs(expected_count - current_count)} √∂zellik\n"
                    f"üí° Model yeniden eƒüitilmeli veya kod g√ºncellenmeli"
                )
            
            # Feature isimleri kontrol√º
            current_feature_names = sorted(list(current_features.keys()))
            expected_feature_names = sorted(expected_features)
            
            missing_features = set(expected_feature_names) - set(current_feature_names)
            extra_features = set(current_feature_names) - set(expected_feature_names)
            
            if missing_features or extra_features:
                error_msg = "üö® FEATURE SCHEMA MISMATCH:\n"
                if missing_features:
                    error_msg += f"   Eksik feature'lar: {list(missing_features)[:5]}{'...' if len(missing_features) > 5 else ''}\n"
                if extra_features:
                    error_msg += f"   Fazla feature'lar: {list(extra_features)[:5]}{'...' if len(extra_features) > 5 else ''}\n"
                error_msg += f"   Model eƒüitildiƒüi: {expected_count} feature\n"
                error_msg += f"   Mevcut kod: {current_count} feature\n"
                error_msg += "üí° Model yeniden eƒüitilmeli veya kod g√ºncellenmeli"
                raise RuntimeError(error_msg)
            
            # Scaler compatibility kontrol√º
            if self.scaler is not None:
                validator.validate_compatibility(current_features, self.scaler, model_name)
            
            logger.info(f"‚úÖ Feature Schema Validation Passed - {current_count} features")
            
        except ImportError:
            logger.warning("‚ö†Ô∏è Feature validator bulunamadƒ±, validation atlanƒ±yor")
        except Exception as e:
            if "Feature schema" in str(e) or "FEATURE" in str(e):
                # Feature schema hatasƒ± - CRITICAL
                raise RuntimeError(f"üö® FEATURE SCHEMA VALIDATION FAILED: {e}")
            else:
                # Diƒüer hatalar - warning ile devam et
                logger.warning(f"‚ö†Ô∏è Feature validation warning: {e}")
    
    def extract_features_from_history(self, history: List[float]) -> Dict:
        """
        Ge√ßmi≈ü verilerden √∂zellik √ßƒ±karƒ±r ve sequence'ler olu≈üturur
        
        Args:
            history: Ge√ßmi≈ü deƒüerler listesi (en yeni en sonda)
            
        Returns:
            Dictionary containing features and sequences
        """
        # T√ºm √∂zellikleri √ßƒ±kar (geli≈ütirilmi≈ü feature engineering)
        features_dict = FeatureEngineering.extract_all_features(history)
        
        # Dictionary'yi array'e √ßevir
        feature_values = np.array(list(features_dict.values())).reshape(1, -1)
        
        # Scaler varsa normalize et
        if self.scaler is not None:
            feature_values = self.scaler.transform(feature_values)
        
        # Sequence'leri hazƒ±rla (4 farklƒ± pencere) - Neural Network i√ßin
        # Log10 transformation uygula (training ile tutarlƒ±)
        seq_50 = None
        seq_200 = None
        seq_500 = None
        seq_1000 = None
        
        if len(history) >= 50:
            seq_50 = np.array(history[-50:]).reshape(1, 50, 1)
            seq_50 = np.log10(seq_50 + 1e-8)
            
        if len(history) >= 200:
            seq_200 = np.array(history[-200:]).reshape(1, 200, 1)
            seq_200 = np.log10(seq_200 + 1e-8)
            
        if len(history) >= 500:
            seq_500 = np.array(history[-500:]).reshape(1, 500, 1)
            seq_500 = np.log10(seq_500 + 1e-8)
            
        if len(history) >= 1000:
            seq_1000 = np.array(history[-1000:]).reshape(1, 1000, 1)
            seq_1000 = np.log10(seq_1000 + 1e-8)
        
        return {
            'features': feature_values,
            'seq_50': seq_50,
            'seq_200': seq_200,
            'seq_500': seq_500,
            'seq_1000': seq_1000
        }
    
    def predict(
        self,
        history: List[float],
        mode: str = 'normal'
    ) -> Dict:
        """
        Tahmin yapar (model tipine g√∂re)
        
        Args:
            history: Ge√ßmi≈ü deƒüerler listesi (en az 1000 deƒüer gerekli)
            mode: Tahmin modu ('normal', 'rolling', 'aggressive')
            
        Returns:
            Tahmin sonu√ßlarƒ± dictionary
        """
        # Model kontrol√º
        if self.model_type == 'neural_network' and self.model is None:
            return {
                'error': 'Neural Network modeli y√ºklenmedi. √ñnce modeli Google Colab\'da eƒüitin.',
                'predicted_value': None,
                'confidence': 0.0,
                'above_threshold': None,
                'category': None,
                'recommendation': 'BEKLE'
            }
        elif self.model_type == 'catboost' and (self.regressor is None or self.classifier is None):
            return {
                'error': 'CatBoost modelleri y√ºklenmedi. √ñnce modelleri Google Colab\'da eƒüitin.',
                'predicted_value': None,
                'confidence': 0.0,
                'above_threshold': None,
                'category': None,
                'recommendation': 'BEKLE'
            }
        
        # Minimum veri kontrol√º
        if len(history) < 1000:
            return {
                'error': f'En az 1000 ge√ßmi≈ü veri gerekli (mevcut: {len(history)})',
                'predicted_value': None,
                'confidence': 0.0,
                'above_threshold': None,
                'category': None,
                'recommendation': 'BEKLE',
                'pattern_risk': 0.0
            }
        
        try:
            # Model tipine g√∂re tahmin yap
            if self.model_type == 'neural_network':
                return self._predict_neural_network(history, mode)
            elif self.model_type == 'catboost':
                return self._predict_catboost(history, mode)
            else:
                return {
                    'error': f'Bilinmeyen model tipi: {self.model_type}',
                    'predicted_value': None,
                    'confidence': 0.0,
                    'above_threshold': None,
                    'category': None,
                    'recommendation': 'BEKLE'
                }
                
        except Exception as e:
            return {
                'error': f'Tahmin hatasƒ±: {str(e)}',
                'predicted_value': None,
                'confidence': 0.0,
                'above_threshold': None,
                'category': None,
                'recommendation': 'BEKLE',
                'pattern_risk': 0.0
            }
    
    def _predict_neural_network(
        self,
        history: List[float],
        mode: str
    ) -> Dict:
        """Neural Network ile tahmin yapar"""
        # √ñzellikleri ve sequence'leri √ßƒ±kar
        model_inputs = self.extract_features_from_history(history)
        
        # Sequence kontrol√º - Eƒüer herhangi biri None ise hata d√∂nd√ºr
        required_sequences = ['seq_50', 'seq_200', 'seq_500', 'seq_1000']
        missing_sequences = [seq for seq in required_sequences if model_inputs.get(seq) is None]
        
        if missing_sequences:
            min_required_data = {
                'seq_50': 50,
                'seq_200': 200,
                'seq_500': 500,
                'seq_1000': 1000
            }
            max_missing = max(min_required_data[seq] for seq in missing_sequences)
            return {
                'error': f'Yetersiz veri: En az {max_missing} ge√ßmi≈ü veri gerekli (mevcut: {len(history)})',
                'predicted_value': None,
                'confidence': 0.0,
                'above_threshold': None,
                'category': None,
                'recommendation': 'BEKLE',
                'pattern_risk': 0.0
            }
        
        # Model inputlarƒ± hazƒ±rla (5 girdi: features + 4 sequence)
        input_data = [
            model_inputs['features'],
            model_inputs['seq_50'],
            model_inputs['seq_200'],
            model_inputs['seq_500'],
            model_inputs['seq_1000']
        ]
        
        # Tahmin yap (3 √ßƒ±ktƒ±: regression, classification, threshold)
        predictions = self.model.predict(input_data, verbose=0)
        
        # √áƒ±ktƒ±larƒ± ayƒ±r
        regression_pred = predictions[0]
        classification_pred = predictions[1]
        threshold_pred = predictions[2]
        
        predicted_value = float(regression_pred[0][0])
        threshold_prob = float(threshold_pred[0][0])
        
        # Model confidence
        model_confidence = max(threshold_prob, 1 - threshold_prob)
        
        # G√ºven skorunu hesapla (model confidence'a daha fazla aƒüƒ±rlƒ±k)
        confidence = model_confidence * 0.7 + self._calculate_confidence(history, predicted_value) * 0.3
        
        # 1.5x e≈üik kontrol√º
        above_threshold = predicted_value >= CategoryDefinitions.CRITICAL_THRESHOLD
        
        # Kategori
        category = CategoryDefinitions.get_category(predicted_value)
        detailed_category = CategoryDefinitions.get_detailed_category(predicted_value)
        
        # Mod bazlƒ± √∂neri
        recommendation = self._get_recommendation(confidence, mode, above_threshold)
        
        # Uyarƒ±lar
        warnings = self._generate_warnings(history, predicted_value, confidence)
        
        return {
            'predicted_value': round(predicted_value, 2),
            'confidence': round(confidence, 2),
            'above_threshold': above_threshold,
            'threshold_probability': round(threshold_prob, 2),
            'category': category,
            'detailed_category': detailed_category,
            'recommendation': recommendation,
            'pattern_risk': 0.0,
            'warnings': warnings,
            'mode': mode,
            'model_type': 'neural_network'
        }
    
    def _predict_catboost(
        self,
        history: List[float],
        mode: str
    ) -> Dict:
        """CatBoost ile tahmin yapar"""
        # √ñzellikleri √ßƒ±kar
        model_inputs = self.extract_features_from_history(history)
        feature_values = model_inputs['features']
        
        # Regressor tahmin (deƒüer)
        predicted_value = float(self.regressor.predict(feature_values)[0])
        
        # Classifier tahmin (1.5 e≈üik)
        threshold_proba = self.classifier.predict_proba(feature_values)[0]
        threshold_prob = float(threshold_proba[1])  # 1.5 √ºst√º olma olasƒ±lƒ±ƒüƒ±
        
        # Confidence (model confidence'a daha fazla aƒüƒ±rlƒ±k)
        model_confidence = max(threshold_prob, 1 - threshold_prob)
        confidence = model_confidence * 0.7 + self._calculate_confidence(history, predicted_value) * 0.3
        
        # 1.5x e≈üik kontrol√º
        above_threshold = predicted_value >= CategoryDefinitions.CRITICAL_THRESHOLD
        
        # Kategori
        category = CategoryDefinitions.get_category(predicted_value)
        detailed_category = CategoryDefinitions.get_detailed_category(predicted_value)
        
        # √ñneri
        recommendation = self._get_recommendation(confidence, mode, above_threshold)
        
        # Uyarƒ±lar
        warnings = self._generate_warnings(history, predicted_value, confidence)
        
        return {
            'predicted_value': round(predicted_value, 2),
            'confidence': round(confidence, 2),
            'above_threshold': above_threshold,
            'threshold_probability': round(threshold_prob, 2),
            'category': category,
            'detailed_category': detailed_category,
            'recommendation': recommendation,
            'pattern_risk': 0.0,
            'warnings': warnings,
            'mode': mode,
            'model_type': 'catboost'
        }
    
    def _calculate_confidence(
        self,
        history: List[float],
        predicted_value: float
    ) -> float:
        """G√ºven skorunu hesaplar"""
        confidence = 0.65
        
        if len(history) >= 10:
            recent = history[-10:]
            volatility = np.std(recent)
            
            if volatility < 2.0:
                confidence += 0.10
            elif volatility > 5.0:
                confidence -= 0.10
        
        if 1.0 <= predicted_value <= 10.0:
            confidence += 0.10
        elif predicted_value > 50.0:
            confidence -= 0.15
        
        return max(0.0, min(1.0, confidence))
    
    def _get_recommendation(
        self,
        confidence: float,
        mode: str,
        above_threshold: bool
    ) -> str:
        """Mod bazlƒ± √∂neri verir (G√úNCELLENDƒ∞)"""
        # Config'den veya category_definitions'dan gelen deƒüeri al, yoksa 0.85 kullan
        threshold = CONFIDENCE_THRESHOLDS.get(mode, 0.85)
        
        if confidence < threshold:
            return 'BEKLE'
        
        if not above_threshold:
            return 'BEKLE'
        
        if confidence >= threshold and above_threshold:
            if mode == 'rolling': # %95 ve √ºzeri
                return 'OYNA (G√úVENLƒ∞)'
            elif mode == 'normal': # %85 ve √ºzeri
                return 'OYNA'
            # Aggressive modu kaldƒ±rƒ±ldƒ±
        
        return 'BEKLE'
    
    def _generate_warnings(
        self,
        history: List[float],
        predicted_value: float,
        confidence: float
    ) -> List[str]:
        """Uyarƒ±lar olu≈üturur"""
        warnings = []
        
        if confidence < 0.60:
            warnings.append(f"‚ö†Ô∏è D√º≈ü√ºk g√ºven seviyesi ({confidence:.0%})")
        
        if 1.45 <= predicted_value <= 1.55:
            warnings.append("üö® KRƒ∞Tƒ∞K B√ñLGE: 1.45-1.55x arasƒ± √ßok riskli!")
        
        if predicted_value < CategoryDefinitions.CRITICAL_THRESHOLD:
            warnings.append(f"‚ùå TAHMƒ∞N 1.5x ALTINDA ({predicted_value:.2f}x) - OYNAMA!")
        
        try:
            features = FeatureEngineering.extract_all_features(history)
            
            if len(history) >= 50:
                distance_10x = features.get('distance_from_10x', 999)
                distance_20x = features.get('distance_from_20x', 999)
                
                if distance_10x < 15 or distance_20x < 20:
                    volatility = features.get('recent_volatility_pattern', 0)
                    if volatility > 0.5:
                        warnings.append("‚ùÑÔ∏è SOƒûUMA D√ñNEMƒ∞ OLABƒ∞Lƒ∞R!")
                        warnings.append("üìä Tavsiye: Sonraki 10-15 eli oynama")
            
            volatility_norm = features.get('volatility_normalization', 0)
            if volatility_norm > 0.6:
                warnings.append("‚úÖ TOPARLANMA ƒ∞≈ûARETƒ∞ tespit edildi")
            
            z_score = features.get('z_score', 0)
            if abs(z_score) > 2.5:
                warnings.append(f"üîî Anormal deƒüer tespit edildi (Z-score: {z_score:.2f})")
        except:
            pass
        
        warnings.append("‚ö†Ô∏è Bu tahmin %100 doƒüru deƒüildir, para kaybedebilirsiniz")
        
        return warnings
    
    def predict_threshold_only(self, history: List[float]) -> Dict:
        """Sadece 1.5x e≈üik tahmini yapar"""
        if len(history) < 10:
            return {
                'above_threshold_probability': 0.5,
                'recommendation': 'BEKLE'
            }
        
        recent_50 = history[-50:] if len(history) >= 50 else history
        above_count = sum(1 for v in recent_50 if v >= 1.5)
        probability = above_count / len(recent_50)
        
        return {
            'above_threshold_probability': round(probability, 2),
            'recommendation': 'OYNA' if probability > 0.65 else 'BEKLE'
        }
